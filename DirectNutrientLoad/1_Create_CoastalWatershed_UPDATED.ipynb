{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Coastal Watersheds for Lake Huron Coastal Wetlands (CW)\n",
    "\n",
    "This notebook delineates **coastal watersheds** for **Lake Huron–connected coastal wetlands** under four inundation scenarios (**avg, low, high, surge**) while ensuring a **stable wetland identifier (`CW_Id`) is preserved throughout the full workflow**. The goal is to produce **one coastal watershed polygon per wetland (`CW_Id`)**, along with consistent wetland and watershed attributes needed for later merging and plotting (area + centroid coordinates).\n",
    "\n",
    "---\n",
    "\n",
    "## Key idea: keep `CW_Id` stable from start to finish\n",
    "Raster-based watershed tools can replace feature IDs with raster values (e.g., `gridcode`) and can also split features during polygon/raster conversions. To avoid ID mismatches, this workflow:\n",
    "\n",
    "- assigns and carries a stable **`CW_Id`** in all wetland layers,\n",
    "- creates **one pour point per wetland** (inside the polygon),\n",
    "- snaps pour points to the drainage network,\n",
    "- delineates watersheds using the snapped points,\n",
    "- **converts watershed outputs back to polygons** and **dissolves by `CW_Id`** so each wetland ends with **exactly one** watershed polygon.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "Main inputs used in this notebook:\n",
    "\n",
    "- **Coastal wetland polygons** (avg/low/high/surge inundation layers)\n",
    "- **Shoreline polyline** (Lake Huron US-side shoreline)\n",
    "- **Great Lakes Basin streams** (used to remove riparian/stream-connected wetland overlap)\n",
    "- **D8 flow direction raster** (hydrologic routing grid)\n",
    "- **Stream-watershed polygons** (areas draining to streams; removed from coastal watersheds)\n",
    "- **Lake Huron polygon** (removed from final watershed polygons)\n",
    "\n",
    "All distance-based operations are performed in **Great Lakes Albers (EPSG:3174)** (meters).\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs (per inundation scenario)\n",
    "For each scenario (**avg, low, high, surge**), the notebook produces:\n",
    "\n",
    "### Wetland-side products\n",
    "- **shoreline-interacting wetlands** (wetlands intersecting a 2000 m shoreline buffer)\n",
    "- **riparian-erased wetlands** (wetlands with 50 m stream-buffer overlap removed)\n",
    "- wetland attributes:\n",
    "  - `CW_Id` (stable wetland identifier)\n",
    "  - `CW_Area_m2`\n",
    "  - wetland centroid coordinates in EPSG:3174 (`CW_cx`, `CW_cy`)\n",
    "  - wetland centroid coordinates in WGS84 (`CW_lon`, `CW_lat`)\n",
    "\n",
    "### Watershed-side products\n",
    "- **pour points** (`*_pourpoints.shp`) — one point inside each wetland polygon\n",
    "- **snapped pour points** — pour points snapped to a drainage cell using flow accumulation\n",
    "- **watershed raster** (cell values correspond to `CW_Id`)\n",
    "- **watershed polygons**, dissolved by `CW_Id` (one watershed per wetland)\n",
    "- final coastal watershed polygons with attributes:\n",
    "  - `CW_Id` (matching wetland `CW_Id`)\n",
    "  - `WatershedArea_m2`\n",
    "  - watershed centroid coordinates in EPSG:3174 (`WS_cx`, `WS_cy`)\n",
    "  - watershed centroid coordinates in WGS84 (`WS_lon`, `WS_lat`)\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow summary\n",
    "For each inundation scenario (**avg/low/high/surge**):\n",
    "\n",
    "1. **Assign stable IDs**\n",
    "   - Ensure wetland polygons contain `CW_Id` and (optionally) `Coastal_Id` derived from `CW_Id`.\n",
    "\n",
    "2. **Select shoreline-interacting wetlands**\n",
    "   - Project shoreline to EPSG:3174, buffer by **2000 m**, and intersect with wetlands.\n",
    "\n",
    "3. **Remove riparian/stream overlap**\n",
    "   - Buffer streams by **50 m** and erase from the shoreline-interacting wetlands.\n",
    "\n",
    "4. **Create pour points**\n",
    "   - Dissolve wetlands by `CW_Id` and create one **inside point** per wetland (`*_pourpoints.shp`).\n",
    "\n",
    "5. **Snap pour points**\n",
    "   - Snap pour points to the drainage network using **SnapPourPoint** with flow accumulation.\n",
    "\n",
    "6. **Delineate watersheds**\n",
    "   - Use **Watershed** with the D8 flow direction raster and snapped pour points.\n",
    "\n",
    "7. **Convert to polygons + enforce 1 watershed per wetland**\n",
    "   - Convert watershed raster to polygons, set `CW_Id = gridcode`, and **dissolve by `CW_Id`**.\n",
    "\n",
    "8. **Remove non-coastal drainage + lake area**\n",
    "   - Erase stream-watershed polygons, then erase Lake Huron polygon from the watershed polygons.\n",
    "\n",
    "9. **Compute areas + centroids**\n",
    "   - Add watershed area and centroid coordinate fields for later merges and plotting.\n",
    "\n",
    "---\n",
    "\n",
    "## Notes / QA checks recommended\n",
    "- Verify **unique `CW_Id` counts** are consistent:\n",
    "  - riparian-erased wetlands vs. pour points vs. dissolved watershed polygons.\n",
    "- If counts differ, inspect:\n",
    "  - wetlands disappearing due to shoreline/riparian erases,\n",
    "  - pour points falling outside valid drainage (before snapping),\n",
    "  - watersheds splitting (should be fixed by dissolving on `CW_Id`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Requirements\n",
    "\n",
    "- ArcGIS Pro / arcpy with Spatial Analyst.\n",
    "- Flow direction raster (`D8_flow`) and **flow accumulation** raster (`FlowAcc`) on the same grid.\n",
    "- Wetland-connected polygons for each scenario (avg/high/low/surge), each with a stable id field (we standardize to `CW_Id`).\n",
    "\n",
    "**What is `avg_pourpoints.shp`?**  \n",
    "It is a **point feature class** with **one point per wetland** (per `CW_Id`). These points are snapped to the highest flow-accumulation cell nearby, then used as pour points for the Watershed tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import SnapPourPoint, Watershed\n",
    "from arcpy import sa\n",
    "import numpy as np\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "arcpy.env.addOutputsToMap = False  # helps avoid schema locks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Inputs / outputs \n",
    "\n",
    "Fill in your real paths. Keep the same projected CRS as your DEM / flow rasters (often EPSG:3174/3175 for Great Lakes Albers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Inputs\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "inDir = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\"\n",
    "inDCW = r\"D:\\Users\\abolmaal\\data\\coastalwetlands\\finalwetland\"\n",
    "CW_path = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Coastalwetland\\hitshoreline\"\n",
    "\n",
    "wetlands_avg_inun_original   = os.path.join(inDCW, \"wetlands_connected_avg_inundation_GLAlbers.shp\")\n",
    "wetlands_high_inun_original  = os.path.join(inDCW, \"wetlands_connected_high_inundation_GLAlbers.shp\")\n",
    "wetlands_low_inun_original   = os.path.join(inDCW, \"wetlands_connected_low_inundation_GLAlbers.shp\")\n",
    "wetlands_surge_original      = os.path.join(inDCW, \"wetlands_connected_surge_inundation_GLAlbers.shp\")\n",
    "\n",
    "inStreams = os.path.join(inDir, \"GLB_Stream\", \"GLB_stream_Ras_FeatureToLine.shp\")\n",
    "D8_flow   = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_dir.tif\"\n",
    "flowacc = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\"\n",
    "inStreamsWatershed = os.path.join(inDir, \"Streamwatershed\", \"PointWaterdhed_LH.shp\")\n",
    "\n",
    "Lake_Huron = r\"D:\\Users\\abolmaal\\code\\boundry\\hydro_p_LakeHuron\\hydro_p_LakeHuron.shp\"\n",
    "shoreline_shapefile = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\shoreline\\100k\\lh_shore_ESRI_100k_USside.shp\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Parameters / field names\n",
    "# -------------------------------------------------------------------\n",
    "CW_ID_FIELD = \"CW_Id\"          # stable wetland id\n",
    "COASTAL_ID_FIELD = \"Coastal_Id\" # optional (we'll set equal to CW_Id unless you want different)\n",
    "\n",
    "crs_Albers = arcpy.SpatialReference(3174)  # Great Lakes Albers meters\n",
    "crs_WGS84  = arcpy.SpatialReference(4326)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Outputs (your folders)\n",
    "# -------------------------------------------------------------------\n",
    "outDir_stream = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\GLB_Stream\"\n",
    "outBuffer = os.path.join(outDir_stream, \"GLB_stream_Ras_FeatureToLine_50m.shp\")\n",
    "\n",
    "outpath = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\"\n",
    "outErase_Riper   = os.path.join(outpath, \"Erase_Riperian\")\n",
    "outErase_drainage= os.path.join(outpath, \"Erase_drainage\")\n",
    "outErase_Lake    = os.path.join(outpath, \"Erase_lake\")\n",
    "outPourpoints    = os.path.join(outpath, \"Pourpoints\")\n",
    "outWatersheds    = os.path.join(outpath, \"Watershed_rasters\")\n",
    "\n",
    "for d in [outDir_stream, outErase_Riper, outErase_drainage, outErase_Lake, outPourpoints, outWatersheds]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "shorebuffer = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\shoreline\\100k\\lh_shore_ESRI_100k_USside_2000buffer.shp\"\n",
    "\n",
    "wetlands_avg_inun  = os.path.join(CW_path, \"Wetland_connected_avg_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "wetlands_low_inun  = os.path.join(CW_path, \"Wetland_connected_low_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "wetlands_high_inun = os.path.join(CW_path, \"Wetland_connected_high_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "wetlands_surge     = os.path.join(CW_path, \"Wetland_connected_surge_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "\n",
    "erase_buffer_avg   = os.path.join(outErase_Riper, \"Wetland_connected_avg_erasebuff_50.shp\")\n",
    "erase_buffer_high  = os.path.join(outErase_Riper, \"Wetland_connected_high_erasebuff_50.shp\")\n",
    "erase_buffer_low   = os.path.join(outErase_Riper, \"Wetland_connected_low_erasebuff_50.shp\")\n",
    "erase_buffer_surge = os.path.join(outErase_Riper, \"Wetland_connected_surge_erasebuff_50.shp\")\n",
    "\n",
    "CoastalWatershed_avg_erase_lakedrain  = os.path.join(outErase_drainage, \"CoastalWatershed_avg_erase_lakedrain.shp\")\n",
    "CoastalWatershed_high_erase_lakedrain = os.path.join(outErase_drainage, \"CoastalWatershed_high_erase_lakedrain.shp\")\n",
    "CoastalWatershed_low_erase_lakedrain  = os.path.join(outErase_drainage, \"CoastalWatershed_low_erase_lakedrain.shp\")\n",
    "CoastalWatershed_surge_erase_lakedrain= os.path.join(outErase_drainage, \"CoastalWatershed_surge_erase_lakedrain.shp\")\n",
    "\n",
    "CoastalWatershed_avg_erase_lakedrain_LakeHuron   = os.path.join(outErase_Lake, \"CoastalWatershed_avg_erase_lakedrain_LakeHuron.shp\")\n",
    "CoastalWatershed_high_erase_lakedrain_LakeHuron  = os.path.join(outErase_Lake, \"CoastalWatershed_high_erase_lakedrain_LakeHuron.shp\")\n",
    "CoastalWatershed_low_erase_lakedrain_LakeHuron   = os.path.join(outErase_Lake, \"CoastalWatershed_low_erase_lakedrain_LakeHuron.shp\")\n",
    "CoastalWatershed_surge_erase_lakedrain_LakeHuron = os.path.join(outErase_Lake, \"CoastalWatershed_surge_erase_lakedrain_LakeHuron.shp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Helper functions\n",
    "\n",
    "These helpers:\n",
    "\n",
    "- enforce a stable `CW_Id`\n",
    "- create **one** pour point per `CW_Id`\n",
    "- snap pour points to high flow accumulation\n",
    "- run watershed (raster) and convert back to polygons while preserving ids\n",
    "- compute areas + WGS84 centroid lat/lon\n",
    "- run sanity checks for missing ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# -------------------------------------------------------------------\n",
    "def ensure_field(fc, name, ftype=\"DOUBLE\"):\n",
    "    # Shapefile limit: 10 chars\n",
    "    if arcpy.Describe(fc).dataType == \"ShapeFile\" and len(name) > 10:\n",
    "        short = name[:10]\n",
    "        print(f\"⚠️ Shapefile field '{name}' too long -> using '{short}'\")\n",
    "        name = short\n",
    "\n",
    "    fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "    if name not in fields:\n",
    "        arcpy.management.AddField(fc, name, ftype)\n",
    "    return name\n",
    "\n",
    "def calculate_area_m2(fc, out_field):\n",
    "    out_field = ensure_field(fc, out_field, \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "        fc, [[out_field, \"AREA\"]], area_unit=\"SQUARE_METERS\"\n",
    "    )\n",
    "    return out_field\n",
    "\n",
    "def add_xy_ll(fc, prefix, src_crs=crs_Albers):\n",
    "    \"\"\"\n",
    "    Adds:\n",
    "      {prefix}_cx, {prefix}_cy  (in src_crs units, meters for 3174)\n",
    "      {prefix}_lon, {prefix}_lat (in WGS84 DD)\n",
    "    \"\"\"\n",
    "    ensure_field(fc, f\"{prefix}_cx\", \"DOUBLE\")\n",
    "    ensure_field(fc, f\"{prefix}_cy\", \"DOUBLE\")\n",
    "    arcpy.management.CalculateField(fc, f\"{prefix}_cx\", \"!SHAPE.centroid.X!\", \"PYTHON3\")\n",
    "    arcpy.management.CalculateField(fc, f\"{prefix}_cy\", \"!SHAPE.centroid.Y!\", \"PYTHON3\")\n",
    "\n",
    "    ensure_field(fc, f\"{prefix}_lon\", \"DOUBLE\")\n",
    "    ensure_field(fc, f\"{prefix}_lat\", \"DOUBLE\")\n",
    "    # CalculateGeometryAttributes supports centroid in a specified coordinate system\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "        fc,\n",
    "        [[f\"{prefix}_lat\", \"CENTROID_Y\"], [f\"{prefix}_lon\", \"CENTROID_X\"]],\n",
    "        coordinate_system=crs_WGS84,\n",
    "        coordinate_format=\"DD\"\n",
    "    )\n",
    "\n",
    "def count_ids(fc, id_field):\n",
    "    ids = set()\n",
    "    with arcpy.da.SearchCursor(fc, [id_field]) as cur:\n",
    "        for (v,) in cur:\n",
    "            if v is not None:\n",
    "                ids.add(int(v))\n",
    "    return len(ids)\n",
    "\n",
    "def make_pourpoints(wetlands_fc, out_points_fc, id_field=CW_ID_FIELD):\n",
    "    \"\"\"\n",
    "    1) Dissolve by CW_Id -> single multipart per CW_Id\n",
    "    2) FeatureToPoint INSIDE -> 1 point per CW_Id\n",
    "    \"\"\"\n",
    "    tmp_diss = os.path.join(\"in_memory\", \"tmp_diss\")\n",
    "    if arcpy.Exists(tmp_diss):\n",
    "        arcpy.management.Delete(tmp_diss)\n",
    "\n",
    "    arcpy.management.Dissolve(wetlands_fc, tmp_diss, dissolve_field=id_field)\n",
    "    arcpy.management.FeatureToPoint(tmp_diss, out_points_fc, \"INSIDE\")\n",
    "    arcpy.management.Delete(tmp_diss)\n",
    "\n",
    "def snap_pourpoints(in_points, flowacc_raster, out_points, snap_dist=\"200 Meters\"):\n",
    "    \"\"\"\n",
    "    SnapPourPoint expects a flow accumulation raster.\n",
    "    \"\"\"\n",
    "    out_ras = os.path.join(\"in_memory\", \"snapped_pp_ras\")\n",
    "    if arcpy.Exists(out_ras):\n",
    "        arcpy.management.Delete(out_ras)\n",
    "\n",
    "    # SnapPourPoint returns a raster. We'll convert to points with value preserved.\n",
    "    snapped = arcpy.sa.SnapPourPoint(in_points, flowacc_raster, snap_dist, CW_ID_FIELD)\n",
    "    snapped.save(out_ras)\n",
    "\n",
    "    # RasterToPoint creates points with \"grid_code\"\n",
    "    arcpy.conversion.RasterToPoint(out_ras, out_points, \"VALUE\")\n",
    "\n",
    "    # Move snapped raster value -> CW_Id\n",
    "    ensure_field(out_points, CW_ID_FIELD, \"LONG\")\n",
    "    arcpy.management.CalculateField(out_points, CW_ID_FIELD, \"!grid_code!\", \"PYTHON3\")\n",
    "    arcpy.management.Delete(out_ras)\n",
    "\n",
    "def watershed_from_points(flowdir, snapped_points, out_watershed_raster):\n",
    "    \"\"\"\n",
    "    Watershed raster values will equal CW_Id (because we pass CW_Id field).\n",
    "    \"\"\"\n",
    "    ws = arcpy.sa.Watershed(flowdir, snapped_points, CW_ID_FIELD)\n",
    "    ws.save(out_watershed_raster)\n",
    "\n",
    "def watershed_raster_to_polygon(ws_raster, out_poly, id_field=CW_ID_FIELD):\n",
    "    \"\"\"\n",
    "    RasterToPolygon -> gridcode. Then set CW_Id=gridcode and dissolve by CW_Id.\n",
    "    \"\"\"\n",
    "    tmp_poly = os.path.join(\"in_memory\", \"tmp_ws_poly\")\n",
    "    if arcpy.Exists(tmp_poly):\n",
    "        arcpy.management.Delete(tmp_poly)\n",
    "\n",
    "    arcpy.conversion.RasterToPolygon(ws_raster, tmp_poly, \"NO_SIMPLIFY\", \"VALUE\")\n",
    "\n",
    "    # Make sure CW_Id exists and equals gridcode\n",
    "    ensure_field(tmp_poly, id_field, \"LONG\")\n",
    "    arcpy.management.CalculateField(tmp_poly, id_field, \"!gridcode!\", \"PYTHON3\")\n",
    "\n",
    "    # Dissolve to one watershed polygon per CW_Id (removes splits)\n",
    "    arcpy.management.Dissolve(tmp_poly, out_poly, dissolve_field=id_field)\n",
    "\n",
    "    arcpy.management.Delete(tmp_poly)\n",
    "    \n",
    "def watershed_from_snapped_raster(flowdir, snapped_ras, out_watershed_raster):\n",
    "    \"\"\"\n",
    "    snapped_ras is the output of SnapPourPoint (a raster with CW_Id values).\n",
    "    Watershed output raster will keep those CW_Id values.\n",
    "    \"\"\"\n",
    "    ws = arcpy.sa.Watershed(flowdir, snapped_ras)\n",
    "    ws.save(out_watershed_raster)\n",
    "    \n",
    "    \n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _ensure_field(fc, field_name, field_type=\"LONG\"):\n",
    "    fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "    if field_name not in fields:\n",
    "        arcpy.management.AddField(fc, field_name, field_type)\n",
    "\n",
    "def unique_snap_points_to_flowacc_cells(\n",
    "    in_points_fc,\n",
    "    id_field,\n",
    "    flowacc_raster,\n",
    "    snap_dist,\n",
    "    out_points_fc,\n",
    "    max_expand_steps=3,\n",
    "    expand_factor=1.5,\n",
    "    allow_nodata=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a snapped points FC where each input point is moved to a UNIQUE raster cell\n",
    "    chosen as the highest flow accumulation cell within snap_dist (expanded if needed).\n",
    "    This guarantees 1 unique snapped cell per input ID (unless there aren't enough cells).\n",
    "    \"\"\"\n",
    "\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    r = arcpy.Raster(flowacc_raster)\n",
    "    sr = r.spatialReference\n",
    "    cellw = float(r.meanCellWidth)\n",
    "    cellh = float(r.meanCellHeight)\n",
    "    ext = r.extent\n",
    "    xmin, ymin, xmax, ymax = ext.XMin, ext.YMin, ext.XMax, ext.YMax\n",
    "\n",
    "    # Determine raster size in cells (approx, but enough for indexing)\n",
    "    ncol = int(round((xmax - xmin) / cellw))\n",
    "    nrow = int(round((ymax - ymin) / cellh))\n",
    "\n",
    "    # Create output FC\n",
    "    out_dir = os.path.dirname(out_points_fc)\n",
    "    out_name = os.path.basename(out_points_fc)\n",
    "    if arcpy.Exists(out_points_fc):\n",
    "        arcpy.management.Delete(out_points_fc)\n",
    "\n",
    "    arcpy.management.CreateFeatureclass(\n",
    "        out_dir, out_name, \"POINT\", spatial_reference=sr\n",
    "    )\n",
    "    _ensure_field(out_points_fc, id_field, \"LONG\")\n",
    "\n",
    "    # Build a quick index of all input points\n",
    "    pts = []\n",
    "    with arcpy.da.SearchCursor(in_points_fc, [\"SHAPE@XY\", id_field]) as cur:\n",
    "        for (x, y), cid in cur:\n",
    "            if cid is None:\n",
    "                continue\n",
    "            pts.append((float(x), float(y), int(cid)))\n",
    "\n",
    "    used_cells = set()  # (row_top, col)\n",
    "\n",
    "    def xy_to_rowcol_top(x, y):\n",
    "        col = int((x - xmin) / cellw)\n",
    "        row_top = int((ymax - y) / cellh)\n",
    "        return row_top, col\n",
    "\n",
    "    def rowcol_top_to_cellcenter(row_top, col):\n",
    "        x = xmin + (col + 0.5) * cellw\n",
    "        y = ymax - (row_top + 0.5) * cellh\n",
    "        return x, y\n",
    "\n",
    "    def window_to_numpy(row_top, col, rad_cells):\n",
    "        # clamp window bounds in raster indices\n",
    "        r0 = max(0, row_top - rad_cells)\n",
    "        r1 = min(nrow - 1, row_top + rad_cells)\n",
    "        c0 = max(0, col - rad_cells)\n",
    "        c1 = min(ncol - 1, col + rad_cells)\n",
    "\n",
    "        # lower-left corner of the window in map units\n",
    "        x_ll = xmin + c0 * cellw\n",
    "        y_ll = ymax - (r1 + 1) * cellh\n",
    "\n",
    "        nrows = (r1 - r0 + 1)\n",
    "        ncols = (c1 - c0 + 1)\n",
    "\n",
    "        # IMPORTANT: integer rasters can't use NaN for nodata_to_value\n",
    "        nodata_sentinel = -9999\n",
    "\n",
    "        arr = arcpy.RasterToNumPyArray(\n",
    "            r,\n",
    "            lower_left_corner=arcpy.Point(x_ll, y_ll),\n",
    "            ncols=ncols,\n",
    "            nrows=nrows,\n",
    "            nodata_to_value=nodata_sentinel\n",
    "        )\n",
    "\n",
    "        # convert to float and set sentinel to NaN\n",
    "        arr = arr.astype(\"float64\")\n",
    "        arr[arr == nodata_sentinel] = np.nan\n",
    "\n",
    "        return arr, (r0, r1, c0, c1)\n",
    "\n",
    "    def pick_best_unused_cell(arr, bounds):\n",
    "        r0, r1, c0, c1 = bounds\n",
    "        nrows, ncols = arr.shape\n",
    "\n",
    "        # Flatten and sort by flowacc descending (nan ignored)\n",
    "        flat = arr.ravel()\n",
    "        valid_idx = np.where(np.isfinite(flat))[0]\n",
    "        if valid_idx.size == 0:\n",
    "            return None\n",
    "\n",
    "        order = valid_idx[np.argsort(flat[valid_idx])[::-1]]\n",
    "\n",
    "        for k in order:\n",
    "            i = k // ncols   # array row index (0=bottom)\n",
    "            j = k % ncols\n",
    "\n",
    "            # convert (i,j) -> global raster (row_top, col)\n",
    "            row_top = r1 - i\n",
    "            col = c0 + j\n",
    "\n",
    "            if (row_top, col) in used_cells:\n",
    "                continue\n",
    "\n",
    "            # if you want to forbid snapping into nodata/invalid, array already NaN-handled\n",
    "            return row_top, col, float(arr[i, j])\n",
    "\n",
    "        return None\n",
    "\n",
    "    missing = []\n",
    "\n",
    "    with arcpy.da.InsertCursor(out_points_fc, [\"SHAPE@XY\", id_field]) as icur:\n",
    "        for x, y, cid in pts:\n",
    "            row_top, col = xy_to_rowcol_top(x, y)\n",
    "\n",
    "            # start radius in cells\n",
    "            base_rad = int(np.ceil(snap_dist / cellw))\n",
    "\n",
    "            chosen = None\n",
    "            rad = base_rad\n",
    "\n",
    "            for step in range(max_expand_steps + 1):\n",
    "                arr, bounds = window_to_numpy(row_top, col, rad)\n",
    "                chosen = pick_best_unused_cell(arr, bounds)\n",
    "                if chosen is not None:\n",
    "                    break\n",
    "                rad = int(np.ceil(rad * expand_factor))\n",
    "\n",
    "            if chosen is None:\n",
    "                missing.append(cid)\n",
    "                continue\n",
    "\n",
    "            rtop, c, val = chosen\n",
    "            used_cells.add((rtop, c))\n",
    "\n",
    "            sx, sy = rowcol_top_to_cellcenter(rtop, c)\n",
    "            icur.insertRow(((sx, sy), cid))\n",
    "\n",
    "    print(f\"✅ unique snapped points created: {len(pts) - len(missing)} / {len(pts)}\")\n",
    "    if missing:\n",
    "        print(f\"⚠️ Could not snap {len(missing)} points (no valid unused cells found). Example IDs: {missing[:10]}\")\n",
    "    return out_points_fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 0) Add stable CW_Id to ORIGINAL wetlands (IMPORTANT FIX)\n",
    "#    Use existing \"Id\" if present; else fallback to OBJECTID/FID.\n",
    "# ------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ensured CW_Id on: wetlands_connected_avg_inundation_GLAlbers.shp\n",
      "✅ ensured CW_Id on: wetlands_connected_high_inundation_GLAlbers.shp\n",
      "✅ ensured CW_Id on: wetlands_connected_low_inundation_GLAlbers.shp\n",
      "✅ ensured CW_Id on: wetlands_connected_surge_inundation_GLAlbers.shp\n"
     ]
    }
   ],
   "source": [
    "wetlands_fcs = [\n",
    "    wetlands_avg_inun_original,\n",
    "    wetlands_high_inun_original,\n",
    "    wetlands_low_inun_original,\n",
    "    wetlands_surge_original,\n",
    "]\n",
    "\n",
    "for fc in wetlands_fcs:\n",
    "    fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "    ensure_field(fc, CW_ID_FIELD, \"LONG\")\n",
    "    ensure_field(fc, COASTAL_ID_FIELD, \"LONG\")\n",
    "\n",
    "    if \"Id\" in fields:\n",
    "        # Stable: CW_Id = Id\n",
    "        arcpy.management.CalculateField(fc, CW_ID_FIELD, \"!Id!\", \"PYTHON3\")\n",
    "        arcpy.management.CalculateField(fc, COASTAL_ID_FIELD, \"!Id!\", \"PYTHON3\")\n",
    "    else:\n",
    "        # Fallback: CW_Id = OBJECTID\n",
    "        oid = arcpy.Describe(fc).OIDFieldName\n",
    "        arcpy.management.CalculateField(fc, CW_ID_FIELD, f\"!{oid}!\", \"PYTHON3\")\n",
    "        arcpy.management.CalculateField(fc, COASTAL_ID_FIELD, f\"!{oid}!\", \"PYTHON3\")\n",
    "\n",
    "    print(f\"✅ ensured CW_Id on: {os.path.basename(fc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89701f25",
   "metadata": {},
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Shoreline buffer (2000m) in EPSG:3174\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6911cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Wednesday, January 14, 2026 10:01:00 AM<br>Succeeded at Wednesday, January 14, 2026 10:01:00 AM (Elapsed Time: 0.01 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoreline_3174 = os.path.join(\"in_memory\", \"shoreline_3174\")\n",
    "arcpy.management.Project(shoreline_shapefile, shoreline_3174, crs_Albers)\n",
    "\n",
    "if not arcpy.Exists(shorebuffer):\n",
    "    arcpy.analysis.Buffer(shoreline_3174, shorebuffer, \"2000 Meters\", dissolve_option=\"ALL\")\n",
    "\n",
    "arcpy.management.Delete(shoreline_3174)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b52293",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 2) Intersect wetlands with shoreline buffer (keeps CW_Id)\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1a69ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ shoreline-intersect: Wetland_connected_avg_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\n",
      "✅ shoreline-intersect: Wetland_connected_low_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\n",
      "✅ shoreline-intersect: Wetland_connected_high_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\n",
      "✅ shoreline-intersect: Wetland_connected_surge_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\n"
     ]
    }
   ],
   "source": [
    "cw_pairs = [\n",
    "    (wetlands_avg_inun_original,  wetlands_avg_inun),\n",
    "    (wetlands_low_inun_original,  wetlands_low_inun),\n",
    "    (wetlands_high_inun_original, wetlands_high_inun),\n",
    "    (wetlands_surge_original,     wetlands_surge),\n",
    "]\n",
    "\n",
    "for in_fc, out_fc in cw_pairs:\n",
    "    # project wetlands to 3174\n",
    "    tmp_3174 = os.path.join(\"in_memory\", \"cw_3174\")\n",
    "    arcpy.management.Project(in_fc, tmp_3174, crs_Albers)\n",
    "\n",
    "    tmp_int = os.path.join(\"in_memory\", \"cw_int\")\n",
    "    arcpy.analysis.Intersect([tmp_3174, shorebuffer], tmp_int, \"ALL\")\n",
    "\n",
    "    # Save in 3174 (recommended). If you really need original CRS, project back here.\n",
    "    arcpy.management.CopyFeatures(tmp_int, out_fc)\n",
    "\n",
    "    arcpy.management.Delete(tmp_3174)\n",
    "    arcpy.management.Delete(tmp_int)\n",
    "\n",
    "    print(f\"✅ shoreline-intersect: {os.path.basename(out_fc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cb190",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 3) Stream riparian buffer 50 m + erase wetlands (keeps CW_Id)\n",
    "- Create a 50 meter buffer for Great lakes basin streams (This is riverin Riperian area)\n",
    "-  Erase your coastal wetlands that overlap with Riperian area(GLB streams)\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf2392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ wetland attrs added: Wetland_connected_avg_erasebuff_50.shp\n",
      "✅ wetland attrs added: Wetland_connected_high_erasebuff_50.shp\n",
      "✅ wetland attrs added: Wetland_connected_low_erasebuff_50.shp\n",
      "✅ wetland attrs added: Wetland_connected_surge_erasebuff_50.shp\n"
     ]
    }
   ],
   "source": [
    "if not arcpy.Exists(outBuffer):\n",
    "    arcpy.analysis.Buffer(inStreams, outBuffer, \"50 Meters\")\n",
    "\n",
    "arcpy.analysis.Erase(wetlands_avg_inun,  outBuffer, erase_buffer_avg)\n",
    "arcpy.analysis.Erase(wetlands_high_inun, outBuffer, erase_buffer_high)\n",
    "arcpy.analysis.Erase(wetlands_low_inun,  outBuffer, erase_buffer_low)\n",
    "arcpy.analysis.Erase(wetlands_surge,     outBuffer, erase_buffer_surge)\n",
    "\n",
    "arcpy.management.ClearWorkspaceCache()\n",
    "# add wetland areas and coordinates\n",
    "for fc in [erase_buffer_avg, erase_buffer_high, erase_buffer_low, erase_buffer_surge]:\n",
    "    # shorter name for SHP + avoids long names anyway\n",
    "    calculate_area_m2(fc, \"CW_Area_m2\")     # if this is SHP it's OK (<10 chars)\n",
    "    add_xy_ll(fc, prefix=\"CW\")\n",
    "    print(f\"✅ wetland attrs added: {os.path.basename(fc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585762f2",
   "metadata": {},
   "source": [
    "## Step 4 — Create **1:1 Coastal-Wetland Watersheds** (Pourpoints → Snap → Watershed → Polygons → **Clip overlaps** → **Repair missing IDs**)\n",
    "\n",
    "This cell delineates **one coastal watershed per coastal wetland (`CW_Id`)** for each inundation category (**avg/high/low/surge**), while ensuring the identifier **`CW_Id` remains 1:1** throughout the workflow.\n",
    "\n",
    "Unlike earlier versions that could *drop entire IDs* when wetlands were in-lake or when watersheds overlapped stream-drainage areas, this updated workflow:\n",
    "\n",
    "* **keeps every `CW_Id`**, even if the wetland is partially/fully in the lake,\n",
    "* **clips out only the overlapping portions** (lake interior and stream-watershed overlap),\n",
    "* and **repairs** missing IDs caused by raster snapping collisions by rebuilding only the missing IDs one-by-one.\n",
    "\n",
    "It is also designed to avoid common ArcPy issues (schema locks, field-name limits in shapefiles, field-case mismatches, and SnapPourPoint ID collapsing).\n",
    "\n",
    "---\n",
    "\n",
    "### What this cell produces (per inundation category: avg/high/low/surge)\n",
    "\n",
    "For each category, the cell creates:\n",
    "\n",
    "* **Pourpoints (GDB feature class)**: one point per `CW_Id` (land-only + fallback for lake-only IDs)\n",
    "* **Snapped pourpoints (GDB feature class)**: snapped onto high-flowacc land cells (using `flowacc_land`)\n",
    "* **Watershed raster (GDB raster)**: watershed labels equal to `CW_Id`\n",
    "* **Watershed polygons (GDB feature class)**: raster converted to polygons and dissolved to **one polygon per `CW_Id`**\n",
    "* **Clipped watershed polygons (final)**: only the portions overlapping:\n",
    "\n",
    "  * **Lake Huron interior**, and\n",
    "  * **stream-watershed mask**\n",
    "    are removed (the rest of the polygon is preserved)\n",
    "* **Repaired final outputs (shapefiles)**:\n",
    "\n",
    "  * `*_erase_lakedrain_LakeHuron.shp` (one feature per `CW_Id`, after clip + repair)\n",
    "* **Final attributes added to the final shapefile** (when possible):\n",
    "\n",
    "  * `WS_AREAM2` = watershed area (m²)\n",
    "  * `WS_cx`, `WS_cy` = centroid X/Y in dataset CRS\n",
    "  * `WS_lon`, `WS_lat` = centroid lon/lat in WGS84\n",
    "\n",
    "---\n",
    "\n",
    "### Why “pourpoints” matter\n",
    "\n",
    "A **pour point** is the location Spatial Analyst uses to define **which upstream cells contribute** to that outlet.\n",
    "Here, each wetland gets **exactly one pourpoint per `CW_Id`**, which drives the “one watershed per wetland” requirement.\n",
    "\n",
    "---\n",
    "\n",
    "### Updated snapping logic (and why it differs from the older “unique snap” approach)\n",
    "\n",
    "Previously, strict uniqueness snapping (one raster cell per point) was used to prevent ID collisions. In practice, nearshore lake-only wetlands can still collide at shoreline cells and/or fail to reach land.\n",
    "\n",
    "This updated workflow uses a **two-stage strategy**:\n",
    "\n",
    "1. **Bulk snapping** (fast): uses SnapPourPoint on a land-only flowacc surface (`flowacc_land`)\n",
    "2. **Repair pass** (precise): if any `CW_Id` is missing after delineation + clipping, rebuild just those IDs **one-by-one** to eliminate raster collisions.\n",
    "\n",
    "This preserves performance (bulk) while guaranteeing completeness (repair).\n",
    "\n",
    "---\n",
    "\n",
    "### Core processing steps inside the loop (per category)\n",
    "\n",
    "#### 0) Environment + workspaces (no C:\\ temp writes)\n",
    "\n",
    "* All intermediates are written to:\n",
    "\n",
    "  * `watersheds.gdb` (under `outWatersheds`)\n",
    "  * `pourpoints.gdb` (under `outPourpoints`)\n",
    "* Processing is aligned to the D8 grid:\n",
    "\n",
    "  * `snapRaster = D8_flow`\n",
    "  * `extent = D8_flow`\n",
    "  * `cellSize = D8_flow`\n",
    "  * `outputCoordinateSystem = D8_SR`\n",
    "\n",
    "---\n",
    "\n",
    "#### 1) Build masks once (outside the loop)\n",
    "\n",
    "* **Stream-watershed mask**\n",
    "\n",
    "  * CRS fixed if mislabeled, geometry repaired, dissolved, and (optionally) buffered slightly\n",
    "* **Lake Huron polygon**\n",
    "\n",
    "  * CRS corrected and projected to D8 CRS\n",
    "* **Land-only flowacc surface**\n",
    "\n",
    "  * `flowacc_land = flowacc` with lake cells set to NoData\n",
    "  * ensures snapping targets land cells only\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) Prepare wetlands and authoritative CW_Id list\n",
    "\n",
    "* Wetlands are projected to D8 CRS and repaired\n",
    "* **Original wetlands dissolved by `CW_Id`** to guarantee:\n",
    "\n",
    "  * one feature per ID\n",
    "  * a definitive list of all IDs that must exist in the final output\n",
    "\n",
    "✅ Output: `{cat}_wet_orig_diss` (GDB)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) Create pourpoints (one per CW_Id, including lake-only)\n",
    "\n",
    "* Create **land-only wetlands** by erasing the lake, then dissolve by `CW_Id`\n",
    "* Create pourpoints inside land-only dissolved polygons (1 per CW_Id)\n",
    "* Identify **lake-only IDs** (present in original dissolve but missing from land-only dissolve)\n",
    "* Create fallback pourpoints for lake-only IDs using the **original dissolved** polygons\n",
    "* Append fallback points into the pourpoint set\n",
    "\n",
    "✅ Output: `{cat}_pp_inside` (GDB; 1 point per CW_Id target)\n",
    "\n",
    "---\n",
    "\n",
    "#### 4) Snap pourpoints to land-only high-flowacc cells (bulk)\n",
    "\n",
    "* Convert pourpoints to raster (VALUE = `CW_Id`)\n",
    "* Snap via:\n",
    "\n",
    "  * `SnapPourPoint(pour_raster, flowacc_land, snap_dist_m)`\n",
    "* Convert snapped raster back to points and confirm ID coverage\n",
    "\n",
    "✅ Outputs:\n",
    "\n",
    "* `{cat}_pp_snapped_pts`\n",
    "* `{cat}_pp_snap_ras`\n",
    "\n",
    "---\n",
    "\n",
    "#### 5) Delineate watershed raster (VALUE = CW_Id)\n",
    "\n",
    "* `Watershed(D8_flow, snapped_pourpoint_raster)`\n",
    "* Produces a raster where each watershed is labeled by `CW_Id`\n",
    "\n",
    "✅ Output: `{cat}_ws_ras`\n",
    "\n",
    "---\n",
    "\n",
    "#### 6) Raster → polygon + dissolve to one feature per CW_Id\n",
    "\n",
    "* `RasterToPolygon` creates `GRIDCODE`\n",
    "* Compute `CW_Id = GRIDCODE`\n",
    "* Dissolve by `CW_Id` to enforce **one polygon per wetland**\n",
    "\n",
    "✅ Output: `{cat}_ws_poly`\n",
    "\n",
    "---\n",
    "\n",
    "#### 7) Clip overlaps (remove only the overlapping parts)\n",
    "\n",
    "To avoid dropping whole watersheds, lake/stream constraints are applied as **polygon clip operations**, not as raster masks:\n",
    "\n",
    "* Erase **Lake Huron** interior from watershed polygons\n",
    "* Erase **stream-watershed mask** overlap from watershed polygons\n",
    "* Dissolve again by `CW_Id`\n",
    "\n",
    "✅ Output: final category shapefile `CoastalWatershed_{cat}_erase_lakedrain_LakeHuron.shp`\n",
    "\n",
    "---\n",
    "\n",
    "#### 8) Repair missing IDs (guarantee 1:1 output)\n",
    "\n",
    "After clipping, some IDs may still be missing due to:\n",
    "\n",
    "* SnapPourPoint raster collisions (multiple IDs snapped to same cell), or\n",
    "* the clipped result becoming empty for a rare ID\n",
    "\n",
    "Repair strategy:\n",
    "\n",
    "* Compare final `CW_Id`s to the authoritative list (`wet_orig_diss`)\n",
    "* For each missing `CW_Id`:\n",
    "\n",
    "  * rebuild watershed **one-by-one** from its pourpoint (avoids collisions),\n",
    "  * clip lake/stream overlaps,\n",
    "  * append to final output,\n",
    "  * dissolve to enforce one feature per `CW_Id`\n",
    "\n",
    "This step ensures the final output is as close as possible to **1 polygon per wetland ID** while still honoring clipping rules.\n",
    "\n",
    "---\n",
    "\n",
    "### Built-in sanity checks (what to watch in the console)\n",
    "\n",
    "The cell prints (per category):\n",
    "\n",
    "* `unique wetland IDs (original, dissolved)`\n",
    "* `unique snapped pourpoint IDs (target wet_n)`\n",
    "* `watersheds BEFORE clipping unique IDs`\n",
    "* `final watersheds AFTER clip unique IDs`\n",
    "* `Missing IDs after clip`\n",
    "* `final watersheds AFTER rebuild`\n",
    "\n",
    "---\n",
    "\n",
    "### Common adjustments you may want\n",
    "\n",
    "* If many IDs are missing after clip:\n",
    "\n",
    "  * increase `snap_dist_m` (lake-only points may need more distance to reach land)\n",
    "  * reduce stream buffer distance if it removes too much nearshore area\n",
    "* If you get schema lock issues:\n",
    "\n",
    "  * close attribute tables, stop drawing layers, avoid adding outputs to map during run\n",
    "* If the repair step runs long:\n",
    "\n",
    "  * it scales with the number of missing IDs; reducing collision likelihood (snap distance + point density) reduces repair workload\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ac44c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inStreamsWatershed (stream watershed mask)\n",
      "  path: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Streamwatershed\\PointWaterdhed_LH.shp\n",
      "  dataType: ShapeFile\n",
      "  sr: GCS_WGS_1984 | factoryCode=4326 | type=Geographic\n",
      "  linearUnit: \n",
      "  extent: XMin=929846.850, XMax=1166434.867, YMin=651452.122, YMax=1020243.911\n",
      "  hint: extent looks like *projected units* (meters/feet)\n",
      "\n",
      "Lake_Huron (lake mask)\n",
      "  path: D:\\Users\\abolmaal\\code\\boundry\\hydro_p_LakeHuron\\hydro_p_LakeHuron.shp\n",
      "  dataType: ShapeFile\n",
      "  sr: Geographic | factoryCode=0 | type=Geographic\n",
      "  linearUnit: \n",
      "  extent: XMin=-84.752, XMax=-79.668, YMin=42.996, YMax=46.333\n",
      "  hint: extent looks like *degrees* (likely EPSG:4326 or similar)\n"
     ]
    }
   ],
   "source": [
    "# --- QUICK CRS CHECK (run this before the big cell) ---\n",
    "import arcpy\n",
    "\n",
    "def _sr_str(sr):\n",
    "    if sr is None:\n",
    "        return \"None\"\n",
    "    try:\n",
    "        return f\"{sr.name} | factoryCode={sr.factoryCode} | type={sr.type}\"\n",
    "    except Exception:\n",
    "        return str(sr)\n",
    "\n",
    "def check_crs(fc, name):\n",
    "    d = arcpy.Describe(fc)\n",
    "    sr = getattr(d, \"spatialReference\", None)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  path: {fc}\")\n",
    "    print(f\"  dataType: {d.dataType}\")\n",
    "    print(f\"  sr: {_sr_str(sr)}\")\n",
    "\n",
    "    # Helpful checks\n",
    "    unknown = (sr is None) or (sr.name in [None, \"\", \"Unknown\"])\n",
    "    if unknown:\n",
    "        print(\"  ⚠️ CRS is UNKNOWN (you must DefineProjection before Project).\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"  linearUnit: {sr.linearUnitName}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # extent can hint degrees vs meters\n",
    "    try:\n",
    "        e = d.extent\n",
    "        print(f\"  extent: XMin={e.XMin:.3f}, XMax={e.XMax:.3f}, YMin={e.YMin:.3f}, YMax={e.YMax:.3f}\")\n",
    "        if abs(e.XMin) <= 180 and abs(e.XMax) <= 180 and abs(e.YMin) <= 90 and abs(e.YMax) <= 90:\n",
    "            print(\"  hint: extent looks like *degrees* (likely EPSG:4326 or similar)\")\n",
    "        else:\n",
    "            print(\"  hint: extent looks like *projected units* (meters/feet)\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- run checks ---\n",
    "check_crs(inStreamsWatershed, \"inStreamsWatershed (stream watershed mask)\")\n",
    "check_crs(Lake_Huron,        \"Lake_Huron (lake mask)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c88963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ flowacc: S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\n",
      "✅ workspace: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:207: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:207: SyntaxWarning: invalid escape sequence '\\)'\n",
      "C:\\Users\\abolmaal\\AppData\\Local\\Temp\\ipykernel_36968\\1971050200.py:207: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  All temp writes stay in ws_gdb (no C:\\).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ scratch:   D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n",
      "✅ D8_flow CRS: NAD_1983_Great_Lakes_Basin_Albers (factoryCode=3174)\n",
      "\n",
      "[inStreamsWS] input: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Streamwatershed\\PointWaterdhed_LH.shp\n",
      "[inStreamsWS] sr: GCS_WGS_1984 | factoryCode=4326 | type=Geographic\n",
      "[inStreamsWS] extent: XMin=929846.850 XMax=1166434.867 YMin=651452.122 YMax=1020243.911\n",
      "▶ CopyFeatures inStreamsWS\n",
      "✅ DONE CopyFeatures inStreamsWS (0.01 min)\n",
      "[inStreamsWS] ⚠️ MISLABELED Geographic but coords are projected. SKIP Project; DefineProjection -> NAD_1983_Great_Lakes_Basin_Albers\n",
      "▶ DefineProjection inStreamsWS\n",
      "✅ DONE DefineProjection inStreamsWS (0.00 min)\n",
      "▶ Copy to output inStreamsWS\n",
      "✅ DONE Copy to output inStreamsWS (0.01 min)\n",
      "▶ RepairGeometry stream mask\n",
      "✅ DONE RepairGeometry stream mask (0.00 min)\n",
      "▶ MultipartToSinglepart stream mask\n",
      "✅ DONE MultipartToSinglepart stream mask (0.01 min)\n",
      "▶ Dissolve stream mask\n",
      "✅ DONE Dissolve stream mask (0.01 min)\n",
      "▶ Buffer stream mask\n",
      "✅ DONE Buffer stream mask (0.03 min)\n",
      "\n",
      "[LakeHuron] input: D:\\Users\\abolmaal\\code\\boundry\\hydro_p_LakeHuron\\hydro_p_LakeHuron.shp\n",
      "[LakeHuron] sr: Geographic | factoryCode=0 | type=Geographic\n",
      "[LakeHuron] extent: XMin=-84.752 XMax=-79.668 YMin=42.996 YMax=46.333\n",
      "▶ CopyFeatures LakeHuron\n",
      "✅ DONE CopyFeatures LakeHuron (0.01 min)\n",
      "[LakeHuron] ⚠️ GENERIC geographic degrees. DefineProjection -> EPSG:4326 then Project.\n",
      "▶ DefineProjection LakeHuron\n",
      "✅ DONE DefineProjection LakeHuron (0.00 min)\n",
      "[LakeHuron] Project -> NAD_1983_Great_Lakes_Basin_Albers | transform=WGS_1984_(ITRF00)_To_NAD_1983\n",
      "▶ Project LakeHuron\n",
      "✅ DONE Project LakeHuron (0.01 min)\n",
      "▶ RepairGeometry lake\n",
      "✅ DONE RepairGeometry lake (0.00 min)\n",
      "▶ PolygonToRaster LakeHuron_mask_ras\n",
      "✅ DONE PolygonToRaster LakeHuron_mask_ras (0.14 min)\n",
      "✅ lake_mask_ras: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\\LakeHuron_mask_ras\n",
      "▶ Build flowacc_land = flowacc where NOT lake\n",
      "✅ flowacc_land: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\\flowacc_land\n",
      "\n",
      "==================== HIGH ====================\n",
      "▶ [high] Project wetlands\n",
      "✅ DONE [high] Project wetlands (0.01 min)\n",
      "▶ [high] RepairGeometry wetlands\n",
      "✅ DONE [high] RepairGeometry wetlands (0.08 min)\n",
      "▶ [high] Dissolve ORIGINAL wetlands by CW_Id\n",
      "✅ DONE [high] Dissolve ORIGINAL wetlands by CW_Id (0.06 min)\n",
      "[high] unique wetland IDs (original, dissolved): 12135\n",
      "▶ [high] Erase lake from wetlands (land-only)\n",
      "✅ DONE [high] Erase lake from wetlands (land-only) (0.03 min)\n",
      "▶ [high] Dissolve land-only wetlands by CW_Id\n",
      "✅ DONE [high] Dissolve land-only wetlands by CW_Id (0.04 min)\n",
      "[high] unique wetland IDs (land-only, dissolved): 7570\n",
      "▶ [high] FeatureToPoint INSIDE (land-only dissolved)\n",
      "✅ DONE [high] FeatureToPoint INSIDE (land-only dissolved) (0.01 min)\n",
      "⚠️ [high] 4565 wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\n",
      "▶ [high missing] Copy selected\n",
      "✅ DONE [high missing] Copy selected (0.01 min)\n",
      "▶ [high] FeatureToPoint INSIDE (fallback dissolved)\n",
      "✅ DONE [high] FeatureToPoint INSIDE (fallback dissolved) (0.01 min)\n",
      "▶ [high] Append fallback points\n",
      "✅ DONE [high] Append fallback points (0.01 min)\n",
      "▶ [high] PointToRaster pourpoints\n",
      "✅ DONE [high] PointToRaster pourpoints (0.16 min)\n",
      "[high] SnapPourPoint distance = 150 m (land-only)\n",
      "▶ [high] RasterToPoint snapped pourpoints\n",
      "✅ DONE [high] RasterToPoint snapped pourpoints (0.09 min)\n",
      "▶ [high] Calculate CW_Id on snapped points\n",
      "✅ DONE [high] Calculate CW_Id on snapped points (0.01 min)\n",
      "[high] unique snapped pourpoint IDs: 11630 (target 12135)\n",
      "▶ [high] PointToRaster snapped points\n",
      "✅ DONE [high] PointToRaster snapped points (0.15 min)\n",
      "▶ [high] Watershed\n",
      "✅ DONE [high] Watershed (0.87 min)\n",
      "▶ [high] RasterToPolygon\n",
      "✅ DONE [high] RasterToPolygon (0.14 min)\n",
      "▶ [high] Calculate CW_Id on watershed polygons\n",
      "✅ DONE [high] Calculate CW_Id on watershed polygons (0.01 min)\n",
      "▶ [high] Dissolve watersheds by CW_Id\n",
      "✅ DONE [high] Dissolve watersheds by CW_Id (0.11 min)\n",
      "[high] watersheds BEFORE clipping unique IDs: 11630 (target 12135)\n",
      "▶ [high] Erase lake from watersheds (clip)\n",
      "✅ DONE [high] Erase lake from watersheds (clip) (0.03 min)\n",
      "▶ [high] Erase stream mask from watersheds (clip)\n",
      "✅ DONE [high] Erase stream mask from watersheds (clip) (0.01 min)\n",
      "▶ [high] Dissolve final output (clip result)\n",
      "✅ DONE [high] Dissolve final output (clip result) (0.04 min)\n",
      "[high] final watersheds AFTER clip unique IDs: 8412 (target 12135)\n",
      "[high] Missing IDs after clip: 3723\n",
      "▶ [high] Copy missing pourpoints\n",
      "✅ DONE [high] Copy missing pourpoints (0.01 min)\n",
      "▶ [high] Near(missing pts -> final watersheds)\n",
      "✅ DONE [high] Near(missing pts -> final watersheds) (0.02 min)\n",
      "▶ [high] Create assigned FC\n",
      "✅ DONE [high] Create assigned FC (0.01 min)\n",
      "[high] Assigned polygons added: 3723\n",
      "▶ [high] Append assigned -> final\n",
      "✅ DONE [high] Append assigned -> final (0.01 min)\n",
      "▶ [high] PairwiseDissolve (enforce 1 per CW_Id)\n",
      "✅ DONE [high] PairwiseDissolve (enforce 1 per CW_Id) (0.02 min)\n",
      "▶ [high] Copy enforced final\n",
      "✅ DONE [high] Copy enforced final (0.03 min)\n",
      "[high] final watersheds AFTER assignment-repair: 12135 (target 12135)\n",
      "✅ final watershed: high -> CoastalWatershed_high_erase_lakedrain_LakeHuron.shp\n",
      "\n",
      "==================== LOW ====================\n",
      "▶ [low] Project wetlands\n",
      "✅ DONE [low] Project wetlands (0.01 min)\n",
      "▶ [low] RepairGeometry wetlands\n",
      "✅ DONE [low] RepairGeometry wetlands (0.03 min)\n",
      "▶ [low] Dissolve ORIGINAL wetlands by CW_Id\n",
      "✅ DONE [low] Dissolve ORIGINAL wetlands by CW_Id (0.02 min)\n",
      "[low] unique wetland IDs (original, dissolved): 4500\n",
      "▶ [low] Erase lake from wetlands (land-only)\n",
      "✅ DONE [low] Erase lake from wetlands (land-only) (0.02 min)\n",
      "▶ [low] Dissolve land-only wetlands by CW_Id\n",
      "✅ DONE [low] Dissolve land-only wetlands by CW_Id (0.01 min)\n",
      "[low] unique wetland IDs (land-only, dissolved): 1696\n",
      "▶ [low] FeatureToPoint INSIDE (land-only dissolved)\n",
      "✅ DONE [low] FeatureToPoint INSIDE (land-only dissolved) (0.01 min)\n",
      "⚠️ [low] 2804 wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\n",
      "▶ [low missing] Copy selected\n",
      "✅ DONE [low missing] Copy selected (0.01 min)\n",
      "▶ [low] FeatureToPoint INSIDE (fallback dissolved)\n",
      "✅ DONE [low] FeatureToPoint INSIDE (fallback dissolved) (0.01 min)\n",
      "▶ [low] Append fallback points\n",
      "✅ DONE [low] Append fallback points (0.00 min)\n",
      "▶ [low] PointToRaster pourpoints\n",
      "✅ DONE [low] PointToRaster pourpoints (0.13 min)\n",
      "[low] SnapPourPoint distance = 150 m (land-only)\n",
      "▶ [low] RasterToPoint snapped pourpoints\n",
      "✅ DONE [low] RasterToPoint snapped pourpoints (0.08 min)\n",
      "▶ [low] Calculate CW_Id on snapped points\n",
      "✅ DONE [low] Calculate CW_Id on snapped points (0.00 min)\n",
      "[low] unique snapped pourpoint IDs: 4346 (target 4500)\n",
      "▶ [low] PointToRaster snapped points\n",
      "✅ DONE [low] PointToRaster snapped points (0.12 min)\n",
      "▶ [low] Watershed\n",
      "✅ DONE [low] Watershed (0.78 min)\n",
      "▶ [low] RasterToPolygon\n",
      "✅ DONE [low] RasterToPolygon (0.15 min)\n",
      "▶ [low] Calculate CW_Id on watershed polygons\n",
      "✅ DONE [low] Calculate CW_Id on watershed polygons (0.01 min)\n",
      "▶ [low] Dissolve watersheds by CW_Id\n",
      "✅ DONE [low] Dissolve watersheds by CW_Id (0.05 min)\n",
      "[low] watersheds BEFORE clipping unique IDs: 4346 (target 4500)\n",
      "▶ [low] Erase lake from watersheds (clip)\n",
      "✅ DONE [low] Erase lake from watersheds (clip) (0.02 min)\n",
      "▶ [low] Erase stream mask from watersheds (clip)\n",
      "✅ DONE [low] Erase stream mask from watersheds (clip) (0.01 min)\n",
      "▶ [low] Dissolve final output (clip result)\n",
      "✅ DONE [low] Dissolve final output (clip result) (0.02 min)\n",
      "[low] final watersheds AFTER clip unique IDs: 2384 (target 4500)\n",
      "[low] Missing IDs after clip: 2116\n",
      "▶ [low] Copy missing pourpoints\n",
      "✅ DONE [low] Copy missing pourpoints (0.01 min)\n",
      "▶ [low] Near(missing pts -> final watersheds)\n",
      "✅ DONE [low] Near(missing pts -> final watersheds) (0.01 min)\n",
      "▶ [low] Create assigned FC\n",
      "✅ DONE [low] Create assigned FC (0.01 min)\n",
      "[low] Assigned polygons added: 2116\n",
      "▶ [low] Append assigned -> final\n",
      "✅ DONE [low] Append assigned -> final (0.01 min)\n",
      "▶ [low] PairwiseDissolve (enforce 1 per CW_Id)\n",
      "✅ DONE [low] PairwiseDissolve (enforce 1 per CW_Id) (0.01 min)\n",
      "▶ [low] Copy enforced final\n",
      "✅ DONE [low] Copy enforced final (0.02 min)\n",
      "[low] final watersheds AFTER assignment-repair: 4500 (target 4500)\n",
      "✅ final watershed: low -> CoastalWatershed_low_erase_lakedrain_LakeHuron.shp\n",
      "\n",
      "==================== SURGE ====================\n",
      "▶ [surge] Project wetlands\n",
      "✅ DONE [surge] Project wetlands (0.01 min)\n",
      "▶ [surge] RepairGeometry wetlands\n",
      "✅ DONE [surge] RepairGeometry wetlands (0.12 min)\n",
      "▶ [surge] Dissolve ORIGINAL wetlands by CW_Id\n",
      "✅ DONE [surge] Dissolve ORIGINAL wetlands by CW_Id (0.08 min)\n",
      "[surge] unique wetland IDs (original, dissolved): 17071\n",
      "▶ [surge] Erase lake from wetlands (land-only)\n",
      "✅ DONE [surge] Erase lake from wetlands (land-only) (0.04 min)\n",
      "▶ [surge] Dissolve land-only wetlands by CW_Id\n",
      "✅ DONE [surge] Dissolve land-only wetlands by CW_Id (0.09 min)\n",
      "[surge] unique wetland IDs (land-only, dissolved): 11715\n",
      "▶ [surge] FeatureToPoint INSIDE (land-only dissolved)\n",
      "✅ DONE [surge] FeatureToPoint INSIDE (land-only dissolved) (0.02 min)\n",
      "⚠️ [surge] 5356 wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\n",
      "▶ [surge missing] Copy selected\n",
      "✅ DONE [surge missing] Copy selected (0.01 min)\n",
      "▶ [surge] FeatureToPoint INSIDE (fallback dissolved)\n",
      "✅ DONE [surge] FeatureToPoint INSIDE (fallback dissolved) (0.01 min)\n",
      "▶ [surge] Append fallback points\n",
      "✅ DONE [surge] Append fallback points (0.01 min)\n",
      "▶ [surge] PointToRaster pourpoints\n",
      "✅ DONE [surge] PointToRaster pourpoints (0.17 min)\n",
      "[surge] SnapPourPoint distance = 150 m (land-only)\n",
      "▶ [surge] RasterToPoint snapped pourpoints\n",
      "✅ DONE [surge] RasterToPoint snapped pourpoints (0.08 min)\n",
      "▶ [surge] Calculate CW_Id on snapped points\n",
      "✅ DONE [surge] Calculate CW_Id on snapped points (0.01 min)\n",
      "[surge] unique snapped pourpoint IDs: 16309 (target 17071)\n",
      "▶ [surge] PointToRaster snapped points\n",
      "✅ DONE [surge] PointToRaster snapped points (0.13 min)\n",
      "▶ [surge] Watershed\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL ROBUST CELL (UPDATED): 1 Coastal Watershed per Coastal Wetland (CW_Id)\n",
    "# Goal:\n",
    "#   - ALWAYS produce one watershed per CW_Id\n",
    "#   - Then CLIP OUT only the portions inside Lake Huron or inside Stream-Watershed mask\n",
    "#   - Do NOT drop whole IDs due to tiny overlaps\n",
    "#   - No C:\\ temp writes (all temp in ws_gdb / pp_gdb)\n",
    "# Notes:\n",
    "#   - This workflow can still lose some CW_Ids due to SnapPourPoint raster collisions.\n",
    "#     We fix that with a \"REPAIR missing IDs\" step that rebuilds only missing CW_Ids one-by-one.\n",
    "\n",
    "import os, gc, time, sys\n",
    "import arcpy\n",
    "from arcpy import sa\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.addOutputsToMap = False\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# -------------------------\n",
    "# REQUIRED: folders exist (must be defined in your notebook)\n",
    "# -------------------------\n",
    "# outPourpoints, outWatersheds, inStreamsWatershed, Lake_Huron, D8_flow\n",
    "# erase_buffer_avg/high/low/surge\n",
    "# CoastalWatershed_* output paths must exist in your notebook variables\n",
    "os.makedirs(outPourpoints, exist_ok=True)\n",
    "os.makedirs(outWatersheds, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Reliable workspaces (GDBs)\n",
    "# -------------------------\n",
    "pp_gdb = os.path.join(outPourpoints, \"pourpoints.gdb\")\n",
    "if not arcpy.Exists(pp_gdb):\n",
    "    arcpy.management.CreateFileGDB(outPourpoints, \"pourpoints.gdb\")\n",
    "\n",
    "ws_gdb = os.path.join(outWatersheds, \"watersheds.gdb\")\n",
    "if not arcpy.Exists(ws_gdb):\n",
    "    arcpy.management.CreateFileGDB(outWatersheds, \"watersheds.gdb\")\n",
    "\n",
    "# FORCE all scratch/workspace to your ws_gdb (no C:\\temp)\n",
    "arcpy.env.workspace = ws_gdb\n",
    "arcpy.env.scratchWorkspace = ws_gdb\n",
    "\n",
    "# -------------------------\n",
    "# Inputs\n",
    "# -------------------------\n",
    "flowacc = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\"\n",
    "print(f\"✅ flowacc: {flowacc}\", flush=True)\n",
    "\n",
    "cats = {\n",
    "    #\"avg\":   (erase_buffer_avg,   CoastalWatershed_avg_erase_lakedrain,   CoastalWatershed_avg_erase_lakedrain_LakeHuron),\n",
    "    \"high\":  (erase_buffer_high,  CoastalWatershed_high_erase_lakedrain,  CoastalWatershed_high_erase_lakedrain_LakeHuron),\n",
    "    \"low\":   (erase_buffer_low,   CoastalWatershed_low_erase_lakedrain,   CoastalWatershed_low_erase_lakedrain_LakeHuron),\n",
    "    \"surge\": (erase_buffer_surge, CoastalWatershed_surge_erase_lakedrain, CoastalWatershed_surge_erase_lakedrain_LakeHuron),\n",
    "}\n",
    "\n",
    "CW_ID_FIELD = \"CW_Id\"\n",
    "\n",
    "# -------------------------\n",
    "# Align env to D8 grid\n",
    "# -------------------------\n",
    "D8_SR = arcpy.Describe(D8_flow).spatialReference\n",
    "arcpy.env.snapRaster = D8_flow\n",
    "arcpy.env.cellSize   = D8_flow\n",
    "arcpy.env.extent     = D8_flow\n",
    "arcpy.env.outputCoordinateSystem = D8_SR\n",
    "cellsize = float(arcpy.Describe(D8_flow).meanCellWidth)\n",
    "\n",
    "print(f\"✅ workspace: {ws_gdb}\", flush=True)\n",
    "print(f\"✅ scratch:   {ws_gdb}\", flush=True)\n",
    "print(f\"✅ D8_flow CRS: {D8_SR.name} (factoryCode={D8_SR.factoryCode})\", flush=True)\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def _log(msg):\n",
    "    print(msg, flush=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def _clear_locks():\n",
    "    try:\n",
    "        arcpy.ClearWorkspaceCache_management()\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "def _safe_delete(p):\n",
    "    try:\n",
    "        if arcpy.Exists(p):\n",
    "            arcpy.management.Delete(p)\n",
    "    except Exception:\n",
    "        _clear_locks()\n",
    "        if arcpy.Exists(p):\n",
    "            arcpy.management.Delete(p)\n",
    "\n",
    "def _field_map_lower(fc):\n",
    "    return {f.name.lower(): f.name for f in arcpy.ListFields(fc)}\n",
    "\n",
    "def _find_field(fc, candidates):\n",
    "    fmap = _field_map_lower(fc)\n",
    "    for c in candidates:\n",
    "        if c and c.lower() in fmap:\n",
    "            return fmap[c.lower()]\n",
    "    return None\n",
    "\n",
    "def get_field_name_ci(fc, target_name):\n",
    "    if not target_name:\n",
    "        return None\n",
    "    t = target_name.lower()\n",
    "    for f in arcpy.ListFields(fc):\n",
    "        if f.name.lower() == t:\n",
    "            return f.name\n",
    "    return None\n",
    "\n",
    "def _is_shp(path):\n",
    "    return isinstance(path, str) and path.lower().endswith(\".shp\")\n",
    "\n",
    "def _ensure_field(fc, desired_name, field_type=\"LONG\", fallbacks=()):\n",
    "    if not desired_name or not str(desired_name).strip():\n",
    "        desired_name = \"CW_Id\"\n",
    "\n",
    "    existing = get_field_name_ci(fc, desired_name)\n",
    "    if existing:\n",
    "        return existing\n",
    "\n",
    "    candidates = [desired_name] + list(fallbacks)\n",
    "    for nm in candidates:\n",
    "        if not nm:\n",
    "            continue\n",
    "\n",
    "        safe = arcpy.ValidateFieldName(nm, os.path.dirname(fc) if isinstance(fc, str) else \"\")\n",
    "        if _is_shp(fc) and len(safe) > 10:\n",
    "            safe = safe[:10]\n",
    "\n",
    "        existing = get_field_name_ci(fc, safe)\n",
    "        if existing:\n",
    "            return existing\n",
    "\n",
    "        try:\n",
    "            arcpy.management.AddField(fc, safe, field_type)\n",
    "            return get_field_name_ci(fc, safe) or safe\n",
    "        except Exception:\n",
    "            _clear_locks()\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(f\"Cannot add field '{desired_name}' to {fc}\")\n",
    "\n",
    "def count_unique(fc, id_field):\n",
    "    fld = get_field_name_ci(fc, id_field) or _find_field(fc, [id_field])\n",
    "    if not fld:\n",
    "        return 0\n",
    "    vals = set()\n",
    "    with arcpy.da.SearchCursor(fc, [fld]) as cur:\n",
    "        for (v,) in cur:\n",
    "            if v is not None:\n",
    "                vals.add(int(v))\n",
    "    return len(vals)\n",
    "\n",
    "def _idset(fc, id_field):\n",
    "    fld = get_field_name_ci(fc, id_field) or _find_field(fc, [id_field])\n",
    "    s = set()\n",
    "    with arcpy.da.SearchCursor(fc, [fld]) as cur:\n",
    "        for (v,) in cur:\n",
    "            if v is not None:\n",
    "                s.add(int(v))\n",
    "    return s\n",
    "\n",
    "def calculate_area_m2(fc, field=\"WS_AREAM2\"):\n",
    "    try:\n",
    "        field = _ensure_field(fc, field, \"DOUBLE\", fallbacks=(\"AREA_M2\",\"A_M2\",\"AREA\"))\n",
    "        arcpy.management.CalculateGeometryAttributes(fc, [[field, \"AREA\"]], area_unit=\"SQUARE_METERS\")\n",
    "    except Exception as e:\n",
    "        _log(f\"⚠️ area field skipped: {e}\")\n",
    "    return field\n",
    "\n",
    "def add_xy_ll(fc, prefix=\"WS\"):\n",
    "    try:\n",
    "        cx = _ensure_field(fc, f\"{prefix}_cx\", \"DOUBLE\", fallbacks=(f\"{prefix}X\",))\n",
    "        cy = _ensure_field(fc, f\"{prefix}_cy\", \"DOUBLE\", fallbacks=(f\"{prefix}Y\",))\n",
    "        arcpy.management.CalculateField(fc, cx, \"!SHAPE.centroid.X!\", \"PYTHON3\")\n",
    "        arcpy.management.CalculateField(fc, cy, \"!SHAPE.centroid.Y!\", \"PYTHON3\")\n",
    "\n",
    "        lon = _ensure_field(fc, f\"{prefix}_lon\", \"DOUBLE\", fallbacks=(f\"{prefix}LON\",))\n",
    "        lat = _ensure_field(fc, f\"{prefix}_lat\", \"DOUBLE\", fallbacks=(f\"{prefix}LAT\",))\n",
    "        arcpy.management.CalculateGeometryAttributes(\n",
    "            fc,\n",
    "            [[lat, \"CENTROID_Y\"], [lon, \"CENTROID_X\"]],\n",
    "            coordinate_system=arcpy.SpatialReference(4326),\n",
    "            coordinate_format=\"DD\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        _log(f\"⚠️ xy/ll fields skipped: {e}\")\n",
    "\n",
    "def gp(label, func, *args, **kwargs):\n",
    "    _log(f\"▶ {label}\")\n",
    "    t0 = time.time()\n",
    "    out = func(*args, **kwargs)\n",
    "    _log(f\"✅ DONE {label} ({(time.time()-t0)/60:.2f} min)\")\n",
    "    return out\n",
    "\n",
    "# ---------- CRS FIX + PROJECT (TEMP WRITES INTO ws_gdb) ----------\n",
    "def fix_define_and_project_to_gdb(in_fc, out_fc, out_sr, assumed_src_if_mislabeled=None, name=\"layer\"):\n",
    "    \"\"\"\n",
    "    Robust CRS fixer:\n",
    "    - If dataset is mislabeled but coordinates already match out_sr, we:\n",
    "        CopyFeatures -> DefineProjection(out_sr) and STOP (no Project).\n",
    "    - Otherwise we DefineProjection to known source CRS (e.g. EPSG:4326) then Project.\n",
    "    All temp writes stay in ws_gdb (no C:\\).\n",
    "    \"\"\"\n",
    "    def _looks_like_degrees(ext):\n",
    "        return (abs(ext.XMin) <= 180 and abs(ext.XMax) <= 180 and abs(ext.YMin) <= 90 and abs(ext.YMax) <= 90)\n",
    "\n",
    "    def _looks_like_projected(ext):\n",
    "        return (max(abs(ext.XMin), abs(ext.XMax), abs(ext.YMin), abs(ext.YMax)) > 1000)\n",
    "\n",
    "    def _pick_transform(in_sr, out_sr):\n",
    "        try:\n",
    "            tx = arcpy.ListTransformations(in_sr, out_sr)\n",
    "            return tx[0] if tx else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    _safe_delete(out_fc)\n",
    "\n",
    "    d = arcpy.Describe(in_fc)\n",
    "    sr = d.spatialReference\n",
    "    ext = d.extent\n",
    "\n",
    "    _log(f\"\\n[{name}] input: {in_fc}\")\n",
    "    _log(f\"[{name}] sr: {sr.name if sr else None} | factoryCode={getattr(sr,'factoryCode',None)} | type={getattr(sr,'type',None)}\")\n",
    "    _log(f\"[{name}] extent: XMin={ext.XMin:.3f} XMax={ext.XMax:.3f} YMin={ext.YMin:.3f} YMax={ext.YMax:.3f}\")\n",
    "\n",
    "    tmp_copy = os.path.join(ws_gdb, f\"tmp_{name}_copy\")\n",
    "    _safe_delete(tmp_copy)\n",
    "\n",
    "    # Copy without any implicit projection\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=None, extent=None, snapRaster=None, cellSize=None):\n",
    "        gp(f\"CopyFeatures {name}\", arcpy.management.CopyFeatures, in_fc, tmp_copy)\n",
    "\n",
    "    d2 = arcpy.Describe(tmp_copy)\n",
    "    sr2 = d2.spatialReference\n",
    "    ext2 = d2.extent\n",
    "\n",
    "    mislabeled_projected = (\n",
    "        sr2 is not None and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "        and _looks_like_projected(ext2) and not _looks_like_degrees(ext2)\n",
    "    )\n",
    "\n",
    "    if mislabeled_projected:\n",
    "        _log(f\"[{name}] ⚠️ MISLABELED Geographic but coords are projected. SKIP Project; DefineProjection -> {out_sr.name}\")\n",
    "        gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, out_sr)\n",
    "        gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "        _safe_delete(tmp_copy)\n",
    "        return out_fc\n",
    "\n",
    "    generic_degrees = (\n",
    "        sr2 is not None and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "        and _looks_like_degrees(ext2)\n",
    "        and getattr(sr2, \"factoryCode\", 0) in (0, None)\n",
    "    )\n",
    "\n",
    "    if generic_degrees:\n",
    "        if assumed_src_if_mislabeled is None:\n",
    "            assumed_src_if_mislabeled = arcpy.SpatialReference(4326)\n",
    "        _log(f\"[{name}] ⚠️ GENERIC geographic degrees. DefineProjection -> EPSG:4326 then Project.\")\n",
    "        gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, assumed_src_if_mislabeled)\n",
    "\n",
    "    sr_fixed = arcpy.Describe(tmp_copy).spatialReference\n",
    "    if sr_fixed and (sr_fixed.factoryCode == out_sr.factoryCode) and (sr_fixed.name == out_sr.name):\n",
    "        _log(f\"[{name}] Already in target CRS. CopyFeatures only (no Project).\")\n",
    "        gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "        _safe_delete(tmp_copy)\n",
    "        return out_fc\n",
    "\n",
    "    transform = _pick_transform(sr_fixed, out_sr)\n",
    "    _log(f\"[{name}] Project -> {out_sr.name} | transform={transform}\")\n",
    "\n",
    "    if transform:\n",
    "        gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr, transform)\n",
    "    else:\n",
    "        gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr)\n",
    "\n",
    "    _safe_delete(tmp_copy)\n",
    "    return out_fc\n",
    "\n",
    "def polygon_to_mask_raster(poly_fc, out_ras, value=1):\n",
    "    \"\"\"\n",
    "    Polygon -> raster aligned to D8 (snap/cellsize/extent already set).\n",
    "    Uses a constant field to burn 'value' into raster.\n",
    "    \"\"\"\n",
    "    _safe_delete(out_ras)\n",
    "    fld = \"MASKVAL\"\n",
    "    if fld not in [f.name for f in arcpy.ListFields(poly_fc)]:\n",
    "        arcpy.management.AddField(poly_fc, fld, \"SHORT\")\n",
    "        arcpy.management.CalculateField(poly_fc, fld, value, \"PYTHON3\")\n",
    "    gp(f\"PolygonToRaster {os.path.basename(out_ras)}\", arcpy.conversion.PolygonToRaster,\n",
    "       poly_fc, fld, out_ras, \"CELL_CENTER\", \"\", cellsize)\n",
    "    return out_ras\n",
    "\n",
    "# ============================================================\n",
    "# 0) Build projected masks ONCE (stored in ws_gdb)\n",
    "# ============================================================\n",
    "# Stream watershed mask: mislabeled as 4326 but projected coords\n",
    "inStreamsWS_tgt = os.path.join(ws_gdb, \"inStreamsWS_tgt\")\n",
    "fix_define_and_project_to_gdb(\n",
    "    in_fc=inStreamsWatershed,\n",
    "    out_fc=inStreamsWS_tgt,\n",
    "    out_sr=D8_SR,\n",
    "    name=\"inStreamsWS\"\n",
    ")\n",
    "\n",
    "gp(\"RepairGeometry stream mask\", arcpy.management.RepairGeometry, inStreamsWS_tgt)\n",
    "\n",
    "inStreams_single = os.path.join(ws_gdb, \"inStreamsWS_single\")\n",
    "_safe_delete(inStreams_single)\n",
    "gp(\"MultipartToSinglepart stream mask\", arcpy.management.MultipartToSinglepart, inStreamsWS_tgt, inStreams_single)\n",
    "\n",
    "inStreamsWS_tgt_diss = os.path.join(ws_gdb, \"inStreamsWS_tgt_diss\")\n",
    "_safe_delete(inStreamsWS_tgt_diss)\n",
    "gp(\"Dissolve stream mask\", arcpy.management.Dissolve, inStreams_single, inStreamsWS_tgt_diss)\n",
    "\n",
    "# Buffer stream mask (helps remove slivers; does NOT delete entire IDs because we clip polygons later)\n",
    "stream_buf_m = 60\n",
    "inStreamsWS_buf = os.path.join(ws_gdb, f\"inStreamsWS_buf{stream_buf_m}m\")\n",
    "_safe_delete(inStreamsWS_buf)\n",
    "gp(\"Buffer stream mask\", arcpy.analysis.Buffer, inStreamsWS_tgt_diss, inStreamsWS_buf, f\"{stream_buf_m} Meters\", \"FULL\", \"ROUND\", \"ALL\")\n",
    "\n",
    "# Lake polygon: generic geographic in degrees\n",
    "Lake_tgt = os.path.join(ws_gdb, \"LakeHuron_tgt\")\n",
    "fix_define_and_project_to_gdb(\n",
    "    in_fc=Lake_Huron,\n",
    "    out_fc=Lake_tgt,\n",
    "    out_sr=D8_SR,\n",
    "    assumed_src_if_mislabeled=arcpy.SpatialReference(4326),\n",
    "    name=\"LakeHuron\"\n",
    ")\n",
    "\n",
    "gp(\"RepairGeometry lake\", arcpy.management.RepairGeometry, Lake_tgt)\n",
    "\n",
    "# Lake mask raster (for flowacc_land only)\n",
    "lake_mask_ras = os.path.join(ws_gdb, \"LakeHuron_mask_ras\")\n",
    "polygon_to_mask_raster(Lake_tgt, lake_mask_ras, value=1)\n",
    "_log(f\"✅ lake_mask_ras: {lake_mask_ras}\")\n",
    "\n",
    "# Land-only flowacc for snapping (NoData on lake)\n",
    "flowacc_land = os.path.join(ws_gdb, \"flowacc_land\")\n",
    "_safe_delete(flowacc_land)\n",
    "_log(\"▶ Build flowacc_land = flowacc where NOT lake\")\n",
    "fa_land = sa.SetNull(sa.Raster(lake_mask_ras), sa.Raster(flowacc))\n",
    "fa_land.save(flowacc_land)\n",
    "_log(f\"✅ flowacc_land: {flowacc_land}\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "for cat, (wet_fc, out_ws_drain, out_ws_lake) in cats.items():\n",
    "\n",
    "    _log(f\"\\n==================== {cat.upper()} ====================\")\n",
    "\n",
    "    # --- 1) Project wetlands into D8 SR (work in GDB)\n",
    "    wet_tgt = os.path.join(ws_gdb, f\"{cat}_wet_tgt\")\n",
    "    _safe_delete(wet_tgt)\n",
    "    gp(f\"[{cat}] Project wetlands\", arcpy.management.Project, wet_fc, wet_tgt, D8_SR)\n",
    "\n",
    "    wet_id_f = _ensure_field(wet_tgt, CW_ID_FIELD, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] RepairGeometry wetlands\", arcpy.management.RepairGeometry, wet_tgt)\n",
    "\n",
    "    # --- 2) Dissolve ORIGINAL wetlands by CW_Id (guarantees 1 polygon per CW_Id)\n",
    "    wet_orig_diss = os.path.join(ws_gdb, f\"{cat}_wet_orig_diss\")\n",
    "    _safe_delete(wet_orig_diss)\n",
    "    gp(f\"[{cat}] Dissolve ORIGINAL wetlands by CW_Id\", arcpy.management.Dissolve, wet_tgt, wet_orig_diss, wet_id_f)\n",
    "\n",
    "    wet_n = count_unique(wet_orig_diss, wet_id_f)\n",
    "    _log(f\"[{cat}] unique wetland IDs (original, dissolved): {wet_n}\")\n",
    "\n",
    "    # --- 3) LAND-ONLY wetlands (erase lake) then dissolve (for land pourpoints)\n",
    "    wet_land = os.path.join(ws_gdb, f\"{cat}_wet_land\")\n",
    "    _safe_delete(wet_land)\n",
    "    gp(f\"[{cat}] Erase lake from wetlands (land-only)\", arcpy.analysis.Erase, wet_tgt, Lake_tgt, wet_land)\n",
    "\n",
    "    wet_land_diss = os.path.join(ws_gdb, f\"{cat}_wet_land_diss\")\n",
    "    _safe_delete(wet_land_diss)\n",
    "    gp(f\"[{cat}] Dissolve land-only wetlands by CW_Id\", arcpy.management.Dissolve, wet_land, wet_land_diss, wet_id_f)\n",
    "\n",
    "    land_n = count_unique(wet_land_diss, wet_id_f)\n",
    "    _log(f\"[{cat}] unique wetland IDs (land-only, dissolved): {land_n}\")\n",
    "\n",
    "    # --- 4) Pourpoints from land-only dissolved (1 per CW_Id)\n",
    "    pp_inside = os.path.join(pp_gdb, f\"{cat}_pp_inside\")\n",
    "    _safe_delete(pp_inside)\n",
    "    gp(f\"[{cat}] FeatureToPoint INSIDE (land-only dissolved)\", arcpy.management.FeatureToPoint, wet_land_diss, pp_inside, \"INSIDE\")\n",
    "\n",
    "    # --- 5) Add fallback pourpoints for lake-only IDs from ORIGINAL dissolved (still 1 per CW_Id)\n",
    "    orig_ids = _idset(wet_orig_diss, wet_id_f)\n",
    "    land_ids = _idset(wet_land_diss, wet_id_f)\n",
    "    missing_lakeonly = sorted(list(orig_ids - land_ids))\n",
    "\n",
    "    if missing_lakeonly:\n",
    "        _log(f\"⚠️ [{cat}] {len(missing_lakeonly)} wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\")\n",
    "\n",
    "        # Select missing polygons from wet_orig_diss using a chunked IN() approach\n",
    "        wet_missing_poly = os.path.join(ws_gdb, f\"{cat}_wet_missing_poly\")\n",
    "        _safe_delete(wet_missing_poly)\n",
    "\n",
    "        lyr = f\"lyr_{cat}_missing\"\n",
    "        arcpy.management.MakeFeatureLayer(wet_orig_diss, lyr)\n",
    "        chunk = 900\n",
    "        for i in range(0, len(missing_lakeonly), chunk):\n",
    "            sub = missing_lakeonly[i:i+chunk]\n",
    "            where = f\"{arcpy.AddFieldDelimiters(lyr, wet_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "            arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "        gp(f\"[{cat} missing] Copy selected\", arcpy.management.CopyFeatures, lyr, wet_missing_poly)\n",
    "        arcpy.management.Delete(lyr)\n",
    "\n",
    "        pp_fallback = os.path.join(pp_gdb, f\"{cat}_pp_fallback\")\n",
    "        _safe_delete(pp_fallback)\n",
    "        gp(f\"[{cat}] FeatureToPoint INSIDE (fallback dissolved)\", arcpy.management.FeatureToPoint, wet_missing_poly, pp_fallback, \"INSIDE\")\n",
    "\n",
    "        gp(f\"[{cat}] Append fallback points\", arcpy.management.Append, pp_fallback, pp_inside, \"NO_TEST\")\n",
    "        _safe_delete(pp_fallback)\n",
    "        _safe_delete(wet_missing_poly)\n",
    "\n",
    "    # ensure ID field exists on points\n",
    "    pp_id_f = _ensure_field(pp_inside, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "\n",
    "    # --- 6) SnapPourPoint in raster space (bulk) using LAND-ONLY flowacc\n",
    "    pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_ras\")\n",
    "    _safe_delete(pp_ras)\n",
    "    gp(f\"[{cat}] PointToRaster pourpoints\", arcpy.conversion.PointToRaster,\n",
    "       pp_inside, pp_id_f, pp_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "    snapped_pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_snapped_ras\")\n",
    "    _safe_delete(snapped_pp_ras)\n",
    "\n",
    "    # For lake-only points you typically need a larger snap distance to reach land.\n",
    "    # But larger distances increase collisions. We'll keep it moderate and REPAIR missing IDs later.\n",
    "    snap_dist_m = 150\n",
    "    _log(f\"[{cat}] SnapPourPoint distance = {snap_dist_m} m (land-only)\")\n",
    "    sa.SnapPourPoint(sa.Raster(pp_ras), sa.Raster(flowacc_land), snap_dist_m).save(snapped_pp_ras)\n",
    "\n",
    "    # Convert snapped raster to points (bulk snapped pourpoints)\n",
    "    snapped_pts = os.path.join(pp_gdb, f\"{cat}_pp_snapped_pts\")\n",
    "    _safe_delete(snapped_pts)\n",
    "    gp(f\"[{cat}] RasterToPoint snapped pourpoints\", arcpy.conversion.RasterToPoint, snapped_pp_ras, snapped_pts, \"VALUE\")\n",
    "\n",
    "    val_field = _find_field(snapped_pts, [\"GRID_CODE\", \"GRIDCODE\", \"VALUE\"])\n",
    "    if not val_field:\n",
    "        raise RuntimeError(f\"[{cat}] Could not find VALUE/GRIDCODE in snapped points.\")\n",
    "\n",
    "    pp_final_id = _ensure_field(snapped_pts, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] Calculate CW_Id on snapped points\", arcpy.management.CalculateField,\n",
    "       snapped_pts, pp_final_id, f\"!{val_field}!\", \"PYTHON3\")\n",
    "\n",
    "    uniq_pp = count_unique(snapped_pts, pp_final_id)\n",
    "    _log(f\"[{cat}] unique snapped pourpoint IDs: {uniq_pp} (target {wet_n})\")\n",
    "\n",
    "    # --- 7) Convert snapped points back to raster for Watershed\n",
    "    pp_snap_ras = os.path.join(pp_gdb, f\"{cat}_pp_snap_ras\")\n",
    "    _safe_delete(pp_snap_ras)\n",
    "    gp(f\"[{cat}] PointToRaster snapped points\", arcpy.conversion.PointToRaster,\n",
    "       snapped_pts, pp_final_id, pp_snap_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "    # --- 8) Watershed raster (NO lake/stream raster masking here!)\n",
    "    ws_ras = os.path.join(ws_gdb, f\"{cat}_ws_ras\")\n",
    "    _safe_delete(ws_ras)\n",
    "    _log(f\"▶ [{cat}] Watershed\")\n",
    "    t0 = time.time()\n",
    "    sa.Watershed(D8_flow, pp_snap_ras).save(ws_ras)\n",
    "    _log(f\"✅ DONE [{cat}] Watershed ({(time.time()-t0)/60:.2f} min)\")\n",
    "\n",
    "    # --- 9) RasterToPolygon (NO raster masking)\n",
    "    ws_poly_raw = os.path.join(ws_gdb, f\"{cat}_ws_poly_raw\")\n",
    "    _safe_delete(ws_poly_raw)\n",
    "    gp(f\"[{cat}] RasterToPolygon\", arcpy.conversion.RasterToPolygon, ws_ras, ws_poly_raw, \"NO_SIMPLIFY\", \"VALUE\")\n",
    "\n",
    "    grid_field = _find_field(ws_poly_raw, [\"GRIDCODE\",\"GRID_CODE\"])\n",
    "    if not grid_field:\n",
    "        raise RuntimeError(f\"[{cat}] GRIDCODE missing in watershed polygons.\")\n",
    "\n",
    "    ws_id_f = _ensure_field(ws_poly_raw, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] Calculate CW_Id on watershed polygons\", arcpy.management.CalculateField,\n",
    "       ws_poly_raw, ws_id_f, f\"!{grid_field}!\", \"PYTHON3\")\n",
    "\n",
    "    ws_poly = os.path.join(ws_gdb, f\"{cat}_ws_poly\")\n",
    "    _safe_delete(ws_poly)\n",
    "    gp(f\"[{cat}] Dissolve watersheds by CW_Id\", arcpy.management.Dissolve, ws_poly_raw, ws_poly, ws_id_f)\n",
    "\n",
    "    ws_before = count_unique(ws_poly, ws_id_f)\n",
    "    _log(f\"[{cat}] watersheds BEFORE clipping unique IDs: {ws_before} (target {wet_n})\")\n",
    "\n",
    "    # --- 10) CLIP OUT ONLY overlap parts (lake + stream) as polygons\n",
    "    tmp_no_lake = os.path.join(ws_gdb, f\"{cat}_ws_no_lake\")\n",
    "    tmp_no_stream = os.path.join(ws_gdb, f\"{cat}_ws_no_stream\")\n",
    "    _safe_delete(tmp_no_lake); _safe_delete(tmp_no_stream)\n",
    "\n",
    "    gp(f\"[{cat}] Erase lake from watersheds (clip)\", arcpy.analysis.Erase, ws_poly, Lake_tgt, tmp_no_lake)\n",
    "    gp(f\"[{cat}] Erase stream mask from watersheds (clip)\", arcpy.analysis.Erase, tmp_no_lake, inStreamsWS_buf, tmp_no_stream)\n",
    "\n",
    "    _safe_delete(out_ws_lake)\n",
    "    gp(f\"[{cat}] Dissolve final output (clip result)\", arcpy.management.Dissolve, tmp_no_stream, out_ws_lake, ws_id_f)\n",
    "\n",
    "    ws_after = count_unique(out_ws_lake, ws_id_f)\n",
    "    _log(f\"[{cat}] final watersheds AFTER clip unique IDs: {ws_after} (target {wet_n})\")\n",
    "\n",
    "    # ============================================================\n",
    "# 11) REPAIR missing IDs (FAST VERSION)\n",
    "# ============================================================\n",
    "# 11) REPAIR missing IDs (ASSIGNMENT ONLY - FAST)\n",
    "#     This guarantees 1 feature per CW_Id without per-ID watershed rebuild.\n",
    "# ============================================================\n",
    "# ============================================================\n",
    "# 11) REPAIR missing IDs (ASSIGNMENT ONLY - FAST)\n",
    "#     This guarantees 1 feature per CW_Id without per-ID watershed rebuild.\n",
    "# ============================================================\n",
    "\n",
    "    final_ids = _idset(out_ws_lake, ws_id_f)\n",
    "    missing_ids = sorted(list(orig_ids - final_ids))\n",
    "    _log(f\"[{cat}] Missing IDs after clip: {len(missing_ids)}\")\n",
    "\n",
    "    if missing_ids:\n",
    "        # Extract pourpoints for missing IDs\n",
    "        pp_layer = f\"lyr_{cat}_pp_inside\"\n",
    "        arcpy.management.MakeFeatureLayer(pp_inside, pp_layer)\n",
    "\n",
    "        miss_pts = os.path.join(pp_gdb, f\"{cat}_missing_pts\")\n",
    "        _safe_delete(miss_pts)\n",
    "\n",
    "        arcpy.management.SelectLayerByAttribute(pp_layer, \"CLEAR_SELECTION\")\n",
    "        chunk = 900\n",
    "        for i in range(0, len(missing_ids), chunk):\n",
    "            sub = missing_ids[i:i+chunk]\n",
    "            where = f\"{arcpy.AddFieldDelimiters(pp_layer, pp_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "            arcpy.management.SelectLayerByAttribute(pp_layer, \"ADD_TO_SELECTION\", where)\n",
    "\n",
    "        gp(f\"[{cat}] Copy missing pourpoints\", arcpy.management.CopyFeatures, pp_layer, miss_pts)\n",
    "        arcpy.management.Delete(pp_layer)\n",
    "\n",
    "        # Near -> closest existing final watershed polygon\n",
    "        gp(f\"[{cat}] Near(missing pts -> final watersheds)\", arcpy.analysis.Near, miss_pts, out_ws_lake)\n",
    "\n",
    "        # Build donor geometry lookup (OID -> geometry)\n",
    "        oid_field = arcpy.Describe(out_ws_lake).OIDFieldName\n",
    "        donor_geom = {}\n",
    "        with arcpy.da.SearchCursor(out_ws_lake, [oid_field, \"SHAPE@\"]) as cur:\n",
    "            for oid, geom in cur:\n",
    "                donor_geom[int(oid)] = geom\n",
    "\n",
    "        # Create assigned FC (one polygon per missing CW_Id)\n",
    "        assigned_fc = os.path.join(ws_gdb, f\"{cat}_assigned_missing\")\n",
    "        _safe_delete(assigned_fc)\n",
    "        gp(f\"[{cat}] Create assigned FC\", arcpy.management.CreateFeatureclass,\n",
    "        ws_gdb, os.path.basename(assigned_fc), \"POLYGON\", None, \"DISABLED\", \"DISABLED\", D8_SR)\n",
    "\n",
    "        assigned_id = _ensure_field(assigned_fc, ws_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "\n",
    "        near_fld = _find_field(miss_pts, [\"NEAR_FID\"])\n",
    "        n_assigned = 0\n",
    "        with arcpy.da.SearchCursor(miss_pts, [pp_id_f, near_fld]) as cur, \\\n",
    "            arcpy.da.InsertCursor(assigned_fc, [assigned_id, \"SHAPE@\"]) as ic:\n",
    "            for cw, near_fid in cur:\n",
    "                if near_fid is None or int(near_fid) < 0:\n",
    "                    continue\n",
    "                geom = donor_geom.get(int(near_fid))\n",
    "                if geom is None:\n",
    "                    continue\n",
    "                ic.insertRow((int(cw), geom))\n",
    "                n_assigned += 1\n",
    "\n",
    "        _log(f\"[{cat}] Assigned polygons added: {n_assigned}\")\n",
    "\n",
    "        if int(arcpy.management.GetCount(assigned_fc)[0]) > 0:\n",
    "            gp(f\"[{cat}] Append assigned -> final\", arcpy.management.Append, assigned_fc, out_ws_lake, \"NO_TEST\")\n",
    "\n",
    "            out_ws_lake_diss2 = os.path.join(ws_gdb, f\"{cat}_final_diss2\")\n",
    "            _safe_delete(out_ws_lake_diss2)\n",
    "\n",
    "            # Use PairwiseDissolve if available (faster)\n",
    "            if hasattr(arcpy.analysis, \"PairwiseDissolve\"):\n",
    "                gp(f\"[{cat}] PairwiseDissolve (enforce 1 per CW_Id)\", arcpy.analysis.PairwiseDissolve,\n",
    "                out_ws_lake, out_ws_lake_diss2, ws_id_f)\n",
    "            else:\n",
    "                gp(f\"[{cat}] Dissolve (enforce 1 per CW_Id)\", arcpy.management.Dissolve,\n",
    "                out_ws_lake, out_ws_lake_diss2, ws_id_f)\n",
    "\n",
    "            _safe_delete(out_ws_lake)\n",
    "            gp(f\"[{cat}] Copy enforced final\", arcpy.management.CopyFeatures, out_ws_lake_diss2, out_ws_lake)\n",
    "\n",
    "        _safe_delete(miss_pts)\n",
    "\n",
    "    ws_after_final = count_unique(out_ws_lake, ws_id_f)\n",
    "    _log(f\"[{cat}] final watersheds AFTER assignment-repair: {ws_after_final} (target {len(orig_ids)})\")\n",
    "\n",
    "\n",
    "    # --- 12) Add attributes safely (do not crash if locked)\n",
    "    calculate_area_m2(out_ws_lake, \"WS_AREAM2\")\n",
    "    add_xy_ll(out_ws_lake, prefix=\"WS\")\n",
    "\n",
    "    _log(f\"✅ final watershed: {cat} -> {os.path.basename(out_ws_lake)}\")\n",
    "    _clear_locks()\n",
    "\n",
    "_log(\"\\n🎉 DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4eab11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disconnected count: 2578\n",
      "Examples: [5295, 6056, 6172, 6174, 6245, 6328, 6344, 7088, 7596, 7924, 8040, 8693, 8704, 8712, 8809, 8867, 9107, 9231, 9587, 9965]\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "\n",
    "def find_disconnected_ids(wet_fc, ws_fc, id_field=\"CW_Id\"):\n",
    "    arcpy.management.MakeFeatureLayer(wet_fc, \"wet_lyr\")\n",
    "    arcpy.management.MakeFeatureLayer(ws_fc,  \"ws_lyr\")\n",
    "\n",
    "    # Select watersheds that DO NOT intersect any wetland\n",
    "    arcpy.management.SelectLayerByLocation(\n",
    "        \"ws_lyr\",\n",
    "        overlap_type=\"INTERSECT\",\n",
    "        select_features=\"wet_lyr\",\n",
    "        selection_type=\"NEW_SELECTION\",\n",
    "        invert_spatial_relationship=\"INVERT\"\n",
    "    )\n",
    "\n",
    "    bad = set()\n",
    "    with arcpy.da.SearchCursor(\"ws_lyr\", [id_field]) as cur:\n",
    "        for (cid,) in cur:\n",
    "            if cid is not None:\n",
    "                bad.add(int(cid))\n",
    "\n",
    "    arcpy.management.Delete(\"wet_lyr\")\n",
    "    arcpy.management.Delete(\"ws_lyr\")\n",
    "    return sorted(bad)\n",
    "\n",
    "bad_ids = find_disconnected_ids(wet_fc, out_ws_lake, id_field=\"CW_Id\")\n",
    "print(\"Disconnected count:\", len(bad_ids))\n",
    "print(\"Examples:\", bad_ids[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2c84164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW_Id 4505: dist=96.16 m | inside_lake=True | D8_NoData=False | D8_val=64\n",
      "CW_Id 4635: dist=146.96 m | inside_lake=True | D8_NoData=False | D8_val=128\n",
      "CW_Id 4674: dist=125.76 m | inside_lake=True | D8_NoData=False | D8_val=1\n",
      "CW_Id 6132: dist=69.60 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 6328: dist=87.79 m | inside_lake=False | D8_NoData=False | D8_val=1\n",
      "CW_Id 6344: dist=137.36 m | inside_lake=False | D8_NoData=False | D8_val=1\n",
      "CW_Id 7290: dist=103.96 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 7924: dist=132.98 m | inside_lake=False | D8_NoData=False | D8_val=128\n",
      "CW_Id 8712: dist=49.62 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 8779: dist=97.66 m | inside_lake=False | D8_NoData=False | D8_val=128\n",
      "CW_Id 8780: dist=1.15 m | inside_lake=True | D8_NoData=False | D8_val=64\n",
      "CW_Id 8867: dist=129.64 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 8889: dist=53.54 m | inside_lake=False | D8_NoData=False | D8_val=32\n",
      "CW_Id 8890: dist=116.52 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 9104: dist=58.36 m | inside_lake=False | D8_NoData=False | D8_val=1\n",
      "CW_Id 9173: dist=119.79 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 9207: dist=119.87 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 9231: dist=151.50 m | inside_lake=True | D8_NoData=False | D8_val=1\n",
      "CW_Id 9361: dist=105.89 m | inside_lake=True | D8_NoData=False | D8_val=64\n",
      "CW_Id 9407: dist=129.15 m | inside_lake=True | D8_NoData=False | D8_val=64\n",
      "CW_Id 9426: dist=167.04 m | inside_lake=False | D8_NoData=False | D8_val=64\n",
      "CW_Id 9495: dist=134.94 m | inside_lake=False | D8_NoData=False | D8_val=32\n",
      "CW_Id 9587: dist=53.23 m | inside_lake=True | D8_NoData=False | D8_val=32\n",
      "CW_Id 9965: dist=154.56 m | inside_lake=False | D8_NoData=False | D8_val=128\n",
      "CW_Id 10263: dist=113.03 m | inside_lake=True | D8_NoData=False | D8_val=128\n",
      "CW_Id 10359: dist=112.59 m | inside_lake=True | D8_NoData=False | D8_val=128\n",
      "CW_Id 10452: dist=116.68 m | inside_lake=True | D8_NoData=False | D8_val=128\n",
      "CW_Id 10545: dist=113.91 m | inside_lake=True | D8_NoData=False | D8_val=64\n",
      "CW_Id 10709: dist=102.62 m | inside_lake=True | D8_NoData=False | D8_val=128\n",
      "CW_Id 10775: dist=121.06 m | inside_lake=True | D8_NoData=False | D8_val=64\n"
     ]
    }
   ],
   "source": [
    "def diagnose_bad_ids(bad_ids, wet_fc, snapped_pp_fc, lake_fc, flowdir_ras, id_field=\"CW_Id\"):\n",
    "    arcpy.management.MakeFeatureLayer(wet_fc, \"wet_lyr\")\n",
    "    arcpy.management.MakeFeatureLayer(snapped_pp_fc, \"pp_lyr\")\n",
    "\n",
    "    for tid in bad_ids[:30]:  # limit print\n",
    "        fldW = arcpy.AddFieldDelimiters(wet_fc, id_field)\n",
    "        fldP = arcpy.AddFieldDelimiters(snapped_pp_fc, id_field)\n",
    "\n",
    "        arcpy.management.SelectLayerByAttribute(\"wet_lyr\", \"NEW_SELECTION\", f\"{fldW} = {tid}\")\n",
    "        arcpy.management.SelectLayerByAttribute(\"pp_lyr\",  \"NEW_SELECTION\", f\"{fldP} = {tid}\")\n",
    "\n",
    "        wet_geom = next(arcpy.da.SearchCursor(\"wet_lyr\", [\"SHAPE@\"]))[0]\n",
    "        pp_geom  = next(arcpy.da.SearchCursor(\"pp_lyr\",  [\"SHAPE@\"]))[0]\n",
    "\n",
    "        dist = wet_geom.distanceTo(pp_geom)\n",
    "\n",
    "        # inside lake?\n",
    "        inside_lake = False\n",
    "        if lake_fc:\n",
    "            arcpy.management.MakeFeatureLayer(lake_fc, \"lake_lyr\")\n",
    "            arcpy.management.SelectLayerByLocation(\"lake_lyr\", \"INTERSECT\", pp_geom)\n",
    "            inside_lake = int(arcpy.management.GetCount(\"lake_lyr\")[0]) > 0\n",
    "            arcpy.management.Delete(\"lake_lyr\")\n",
    "\n",
    "        # NoData check on flowdir\n",
    "        cellval = arcpy.management.GetCellValue(flowdir_ras, f\"{pp_geom.centroid.X} {pp_geom.centroid.Y}\").getOutput(0)\n",
    "        nodata = (cellval in [\"NoData\", None])\n",
    "\n",
    "        print(f\"CW_Id {tid}: dist={dist:.2f} m | inside_lake={inside_lake} | D8_NoData={nodata} | D8_val={cellval}\")\n",
    "\n",
    "    arcpy.management.Delete(\"wet_lyr\")\n",
    "    arcpy.management.Delete(\"pp_lyr\")\n",
    "\n",
    "diagnose_bad_ids(bad_ids, wet_fc, unique_snapped_pp, Lake_tgt, D8_flow, id_field=\"CW_Id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "624e6dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[surge] CW_Id 415116: snapped->wetland distance = 98.53 m\n"
     ]
    }
   ],
   "source": [
    "# pick a few IDs to test\n",
    "test_ids = [415116]  # add more if you want\n",
    "\n",
    "# make layers\n",
    "arcpy.management.MakeFeatureLayer(unique_snapped_pp, \"snapped_lyr\")\n",
    "arcpy.management.MakeFeatureLayer(wet_fc, \"wet_lyr\")\n",
    "\n",
    "for tid in test_ids:\n",
    "    fldW = arcpy.AddFieldDelimiters(wet_fc, wet_id_f)\n",
    "    fldP = arcpy.AddFieldDelimiters(unique_snapped_pp, pp_id_f)\n",
    "\n",
    "    arcpy.management.SelectLayerByAttribute(\"wet_lyr\", \"NEW_SELECTION\", f\"{fldW} = {tid}\")\n",
    "    arcpy.management.SelectLayerByAttribute(\"snapped_lyr\", \"NEW_SELECTION\", f\"{fldP} = {tid}\")\n",
    "\n",
    "    # get geometries\n",
    "    wet_geom = next(arcpy.da.SearchCursor(\"wet_lyr\", [\"SHAPE@\"]))[0]\n",
    "    pp_geom  = next(arcpy.da.SearchCursor(\"snapped_lyr\", [\"SHAPE@\"]))[0]\n",
    "\n",
    "    dist = wet_geom.distanceTo(pp_geom)\n",
    "    print(f\"[{cat}] CW_Id {tid}: snapped->wetland distance = {dist:.2f} m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dc5c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watershed intersects wetland? False\n",
      "Distance snapped pourpoint -> wetland: 100.2234555610154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('D:\\\\Users\\\\abolmaal\\\\Arcgis\\\\NASAOceanProject\\\\GIS_layer\\\\CoastalWatersheds\\\\temp\\\\cw_debug_avg.gdb\\\\avg_wet_415116',\n",
       " 'D:\\\\Users\\\\abolmaal\\\\Arcgis\\\\NASAOceanProject\\\\GIS_layer\\\\CoastalWatersheds\\\\temp\\\\cw_debug_avg.gdb\\\\avg_pp_415116',\n",
       " 'D:\\\\Users\\\\abolmaal\\\\Arcgis\\\\NASAOceanProject\\\\GIS_layer\\\\CoastalWatersheds\\\\temp\\\\cw_debug_avg.gdb\\\\avg_upp_415116',\n",
       " 'D:\\\\Users\\\\abolmaal\\\\Arcgis\\\\NASAOceanProject\\\\GIS_layer\\\\CoastalWatersheds\\\\temp\\\\cw_debug_avg.gdb\\\\avg_ws_415116')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def debug_one_cw(cat, cw_id, wet_fc, pourpoints_fc, uniq_pp_fc, ws_poly_gdb, out_gdb):\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    if not arcpy.Exists(out_gdb):\n",
    "        arcpy.management.CreateFileGDB(os.path.dirname(out_gdb), os.path.basename(out_gdb))\n",
    "\n",
    "    def sel_to_fc(fc, where, out_name):\n",
    "        out = os.path.join(out_gdb, out_name)\n",
    "        if arcpy.Exists(out): arcpy.management.Delete(out)\n",
    "        lyr = f\"lyr_{out_name}\"\n",
    "        arcpy.management.MakeFeatureLayer(fc, lyr, where)\n",
    "        arcpy.management.CopyFeatures(lyr, out)\n",
    "        arcpy.management.Delete(lyr)\n",
    "        return out\n",
    "\n",
    "    # export the pieces\n",
    "    wet_sel  = sel_to_fc(wet_fc,        f\"{CW_ID_FIELD} = {cw_id}\", f\"{cat}_wet_{cw_id}\")\n",
    "    pp_sel   = sel_to_fc(pourpoints_fc, f\"{CW_ID_FIELD} = {cw_id}\", f\"{cat}_pp_{cw_id}\")\n",
    "    upp_sel  = sel_to_fc(uniq_pp_fc,    f\"{CW_ID_FIELD} = {cw_id}\", f\"{cat}_upp_{cw_id}\")\n",
    "    ws_sel   = sel_to_fc(ws_poly_gdb,   f\"{CW_ID_FIELD} = {cw_id}\", f\"{cat}_ws_{cw_id}\")\n",
    "\n",
    "    # check intersection\n",
    "    wet_geom = next(arcpy.da.SearchCursor(wet_sel, [\"SHAPE@\"]))[0]\n",
    "    ws_geom  = next(arcpy.da.SearchCursor(ws_sel,  [\"SHAPE@\"]))[0]\n",
    "    inter = not wet_geom.disjoint(ws_geom)\n",
    "    print(\"Watershed intersects wetland?\", inter)\n",
    "\n",
    "    # distance from snapped pourpoint to wetland (meters if projected)\n",
    "    upp_geom = next(arcpy.da.SearchCursor(upp_sel, [\"SHAPE@\"]))[0]\n",
    "    print(\"Distance snapped pourpoint -> wetland:\", upp_geom.distanceTo(wet_geom))\n",
    "\n",
    "    return wet_sel, pp_sel, upp_sel, ws_sel\n",
    "\n",
    "\n",
    "CW_Id = 415116\n",
    "\n",
    "debug_one_cw(\n",
    "    cat=\"avg\",\n",
    "    cw_id=CW_Id,\n",
    "    wet_fc=erase_buffer_avg,\n",
    "    pourpoints_fc=os.path.join(outPourpoints, \"avg_pourpoints.shp\"),\n",
    "    uniq_pp_fc=os.path.join(pp_gdb, \"avg_uniq_pp\"),\n",
    "    ws_poly_gdb=os.path.join(ws_gdb, \"avg_ws_poly\"),\n",
    "    out_gdb=r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\temp\\cw_debug_avg.gdb\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samin-arcpy1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
