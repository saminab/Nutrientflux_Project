{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Coastal Watersheds for Lake Huron Coastal Wetlands (CW)\n",
    "\n",
    "This notebook delineates **coastal watersheds** for **Lake Huron–connected coastal wetlands** under four inundation scenarios (**avg, low, high, surge**) while ensuring a **stable wetland identifier (`CW_Id`) is preserved throughout the full workflow**. The goal is to produce **one coastal watershed polygon per wetland (`CW_Id`)**, along with consistent wetland and watershed attributes needed for later merging and plotting (area + centroid coordinates).\n",
    "\n",
    "---\n",
    "\n",
    "## Key idea: keep `CW_Id` stable from start to finish\n",
    "Raster-based watershed tools can replace feature IDs with raster values (e.g., `gridcode`) and can also split features during polygon/raster conversions. To avoid ID mismatches, this workflow:\n",
    "\n",
    "- assigns and carries a stable **`CW_Id`** in all wetland layers,\n",
    "- creates **one pour point per wetland** (inside the polygon),\n",
    "- snaps pour points to the drainage network,\n",
    "- delineates watersheds using the snapped points,\n",
    "- **converts watershed outputs back to polygons** and **dissolves by `CW_Id`** so each wetland ends with **exactly one** watershed polygon.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "Main inputs used in this notebook:\n",
    "\n",
    "- **Coastal wetland polygons** (avg/low/high/surge inundation layers)\n",
    "- **Shoreline polyline** (Lake Huron US-side shoreline)\n",
    "- **Great Lakes Basin streams** (used to remove riparian/stream-connected wetland overlap)\n",
    "- **D8 flow direction raster** (hydrologic routing grid)\n",
    "- **Stream-watershed polygons** (areas draining to streams; removed from coastal watersheds)\n",
    "- **Lake Huron polygon** (removed from final watershed polygons)\n",
    "\n",
    "All distance-based operations are performed in **Great Lakes Albers (EPSG:3174)** (meters).\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs (per inundation scenario)\n",
    "For each scenario (**avg, low, high, surge**), the notebook produces:\n",
    "\n",
    "### Wetland-side products\n",
    "- **shoreline-interacting wetlands** (wetlands intersecting a 2000 m shoreline buffer)\n",
    "- **riparian-erased wetlands** (wetlands with 50 m stream-buffer overlap removed)\n",
    "- wetland attributes:\n",
    "  - `CW_Id` (stable wetland identifier)\n",
    "  - `CW_Area_m2`\n",
    "  - wetland centroid coordinates in EPSG:3174 (`CW_cx`, `CW_cy`)\n",
    "  - wetland centroid coordinates in WGS84 (`CW_lon`, `CW_lat`)\n",
    "\n",
    "### Watershed-side products\n",
    "- **pour points** (`*_pourpoints.shp`) — one point inside each wetland polygon\n",
    "- **snapped pour points** — pour points snapped to a drainage cell using flow accumulation\n",
    "- **watershed raster** (cell values correspond to `CW_Id`)\n",
    "- **watershed polygons**, dissolved by `CW_Id` (one watershed per wetland)\n",
    "- final coastal watershed polygons with attributes:\n",
    "  - `CW_Id` (matching wetland `CW_Id`)\n",
    "  - `WatershedArea_m2`\n",
    "  - watershed centroid coordinates in EPSG:3174 (`WS_cx`, `WS_cy`)\n",
    "  - watershed centroid coordinates in WGS84 (`WS_lon`, `WS_lat`)\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow summary\n",
    "For each inundation scenario (**avg/low/high/surge**):\n",
    "\n",
    "1. **Assign stable IDs**\n",
    "   - Ensure wetland polygons contain `CW_Id` and (optionally) `Coastal_Id` derived from `CW_Id`.\n",
    "\n",
    "2. **Select shoreline-interacting wetlands**\n",
    "   - Project shoreline to EPSG:3174, buffer by **2000 m**, and intersect with wetlands.\n",
    "\n",
    "3. **Remove riparian/stream overlap**\n",
    "   - Buffer streams by **50 m** and erase from the shoreline-interacting wetlands.\n",
    "\n",
    "4. **Create pour points**\n",
    "   - Dissolve wetlands by `CW_Id` and create one **inside point** per wetland (`*_pourpoints.shp`).\n",
    "\n",
    "5. **Snap pour points**\n",
    "   - Snap pour points to the drainage network using **SnapPourPoint** with flow accumulation.\n",
    "\n",
    "6. **Delineate watersheds**\n",
    "   - Use **Watershed** with the D8 flow direction raster and snapped pour points.\n",
    "\n",
    "7. **Convert to polygons + enforce 1 watershed per wetland**\n",
    "   - Convert watershed raster to polygons, set `CW_Id = gridcode`, and **dissolve by `CW_Id`**.\n",
    "\n",
    "8. **Remove non-coastal drainage + lake area**\n",
    "   - Erase stream-watershed polygons, then erase Lake Huron polygon from the watershed polygons.\n",
    "\n",
    "9. **Compute areas + centroids**\n",
    "   - Add watershed area and centroid coordinate fields for later merges and plotting.\n",
    "\n",
    "---\n",
    "\n",
    "## Notes / QA checks recommended\n",
    "- Verify **unique `CW_Id` counts** are consistent:\n",
    "  - riparian-erased wetlands vs. pour points vs. dissolved watershed polygons.\n",
    "- If counts differ, inspect:\n",
    "  - wetlands disappearing due to shoreline/riparian erases,\n",
    "  - pour points falling outside valid drainage (before snapping),\n",
    "  - watersheds splitting (should be fixed by dissolving on `CW_Id`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Requirements\n",
    "\n",
    "- ArcGIS Pro / arcpy with Spatial Analyst.\n",
    "- Flow direction raster (`D8_flow`) and **flow accumulation** raster (`FlowAcc`) on the same grid.\n",
    "- Wetland-connected polygons for each scenario (avg/high/low/surge), each with a stable id field (we standardize to `CW_Id`).\n",
    "\n",
    "**What is `avg_pourpoints.shp`?**  \n",
    "It is a **point feature class** with **one point per wetland** (per `CW_Id`). These points are snapped to the highest flow-accumulation cell nearby, then used as pour points for the Watershed tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import SnapPourPoint, Watershed\n",
    "from arcpy import sa\n",
    "import numpy as np\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "arcpy.env.addOutputsToMap = False  # helps avoid schema locks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Inputs / outputs \n",
    "\n",
    "Fill in your real paths. Keep the same projected CRS as your DEM / flow rasters (often EPSG:3174/3175 for Great Lakes Albers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Inputs\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "inDir = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\"\n",
    "inDCW = r\"D:\\Users\\abolmaal\\data\\coastalwetlands\\finalwetland\"\n",
    "CW_path = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Coastalwetland\\hitshoreline\"\n",
    "\n",
    "wetlands_avg_inun_original   = os.path.join(inDCW, \"wetlands_connected_avg_inundation_GLAlbers.shp\")\n",
    "wetlands_high_inun_original  = os.path.join(inDCW, \"wetlands_connected_high_inundation_GLAlbers.shp\")\n",
    "wetlands_low_inun_original   = os.path.join(inDCW, \"wetlands_connected_low_inundation_GLAlbers.shp\")\n",
    "wetlands_surge_original      = os.path.join(inDCW, \"wetlands_connected_surge_inundation_GLAlbers.shp\")\n",
    "\n",
    "inStreams = os.path.join(inDir, \"GLB_Stream\", \"GLB_stream_Ras_FeatureToLine.shp\")\n",
    "D8_flow   = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_dir.tif\"\n",
    "flowacc = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\"\n",
    "inStreamsWatershed = os.path.join(inDir, \"Streamwatershed\", \"PointWaterdhed_LH.shp\")\n",
    "\n",
    "Lake_Huron = r\"D:\\Users\\abolmaal\\code\\boundry\\hydro_p_LakeHuron\\hydro_p_LakeHuron.shp\"\n",
    "\n",
    "\n",
    "shoreline_fvcome = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Basins\\FVCOME\\FVCOM_shoreline.shp\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Parameters / field names\n",
    "# -------------------------------------------------------------------\n",
    "CW_ID_FIELD = \"CW_Id\"          # stable wetland id\n",
    "COASTAL_ID_FIELD = \"Coastal_Id\" # optional (we'll set equal to CW_Id unless you want different)\n",
    "COASTAL_Area_FIELD = \"CW_Aream2\"  # area of coastal watershed in m2\n",
    "Wetland_Area_FIELD = \"WS_Aream2\"  # area of wetland in m2\n",
    "crs_Albers = arcpy.SpatialReference(3174)  # Great Lakes Albers meters\n",
    "crs_WGS84  = arcpy.SpatialReference(4326)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Outputs (your folders)\n",
    "# -------------------------------------------------------------------\n",
    "outDir_stream = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\GLB_Stream\"\n",
    "outBuffer = os.path.join(outDir_stream, \"GLB_stream_Ras_FeatureToLine_50m.shp\")\n",
    "\n",
    "outpath = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\"\n",
    "outErase_Riper   = os.path.join(outpath, \"Erase_Riperian\")\n",
    "outErase_drainage= os.path.join(outpath, \"Erase_drainage\")\n",
    "outErase_Lake    = os.path.join(outpath, \"Erase_lake\")\n",
    "outPourpoints    = os.path.join(outpath, \"Pourpoints\")\n",
    "outWatersheds    = os.path.join(outpath, \"Watershed_rasters\")\n",
    "\n",
    "for d in [outDir_stream, outErase_Riper, outErase_drainage, outErase_Lake, outPourpoints, outWatersheds]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "shorebuffer = r\"D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Basins\\FVCOME\\FVCOM_shoreline_2000buffer.shp\"\n",
    "\n",
    "wetlands_avg_inun  = os.path.join(CW_path, \"Wetland_connected_avg_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "wetlands_low_inun  = os.path.join(CW_path, \"Wetland_connected_low_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "wetlands_high_inun = os.path.join(CW_path, \"Wetland_connected_high_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "wetlands_surge     = os.path.join(CW_path, \"Wetland_connected_surge_inundation_NAD1983_shorelineinteraction_buffer2000m.shp\")\n",
    "\n",
    "erase_buffer_avg   = os.path.join(outErase_Riper, \"Wetland_connected_avg_erasebuff_50.shp\")\n",
    "erase_buffer_high  = os.path.join(outErase_Riper, \"Wetland_connected_high_erasebuff_50.shp\")\n",
    "erase_buffer_low   = os.path.join(outErase_Riper, \"Wetland_connected_low_erasebuff_50.shp\")\n",
    "erase_buffer_surge = os.path.join(outErase_Riper, \"Wetland_connected_surge_erasebuff_50.shp\")\n",
    "\n",
    "CoastalWatershed_avg_erase_lakedrain  = os.path.join(outErase_drainage, \"CoastalWatershed_avg_erase_lakedrain.shp\")\n",
    "CoastalWatershed_high_erase_lakedrain = os.path.join(outErase_drainage, \"CoastalWatershed_high_erase_lakedrain.shp\")\n",
    "CoastalWatershed_low_erase_lakedrain  = os.path.join(outErase_drainage, \"CoastalWatershed_low_erase_lakedrain.shp\")\n",
    "CoastalWatershed_surge_erase_lakedrain= os.path.join(outErase_drainage, \"CoastalWatershed_surge_erase_lakedrain.shp\")\n",
    "\n",
    "CoastalWatershed_avg_erase_lakedrain_LakeHuron   = os.path.join(outErase_Lake, \"CoastalWatershed_avg_erase_lakedrain_LakeHuron.shp\")\n",
    "CoastalWatershed_high_erase_lakedrain_LakeHuron  = os.path.join(outErase_Lake, \"CoastalWatershed_high_erase_lakedrain_LakeHuron.shp\")\n",
    "CoastalWatershed_low_erase_lakedrain_LakeHuron   = os.path.join(outErase_Lake, \"CoastalWatershed_low_erase_lakedrain_LakeHuron.shp\")\n",
    "CoastalWatershed_surge_erase_lakedrain_LakeHuron = os.path.join(outErase_Lake, \"CoastalWatershed_surge_erase_lakedrain_LakeHuron.shp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Helper functions\n",
    "\n",
    "These helpers:\n",
    "\n",
    "- enforce a stable `CW_Id`\n",
    "- create **one** pour point per `CW_Id`\n",
    "- snap pour points to high flow accumulation\n",
    "- run watershed (raster) and convert back to polygons while preserving ids\n",
    "- compute areas + WGS84 centroid lat/lon\n",
    "- run sanity checks for missing ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# -------------------------------------------------------------------\n",
    "def ensure_field(fc, name, ftype=\"DOUBLE\"):\n",
    "    # Shapefile limit: 10 chars\n",
    "    if arcpy.Describe(fc).dataType == \"ShapeFile\" and len(name) > 10:\n",
    "        short = name[:10]\n",
    "        print(f\"⚠️ Shapefile field '{name}' too long -> using '{short}'\")\n",
    "        name = short\n",
    "\n",
    "    fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "    if name not in fields:\n",
    "        arcpy.management.AddField(fc, name, ftype)\n",
    "    return name\n",
    "\n",
    "def calculate_area_m2(fc, out_field):\n",
    "    out_field = ensure_field(fc, out_field, \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "        fc, [[out_field, \"AREA\"]], area_unit=\"SQUARE_METERS\"\n",
    "    )\n",
    "    return out_field\n",
    "\n",
    "def add_xy_ll(fc, prefix, src_crs=crs_Albers):\n",
    "    \"\"\"\n",
    "    Adds:\n",
    "      {prefix}_cx, {prefix}_cy  (in src_crs units, meters for 3174)\n",
    "      {prefix}_lon, {prefix}_lat (in WGS84 DD)\n",
    "    \"\"\"\n",
    "    ensure_field(fc, f\"{prefix}_cx\", \"DOUBLE\")\n",
    "    ensure_field(fc, f\"{prefix}_cy\", \"DOUBLE\")\n",
    "    arcpy.management.CalculateField(fc, f\"{prefix}_cx\", \"!SHAPE.centroid.X!\", \"PYTHON3\")\n",
    "    arcpy.management.CalculateField(fc, f\"{prefix}_cy\", \"!SHAPE.centroid.Y!\", \"PYTHON3\")\n",
    "\n",
    "    ensure_field(fc, f\"{prefix}_lon\", \"DOUBLE\")\n",
    "    ensure_field(fc, f\"{prefix}_lat\", \"DOUBLE\")\n",
    "    # CalculateGeometryAttributes supports centroid in a specified coordinate system\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "        fc,\n",
    "        [[f\"{prefix}_lat\", \"CENTROID_Y\"], [f\"{prefix}_lon\", \"CENTROID_X\"]],\n",
    "        coordinate_system=crs_WGS84,\n",
    "        coordinate_format=\"DD\"\n",
    "    )\n",
    "\n",
    "def count_ids(fc, id_field):\n",
    "    ids = set()\n",
    "    with arcpy.da.SearchCursor(fc, [id_field]) as cur:\n",
    "        for (v,) in cur:\n",
    "            if v is not None:\n",
    "                ids.add(int(v))\n",
    "    return len(ids)\n",
    "\n",
    "def make_pourpoints(wetlands_fc, out_points_fc, id_field=CW_ID_FIELD):\n",
    "    \"\"\"\n",
    "    1) Dissolve by CW_Id -> single multipart per CW_Id\n",
    "    2) FeatureToPoint INSIDE -> 1 point per CW_Id\n",
    "    \"\"\"\n",
    "    tmp_diss = os.path.join(\"in_memory\", \"tmp_diss\")\n",
    "    if arcpy.Exists(tmp_diss):\n",
    "        arcpy.management.Delete(tmp_diss)\n",
    "\n",
    "    arcpy.management.Dissolve(wetlands_fc, tmp_diss, dissolve_field=id_field)\n",
    "    arcpy.management.FeatureToPoint(tmp_diss, out_points_fc, \"INSIDE\")\n",
    "    arcpy.management.Delete(tmp_diss)\n",
    "\n",
    "def snap_pourpoints(in_points, flowacc_raster, out_points, snap_dist=\"200 Meters\"):\n",
    "    \"\"\"\n",
    "    SnapPourPoint expects a flow accumulation raster.\n",
    "    \"\"\"\n",
    "    out_ras = os.path.join(\"in_memory\", \"snapped_pp_ras\")\n",
    "    if arcpy.Exists(out_ras):\n",
    "        arcpy.management.Delete(out_ras)\n",
    "\n",
    "    # SnapPourPoint returns a raster. We'll convert to points with value preserved.\n",
    "    snapped = arcpy.sa.SnapPourPoint(in_points, flowacc_raster, snap_dist, CW_ID_FIELD)\n",
    "    snapped.save(out_ras)\n",
    "\n",
    "    # RasterToPoint creates points with \"grid_code\"\n",
    "    arcpy.conversion.RasterToPoint(out_ras, out_points, \"VALUE\")\n",
    "\n",
    "    # Move snapped raster value -> CW_Id\n",
    "    ensure_field(out_points, CW_ID_FIELD, \"LONG\")\n",
    "    arcpy.management.CalculateField(out_points, CW_ID_FIELD, \"!grid_code!\", \"PYTHON3\")\n",
    "    arcpy.management.Delete(out_ras)\n",
    "\n",
    "def watershed_from_points(flowdir, snapped_points, out_watershed_raster):\n",
    "    \"\"\"\n",
    "    Watershed raster values will equal CW_Id (because we pass CW_Id field).\n",
    "    \"\"\"\n",
    "    ws = arcpy.sa.Watershed(flowdir, snapped_points, CW_ID_FIELD)\n",
    "    ws.save(out_watershed_raster)\n",
    "\n",
    "def watershed_raster_to_polygon(ws_raster, out_poly, id_field=CW_ID_FIELD):\n",
    "    \"\"\"\n",
    "    RasterToPolygon -> gridcode. Then set CW_Id=gridcode and dissolve by CW_Id.\n",
    "    \"\"\"\n",
    "    tmp_poly = os.path.join(\"in_memory\", \"tmp_ws_poly\")\n",
    "    if arcpy.Exists(tmp_poly):\n",
    "        arcpy.management.Delete(tmp_poly)\n",
    "\n",
    "    arcpy.conversion.RasterToPolygon(ws_raster, tmp_poly, \"NO_SIMPLIFY\", \"VALUE\")\n",
    "\n",
    "    # Make sure CW_Id exists and equals gridcode\n",
    "    ensure_field(tmp_poly, id_field, \"LONG\")\n",
    "    arcpy.management.CalculateField(tmp_poly, id_field, \"!gridcode!\", \"PYTHON3\")\n",
    "\n",
    "    # Dissolve to one watershed polygon per CW_Id (removes splits)\n",
    "    arcpy.management.Dissolve(tmp_poly, out_poly, dissolve_field=id_field)\n",
    "\n",
    "    arcpy.management.Delete(tmp_poly)\n",
    "    \n",
    "def watershed_from_snapped_raster(flowdir, snapped_ras, out_watershed_raster):\n",
    "    \"\"\"\n",
    "    snapped_ras is the output of SnapPourPoint (a raster with CW_Id values).\n",
    "    Watershed output raster will keep those CW_Id values.\n",
    "    \"\"\"\n",
    "    ws = arcpy.sa.Watershed(flowdir, snapped_ras)\n",
    "    ws.save(out_watershed_raster)\n",
    "    \n",
    "    \n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _ensure_field(fc, field_name, field_type=\"LONG\"):\n",
    "    fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "    if field_name not in fields:\n",
    "        arcpy.management.AddField(fc, field_name, field_type)\n",
    "\n",
    "def unique_snap_points_to_flowacc_cells(\n",
    "    in_points_fc,\n",
    "    id_field,\n",
    "    flowacc_raster,\n",
    "    snap_dist,\n",
    "    out_points_fc,\n",
    "    max_expand_steps=3,\n",
    "    expand_factor=1.5,\n",
    "    allow_nodata=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a snapped points FC where each input point is moved to a UNIQUE raster cell\n",
    "    chosen as the highest flow accumulation cell within snap_dist (expanded if needed).\n",
    "    This guarantees 1 unique snapped cell per input ID (unless there aren't enough cells).\n",
    "    \"\"\"\n",
    "\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    r = arcpy.Raster(flowacc_raster)\n",
    "    sr = r.spatialReference\n",
    "    cellw = float(r.meanCellWidth)\n",
    "    cellh = float(r.meanCellHeight)\n",
    "    ext = r.extent\n",
    "    xmin, ymin, xmax, ymax = ext.XMin, ext.YMin, ext.XMax, ext.YMax\n",
    "\n",
    "    # Determine raster size in cells (approx, but enough for indexing)\n",
    "    ncol = int(round((xmax - xmin) / cellw))\n",
    "    nrow = int(round((ymax - ymin) / cellh))\n",
    "\n",
    "    # Create output FC\n",
    "    out_dir = os.path.dirname(out_points_fc)\n",
    "    out_name = os.path.basename(out_points_fc)\n",
    "    if arcpy.Exists(out_points_fc):\n",
    "        arcpy.management.Delete(out_points_fc)\n",
    "\n",
    "    arcpy.management.CreateFeatureclass(\n",
    "        out_dir, out_name, \"POINT\", spatial_reference=sr\n",
    "    )\n",
    "    _ensure_field(out_points_fc, id_field, \"LONG\")\n",
    "\n",
    "    # Build a quick index of all input points\n",
    "    pts = []\n",
    "    with arcpy.da.SearchCursor(in_points_fc, [\"SHAPE@XY\", id_field]) as cur:\n",
    "        for (x, y), cid in cur:\n",
    "            if cid is None:\n",
    "                continue\n",
    "            pts.append((float(x), float(y), int(cid)))\n",
    "\n",
    "    used_cells = set()  # (row_top, col)\n",
    "\n",
    "    def xy_to_rowcol_top(x, y):\n",
    "        col = int((x - xmin) / cellw)\n",
    "        row_top = int((ymax - y) / cellh)\n",
    "        return row_top, col\n",
    "\n",
    "    def rowcol_top_to_cellcenter(row_top, col):\n",
    "        x = xmin + (col + 0.5) * cellw\n",
    "        y = ymax - (row_top + 0.5) * cellh\n",
    "        return x, y\n",
    "\n",
    "    def window_to_numpy(row_top, col, rad_cells):\n",
    "        # clamp window bounds in raster indices\n",
    "        r0 = max(0, row_top - rad_cells)\n",
    "        r1 = min(nrow - 1, row_top + rad_cells)\n",
    "        c0 = max(0, col - rad_cells)\n",
    "        c1 = min(ncol - 1, col + rad_cells)\n",
    "\n",
    "        # lower-left corner of the window in map units\n",
    "        x_ll = xmin + c0 * cellw\n",
    "        y_ll = ymax - (r1 + 1) * cellh\n",
    "\n",
    "        nrows = (r1 - r0 + 1)\n",
    "        ncols = (c1 - c0 + 1)\n",
    "\n",
    "        # IMPORTANT: integer rasters can't use NaN for nodata_to_value\n",
    "        nodata_sentinel = -9999\n",
    "\n",
    "        arr = arcpy.RasterToNumPyArray(\n",
    "            r,\n",
    "            lower_left_corner=arcpy.Point(x_ll, y_ll),\n",
    "            ncols=ncols,\n",
    "            nrows=nrows,\n",
    "            nodata_to_value=nodata_sentinel\n",
    "        )\n",
    "\n",
    "        # convert to float and set sentinel to NaN\n",
    "        arr = arr.astype(\"float64\")\n",
    "        arr[arr == nodata_sentinel] = np.nan\n",
    "\n",
    "        return arr, (r0, r1, c0, c1)\n",
    "\n",
    "    def pick_best_unused_cell(arr, bounds):\n",
    "        r0, r1, c0, c1 = bounds\n",
    "        nrows, ncols = arr.shape\n",
    "\n",
    "        # Flatten and sort by flowacc descending (nan ignored)\n",
    "        flat = arr.ravel()\n",
    "        valid_idx = np.where(np.isfinite(flat))[0]\n",
    "        if valid_idx.size == 0:\n",
    "            return None\n",
    "\n",
    "        order = valid_idx[np.argsort(flat[valid_idx])[::-1]]\n",
    "\n",
    "        for k in order:\n",
    "            i = k // ncols   # array row index (0=bottom)\n",
    "            j = k % ncols\n",
    "\n",
    "            # convert (i,j) -> global raster (row_top, col)\n",
    "            row_top = r1 - i\n",
    "            col = c0 + j\n",
    "\n",
    "            if (row_top, col) in used_cells:\n",
    "                continue\n",
    "\n",
    "            # if you want to forbid snapping into nodata/invalid, array already NaN-handled\n",
    "            return row_top, col, float(arr[i, j])\n",
    "\n",
    "        return None\n",
    "\n",
    "    missing = []\n",
    "\n",
    "    with arcpy.da.InsertCursor(out_points_fc, [\"SHAPE@XY\", id_field]) as icur:\n",
    "        for x, y, cid in pts:\n",
    "            row_top, col = xy_to_rowcol_top(x, y)\n",
    "\n",
    "            # start radius in cells\n",
    "            base_rad = int(np.ceil(snap_dist / cellw))\n",
    "\n",
    "            chosen = None\n",
    "            rad = base_rad\n",
    "\n",
    "            for step in range(max_expand_steps + 1):\n",
    "                arr, bounds = window_to_numpy(row_top, col, rad)\n",
    "                chosen = pick_best_unused_cell(arr, bounds)\n",
    "                if chosen is not None:\n",
    "                    break\n",
    "                rad = int(np.ceil(rad * expand_factor))\n",
    "\n",
    "            if chosen is None:\n",
    "                missing.append(cid)\n",
    "                continue\n",
    "\n",
    "            rtop, c, val = chosen\n",
    "            used_cells.add((rtop, c))\n",
    "\n",
    "            sx, sy = rowcol_top_to_cellcenter(rtop, c)\n",
    "            icur.insertRow(((sx, sy), cid))\n",
    "\n",
    "    print(f\"✅ unique snapped points created: {len(pts) - len(missing)} / {len(pts)}\")\n",
    "    if missing:\n",
    "        print(f\"⚠️ Could not snap {len(missing)} points (no valid unused cells found). Example IDs: {missing[:10]}\")\n",
    "    return out_points_fc\n",
    "\n",
    "\n",
    "def remove_overlaps_by_priority(in_fc, id_field, out_fc):\n",
    "    _safe_delete(out_fc)\n",
    "\n",
    "    # copy first\n",
    "    tmp = os.path.join(ws_gdb, \"tmp_nooverlap_copy\")\n",
    "    _safe_delete(tmp)\n",
    "    gp(\"Copy for no-overlap\", arcpy.management.CopyFeatures, in_fc, tmp)\n",
    "\n",
    "    # add area\n",
    "    area_f = _ensure_field(tmp, \"A_M2\", \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(tmp, [[area_f, \"AREA\"]], area_unit=\"SQUARE_METERS\")\n",
    "\n",
    "    # sort by area desc (biggest wins)\n",
    "    sorted_fc = os.path.join(ws_gdb, \"tmp_nooverlap_sorted\")\n",
    "    _safe_delete(sorted_fc)\n",
    "    gp(\"Sort by area\", arcpy.management.Sort, tmp, sorted_fc, [[area_f, \"DESCENDING\"]])\n",
    "\n",
    "    # iterative erase\n",
    "    kept = os.path.join(ws_gdb, \"tmp_nooverlap_kept\")\n",
    "    _safe_delete(kept)\n",
    "    gp(\"Create kept FC\", arcpy.management.CopyFeatures, sorted_fc, kept)  # start with all, then we'll rebuild\n",
    "\n",
    "    _safe_delete(kept)\n",
    "    gp(\"Create empty kept FC\", arcpy.management.CreateFeatureclass,\n",
    "       ws_gdb, os.path.basename(kept), \"POLYGON\", sorted_fc, \"DISABLED\", \"DISABLED\", D8_SR)\n",
    "\n",
    "    kept_id = _ensure_field(kept, id_field, \"LONG\")\n",
    "\n",
    "    # process one by one\n",
    "    lyr = \"lyr_sorted\"\n",
    "    arcpy.management.MakeFeatureLayer(sorted_fc, lyr)\n",
    "\n",
    "    oids = [r[0] for r in arcpy.da.SearchCursor(sorted_fc, [arcpy.Describe(sorted_fc).OIDFieldName])]\n",
    "    for oid in oids:\n",
    "        arcpy.management.SelectLayerByAttribute(lyr, \"NEW_SELECTION\", f\"OBJECTID = {oid}\")\n",
    "        piece = os.path.join(ws_gdb, \"tmp_piece\")\n",
    "        _safe_delete(piece)\n",
    "        arcpy.management.CopyFeatures(lyr, piece)\n",
    "\n",
    "        # erase with what we've already kept\n",
    "        if int(arcpy.management.GetCount(kept)[0]) > 0:\n",
    "            erased = os.path.join(ws_gdb, \"tmp_piece_erased\")\n",
    "            _safe_delete(erased)\n",
    "            arcpy.analysis.Erase(piece, kept, erased)\n",
    "            _safe_delete(piece)\n",
    "            piece = erased\n",
    "\n",
    "        if int(arcpy.management.GetCount(piece)[0]) > 0:\n",
    "            arcpy.management.Append(piece, kept, \"NO_TEST\")\n",
    "\n",
    "        _safe_delete(piece)\n",
    "\n",
    "    arcpy.management.Delete(lyr)\n",
    "\n",
    "    # final dissolve back to CW_Id\n",
    "    gp(\"Dissolve no-overlap result\", arcpy.management.Dissolve, kept, out_fc, id_field)\n",
    "\n",
    "    _safe_delete(tmp); _safe_delete(sorted_fc); _safe_delete(kept)\n",
    "    return out_fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 0) Add stable CW_Id, Coastal wetland area to ORIGINAL wetlands (IMPORTANT FIX)\n",
    "#    Use existing \"Id\" if present; else fallback to OBJECTID/FID.\n",
    "# ------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ensured fields + IDs + area on: wetlands_connected_avg_inundation_GLAlbers.shp\n",
      "✅ ensured fields + IDs + area on: wetlands_connected_high_inundation_GLAlbers.shp\n",
      "✅ ensured fields + IDs + area on: wetlands_connected_low_inundation_GLAlbers.shp\n",
      "✅ ensured fields + IDs + area on: wetlands_connected_surge_inundation_GLAlbers.shp\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Parameters / field names\n",
    "# -------------------------------------------------------------------\n",
    "CW_ID_FIELD        = \"CW_Id\"            # stable wetland id\n",
    "COASTAL_ID_FIELD   = \"Coastal_Id\"       # optional (set equal to CW_Id here)\n",
    "COASTAL_AREA_FIELD = \"CW_Aream2\"  # (here: wetland polygon area in m²)\n",
    "\n",
    "wetlands_fcs = [\n",
    "    wetlands_avg_inun_original,\n",
    "    wetlands_high_inun_original,\n",
    "    wetlands_low_inun_original,\n",
    "    wetlands_surge_original,\n",
    "]\n",
    "\n",
    "for fc in wetlands_fcs:\n",
    "\n",
    "    # 1) Ensure fields exist (adds them if missing)\n",
    "    ensure_field(fc, CW_ID_FIELD, \"LONG\")\n",
    "    ensure_field(fc, COASTAL_ID_FIELD, \"LONG\")\n",
    "    ensure_field(fc, COASTAL_AREA_FIELD, \"DOUBLE\")\n",
    "\n",
    "    # 2) Re-read fields AFTER ensuring (important!)\n",
    "    fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "\n",
    "    # 3) Populate CW_Id and Coastal_Id\n",
    "    if \"Id\" in fields:\n",
    "        arcpy.management.CalculateField(fc, CW_ID_FIELD, \"!Id!\", \"PYTHON3\")\n",
    "        arcpy.management.CalculateField(fc, COASTAL_ID_FIELD, \"!Id!\", \"PYTHON3\")\n",
    "    else:\n",
    "        oid = arcpy.Describe(fc).OIDFieldName\n",
    "        arcpy.management.CalculateField(fc, CW_ID_FIELD, f\"!{oid}!\", \"PYTHON3\")\n",
    "        arcpy.management.CalculateField(fc, COASTAL_ID_FIELD, f\"!{oid}!\", \"PYTHON3\")\n",
    "\n",
    "    # 4) Compute polygon area (m²) for THIS layer (wetland area)\n",
    "    #    This uses the dataset CRS units. If fc is EPSG:3174, area will be m².\n",
    "    try:\n",
    "        arcpy.management.CalculateGeometryAttributes(\n",
    "            fc,\n",
    "            [[COASTAL_AREA_FIELD, \"AREA\"]],\n",
    "            area_unit=\"SQUARE_METERS\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not calculate {COASTAL_AREA_FIELD} for {os.path.basename(fc)}: {e}\")\n",
    "\n",
    "    print(f\"✅ ensured fields + IDs + area on: {os.path.basename(fc)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89701f25",
   "metadata": {},
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Shoreline buffer (2000m) in EPSG:3174\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6911cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Tuesday, January 20, 2026 3:55:19 PM<br>Succeeded at Tuesday, January 20, 2026 3:55:19 PM (Elapsed Time: 0.01 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoreline_3174 = os.path.join(\"in_memory\", \"shoreline_3174\")\n",
    "arcpy.management.Project(shoreline_fvcome, shoreline_3174, crs_Albers)\n",
    "\n",
    "if not arcpy.Exists(shorebuffer):\n",
    "    arcpy.analysis.Buffer(shoreline_3174, shorebuffer, \"2000 Meters\", dissolve_option=\"ALL\")\n",
    "\n",
    "arcpy.management.Delete(shoreline_3174)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b52293",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 2) Intersect wetlands with shoreline buffer (keeps CW_Id)\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1a69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cw_pairs = [\n",
    "#     (wetlands_avg_inun_original,  wetlands_avg_inun),\n",
    "#     (wetlands_low_inun_original,  wetlands_low_inun),\n",
    "#     (wetlands_high_inun_original, wetlands_high_inun),\n",
    "#     (wetlands_surge_original,     wetlands_surge),\n",
    "# ]\n",
    "\n",
    "# for in_fc, out_fc in cw_pairs:\n",
    "#     # project wetlands to 3174\n",
    "#     tmp_3174 = os.path.join(\"in_memory\", \"cw_3174\")\n",
    "#     arcpy.management.Project(in_fc, tmp_3174, crs_Albers)\n",
    "\n",
    "#     tmp_int = os.path.join(\"in_memory\", \"cw_int\")\n",
    "#     arcpy.analysis.Intersect([tmp_3174, shorebuffer], tmp_int, \"ALL\")\n",
    "\n",
    "#     # Save in 3174 (recommended). If you really need original CRS, project back here.\n",
    "#     arcpy.management.CopyFeatures(tmp_int, out_fc)\n",
    "\n",
    "#     arcpy.management.Delete(tmp_3174)\n",
    "#     arcpy.management.Delete(tmp_int)\n",
    "\n",
    "#     print(f\"✅ shoreline-intersect: {os.path.basename(out_fc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cb190",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 2) Stream riparian buffer 50 m + erase wetlands (keeps CW_Id)\n",
    "- Create a 50 meter buffer for Great lakes basin streams (This is riverin Riperian area)\n",
    "-  Erase your coastal wetlands that overlap with Riperian area(GLB streams)\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf2392f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Tuesday, January 20, 2026 3:57:49 PM<br>Reading Features...<br>Cracking Features...<br>Assembling Features...<br>Succeeded at Tuesday, January 20, 2026 3:58:02 PM (Elapsed Time: 13.04 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'D:\\\\Users\\\\abolmaal\\\\Arcgis\\\\NASAOceanProject\\\\GIS_layer\\\\CoastalWatersheds\\\\Erase_Riperian\\\\Wetland_connected_surge_erasebuff_50.shp'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not arcpy.Exists(outBuffer):\n",
    "    arcpy.analysis.Buffer(inStreams, outBuffer, \"50 Meters\")\n",
    "\n",
    "arcpy.analysis.Erase(wetlands_avg_inun_original, outBuffer, erase_buffer_avg)\n",
    "arcpy.analysis.Erase(wetlands_high_inun_original, outBuffer, erase_buffer_high)\n",
    "arcpy.analysis.Erase(wetlands_low_inun_original, outBuffer, erase_buffer_low)\n",
    "arcpy.analysis.Erase(wetlands_surge_original, outBuffer, erase_buffer_surge)\n",
    "\n",
    "#arcpy.management.ClearWorkspaceCache()\n",
    "# add wetland areas and coordinates\n",
    "# for fc in [erase_buffer_avg, erase_buffer_high, erase_buffer_low, erase_buffer_surge]:\n",
    "#     # shorter name for SHP + avoids long names anyway\n",
    "#     #calculate_area_m2(fc, \"CW_Area_m2\")     # if this is SHP it's OK (<10 chars)\n",
    "#     add_xy_ll(fc, prefix=\"CW\")\n",
    "#     print(f\"✅ wetland attrs added: {os.path.basename(fc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411dd475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added field CW_cx to Wetland_connected_avg_erasebuff_50.shp\n",
      "✅ Added field CW_cy to Wetland_connected_avg_erasebuff_50.shp\n",
      "✅ Calculated CW_cx/CW_cy/CW_Aream2 for: Wetland_connected_avg_erasebuff_50.shp\n",
      "✅ Added field CW_cx to Wetland_connected_high_erasebuff_50.shp\n",
      "✅ Added field CW_cy to Wetland_connected_high_erasebuff_50.shp\n",
      "✅ Calculated CW_cx/CW_cy/CW_Aream2 for: Wetland_connected_high_erasebuff_50.shp\n",
      "✅ Added field CW_cx to Wetland_connected_low_erasebuff_50.shp\n",
      "✅ Added field CW_cy to Wetland_connected_low_erasebuff_50.shp\n",
      "✅ Calculated CW_cx/CW_cy/CW_Aream2 for: Wetland_connected_low_erasebuff_50.shp\n",
      "✅ Added field CW_cx to Wetland_connected_surge_erasebuff_50.shp\n",
      "✅ Added field CW_cy to Wetland_connected_surge_erasebuff_50.shp\n",
      "✅ Calculated CW_cx/CW_cy/CW_Aream2 for: Wetland_connected_surge_erasebuff_50.shp\n"
     ]
    }
   ],
   "source": [
    "# Add CW_cx and CW_cy to the erase_buffer_avg\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# ---- inputs (your shapefiles) ----\n",
    "shps = [\n",
    "    erase_buffer_avg,\n",
    "    erase_buffer_high,\n",
    "    erase_buffer_low,\n",
    "    erase_buffer_surge\n",
    "]\n",
    "\n",
    "TARGET_CRS = arcpy.SpatialReference(3174)  # NAD_1983_Great_Lakes_Basin_Albers\n",
    "\n",
    "def ensure_field(fc, name, ftype=\"DOUBLE\"):\n",
    "    existing = [f.name for f in arcpy.ListFields(fc)]\n",
    "    if name not in existing:\n",
    "        arcpy.management.AddField(fc, name, ftype)\n",
    "        print(f\"✅ Added field {name} to {os.path.basename(fc)}\")\n",
    "\n",
    "def add_centroid_and_area_3174(fc):\n",
    "    # Ensure fields exist\n",
    "    ensure_field(fc, \"CW_cx\", \"DOUBLE\")\n",
    "    ensure_field(fc, \"CW_cy\", \"DOUBLE\")\n",
    "    ensure_field(fc, \"CW_Aream2\", \"DOUBLE\")\n",
    "\n",
    "    # If fc not in 3174, project geometry on-the-fly for centroid/area calculations\n",
    "    sr = arcpy.Describe(fc).spatialReference\n",
    "    needs_proj = (sr is None) or (sr.factoryCode != 3174)\n",
    "\n",
    "    fields = [\"SHAPE@\", \"CW_cx\", \"CW_cy\", \"CW_Aream2\"]\n",
    "    with arcpy.da.UpdateCursor(fc, fields) as cur:\n",
    "        for shp, cx, cy, area in cur:\n",
    "            if shp is None:\n",
    "                continue\n",
    "\n",
    "            geom = shp.projectAs(TARGET_CRS) if needs_proj else shp\n",
    "\n",
    "            c = geom.centroid\n",
    "            cx_new, cy_new = c.X, c.Y\n",
    "            area_new = geom.area  # m² in 3174\n",
    "\n",
    "            cur.updateRow((shp, cx_new, cy_new, area_new))\n",
    "\n",
    "    print(f\"✅ Calculated CW_cx/CW_cy/CW_Aream2 for: {os.path.basename(fc)}\")\n",
    "\n",
    "# ---- run on all four ----\n",
    "for fc in shps:\n",
    "    add_centroid_and_area_3174(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585762f2",
   "metadata": {},
   "source": [
    "## Step 4 — Create **1:1 Coastal-Wetland Watersheds** (Pourpoints → Snap → Watershed → Polygons → **Clip overlaps** → **Repair missing IDs**)\n",
    "\n",
    "This cell delineates **one coastal watershed per coastal wetland (`CW_Id`)** for each inundation category (**avg/high/low/surge**), while ensuring the identifier **`CW_Id` remains 1:1** throughout the workflow.\n",
    "\n",
    "Unlike earlier versions that could *drop entire IDs* when wetlands were in-lake or when watersheds overlapped stream-drainage areas, this updated workflow:\n",
    "\n",
    "* **keeps every `CW_Id`**, even if the wetland is partially/fully in the lake,\n",
    "* **clips out only the overlapping portions** (lake interior and stream-watershed overlap),\n",
    "* and **repairs** missing IDs caused by raster snapping collisions by rebuilding only the missing IDs one-by-one.\n",
    "\n",
    "It is also designed to avoid common ArcPy issues (schema locks, field-name limits in shapefiles, field-case mismatches, and SnapPourPoint ID collapsing).\n",
    "\n",
    "---\n",
    "\n",
    "### What this cell produces (per inundation category: avg/high/low/surge)\n",
    "\n",
    "For each category, the cell creates:\n",
    "\n",
    "* **Pourpoints (GDB feature class)**: one point per `CW_Id` (land-only + fallback for lake-only IDs)\n",
    "* **Snapped pourpoints (GDB feature class)**: snapped onto high-flowacc land cells (using `flowacc_land`)\n",
    "* **Watershed raster (GDB raster)**: watershed labels equal to `CW_Id`\n",
    "* **Watershed polygons (GDB feature class)**: raster converted to polygons and dissolved to **one polygon per `CW_Id`**\n",
    "* **Clipped watershed polygons (final)**: only the portions overlapping:\n",
    "\n",
    "  * **Lake Huron interior**, and\n",
    "  * **stream-watershed mask**\n",
    "    are removed (the rest of the polygon is preserved)\n",
    "* **Repaired final outputs (shapefiles)**:\n",
    "\n",
    "  * `*_erase_lakedrain_LakeHuron.shp` (one feature per `CW_Id`, after clip + repair)\n",
    "* **Final attributes added to the final shapefile** (when possible):\n",
    "\n",
    "  * `WS_AREAM2` = watershed area (m²)\n",
    "  * `WS_cx`, `WS_cy` = centroid X/Y in dataset CRS\n",
    "  * `WS_lon`, `WS_lat` = centroid lon/lat in WGS84\n",
    "\n",
    "---\n",
    "\n",
    "### Why “pourpoints” matter\n",
    "\n",
    "A **pour point** is the location Spatial Analyst uses to define **which upstream cells contribute** to that outlet.\n",
    "Here, each wetland gets **exactly one pourpoint per `CW_Id`**, which drives the “one watershed per wetland” requirement.\n",
    "\n",
    "---\n",
    "\n",
    "### Updated snapping logic (and why it differs from the older “unique snap” approach)\n",
    "\n",
    "Previously, strict uniqueness snapping (one raster cell per point) was used to prevent ID collisions. In practice, nearshore lake-only wetlands can still collide at shoreline cells and/or fail to reach land.\n",
    "\n",
    "This updated workflow uses a **two-stage strategy**:\n",
    "\n",
    "1. **Bulk snapping** (fast): uses SnapPourPoint on a land-only flowacc surface (`flowacc_land`)\n",
    "2. **Repair pass** (precise): if any `CW_Id` is missing after delineation + clipping, rebuild just those IDs **one-by-one** to eliminate raster collisions.\n",
    "\n",
    "This preserves performance (bulk) while guaranteeing completeness (repair).\n",
    "\n",
    "---\n",
    "\n",
    "### Core processing steps inside the loop (per category)\n",
    "\n",
    "#### 0) Environment + workspaces (no C:\\ temp writes)\n",
    "\n",
    "* All intermediates are written to:\n",
    "\n",
    "  * `watersheds.gdb` (under `outWatersheds`)\n",
    "  * `pourpoints.gdb` (under `outPourpoints`)\n",
    "* Processing is aligned to the D8 grid:\n",
    "\n",
    "  * `snapRaster = D8_flow`\n",
    "  * `extent = D8_flow`\n",
    "  * `cellSize = D8_flow`\n",
    "  * `outputCoordinateSystem = D8_SR`\n",
    "\n",
    "---\n",
    "\n",
    "#### 1) Build masks once (outside the loop)\n",
    "\n",
    "* **Stream-watershed mask**\n",
    "\n",
    "  * CRS fixed if mislabeled, geometry repaired, dissolved, and (optionally) buffered slightly\n",
    "* **Lake Huron polygon**\n",
    "\n",
    "  * CRS corrected and projected to D8 CRS\n",
    "* **Land-only flowacc surface**\n",
    "\n",
    "  * `flowacc_land = flowacc` with lake cells set to NoData\n",
    "  * ensures snapping targets land cells only\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) Prepare wetlands and authoritative CW_Id list\n",
    "\n",
    "* Wetlands are projected to D8 CRS and repaired\n",
    "* **Original wetlands dissolved by `CW_Id`** to guarantee:\n",
    "\n",
    "  * one feature per ID\n",
    "  * a definitive list of all IDs that must exist in the final output\n",
    "\n",
    "✅ Output: `{cat}_wet_orig_diss` (GDB)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) Create pourpoints (one per CW_Id, including lake-only)\n",
    "\n",
    "* Create **land-only wetlands** by erasing the lake, then dissolve by `CW_Id`\n",
    "* Create pourpoints inside land-only dissolved polygons (1 per CW_Id)\n",
    "* Identify **lake-only IDs** (present in original dissolve but missing from land-only dissolve)\n",
    "* Create fallback pourpoints for lake-only IDs using the **original dissolved** polygons\n",
    "* Append fallback points into the pourpoint set\n",
    "\n",
    "✅ Output: `{cat}_pp_inside` (GDB; 1 point per CW_Id target)\n",
    "\n",
    "---\n",
    "\n",
    "#### 4) Snap pourpoints to land-only high-flowacc cells (bulk)\n",
    "\n",
    "* Convert pourpoints to raster (VALUE = `CW_Id`)\n",
    "* Snap via:\n",
    "\n",
    "  * `SnapPourPoint(pour_raster, flowacc_land, snap_dist_m)`\n",
    "* Convert snapped raster back to points and confirm ID coverage\n",
    "\n",
    "✅ Outputs:\n",
    "\n",
    "* `{cat}_pp_snapped_pts`\n",
    "* `{cat}_pp_snap_ras`\n",
    "\n",
    "---\n",
    "\n",
    "#### 5) Delineate watershed raster (VALUE = CW_Id)\n",
    "\n",
    "* `Watershed(D8_flow, snapped_pourpoint_raster)`\n",
    "* Produces a raster where each watershed is labeled by `CW_Id`\n",
    "\n",
    "✅ Output: `{cat}_ws_ras`\n",
    "\n",
    "---\n",
    "\n",
    "#### 6) Raster → polygon + dissolve to one feature per CW_Id\n",
    "\n",
    "* `RasterToPolygon` creates `GRIDCODE`\n",
    "* Compute `CW_Id = GRIDCODE`\n",
    "* Dissolve by `CW_Id` to enforce **one polygon per wetland**\n",
    "\n",
    "✅ Output: `{cat}_ws_poly`\n",
    "\n",
    "---\n",
    "\n",
    "#### 7) Clip overlaps (remove only the overlapping parts)\n",
    "\n",
    "To avoid dropping whole watersheds, lake/stream constraints are applied as **polygon clip operations**, not as raster masks:\n",
    "\n",
    "* Erase **Lake Huron** interior from watershed polygons\n",
    "* Erase **stream-watershed mask** overlap from watershed polygons\n",
    "* Dissolve again by `CW_Id`\n",
    "\n",
    "✅ Output: final category shapefile `CoastalWatershed_{cat}_erase_lakedrain_LakeHuron.shp`\n",
    "\n",
    "---\n",
    "\n",
    "#### 8) Repair missing IDs (guarantee 1:1 output)\n",
    "\n",
    "After clipping, some IDs may still be missing due to:\n",
    "\n",
    "* SnapPourPoint raster collisions (multiple IDs snapped to same cell), or\n",
    "* the clipped result becoming empty for a rare ID\n",
    "\n",
    "Repair strategy:\n",
    "\n",
    "* Compare final `CW_Id`s to the authoritative list (`wet_orig_diss`)\n",
    "* For each missing `CW_Id`:\n",
    "\n",
    "  * rebuild watershed **one-by-one** from its pourpoint (avoids collisions),\n",
    "  * clip lake/stream overlaps,\n",
    "  * append to final output,\n",
    "  * dissolve to enforce one feature per `CW_Id`\n",
    "\n",
    "This step ensures the final output is as close as possible to **1 polygon per wetland ID** while still honoring clipping rules.\n",
    "\n",
    "---\n",
    "\n",
    "### Built-in sanity checks (what to watch in the console)\n",
    "\n",
    "The cell prints (per category):\n",
    "\n",
    "* `unique wetland IDs (original, dissolved)`\n",
    "* `unique snapped pourpoint IDs (target wet_n)`\n",
    "* `watersheds BEFORE clipping unique IDs`\n",
    "* `final watersheds AFTER clip unique IDs`\n",
    "* `Missing IDs after clip`\n",
    "* `final watersheds AFTER rebuild`\n",
    "\n",
    "---\n",
    "\n",
    "### Common adjustments you may want\n",
    "\n",
    "* If many IDs are missing after clip:\n",
    "\n",
    "  * increase `snap_dist_m` (lake-only points may need more distance to reach land)\n",
    "  * reduce stream buffer distance if it removes too much nearshore area\n",
    "* If you get schema lock issues:\n",
    "\n",
    "  * close attribute tables, stop drawing layers, avoid adding outputs to map during run\n",
    "* If the repair step runs long:\n",
    "\n",
    "  * it scales with the number of missing IDs; reducing collision likelihood (snap distance + point density) reduces repair workload\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c88963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ flowacc: S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\n",
      "✅ workspace: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:207: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:207: SyntaxWarning: invalid escape sequence '\\)'\n",
      "C:\\Users\\abolmaal\\AppData\\Local\\Temp\\ipykernel_36968\\1971050200.py:207: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  All temp writes stay in ws_gdb (no C:\\).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ scratch:   D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n",
      "✅ D8_flow CRS: NAD_1983_Great_Lakes_Basin_Albers (factoryCode=3174)\n",
      "\n",
      "[inStreamsWS] input: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Streamwatershed\\PointWaterdhed_LH.shp\n",
      "[inStreamsWS] sr: GCS_WGS_1984 | factoryCode=4326 | type=Geographic\n",
      "[inStreamsWS] extent: XMin=929846.850 XMax=1166434.867 YMin=651452.122 YMax=1020243.911\n",
      "▶ CopyFeatures inStreamsWS\n",
      "✅ DONE CopyFeatures inStreamsWS (0.01 min)\n",
      "[inStreamsWS] ⚠️ MISLABELED Geographic but coords are projected. SKIP Project; DefineProjection -> NAD_1983_Great_Lakes_Basin_Albers\n",
      "▶ DefineProjection inStreamsWS\n",
      "✅ DONE DefineProjection inStreamsWS (0.00 min)\n",
      "▶ Copy to output inStreamsWS\n",
      "✅ DONE Copy to output inStreamsWS (0.01 min)\n",
      "▶ RepairGeometry stream mask\n",
      "✅ DONE RepairGeometry stream mask (0.00 min)\n",
      "▶ MultipartToSinglepart stream mask\n",
      "✅ DONE MultipartToSinglepart stream mask (0.01 min)\n",
      "▶ Dissolve stream mask\n",
      "✅ DONE Dissolve stream mask (0.01 min)\n",
      "▶ Buffer stream mask\n",
      "✅ DONE Buffer stream mask (0.03 min)\n",
      "\n",
      "[LakeHuron] input: D:\\Users\\abolmaal\\code\\boundry\\hydro_p_LakeHuron\\hydro_p_LakeHuron.shp\n",
      "[LakeHuron] sr: Geographic | factoryCode=0 | type=Geographic\n",
      "[LakeHuron] extent: XMin=-84.752 XMax=-79.668 YMin=42.996 YMax=46.333\n",
      "▶ CopyFeatures LakeHuron\n",
      "✅ DONE CopyFeatures LakeHuron (0.01 min)\n",
      "[LakeHuron] ⚠️ GENERIC geographic degrees. DefineProjection -> EPSG:4326 then Project.\n",
      "▶ DefineProjection LakeHuron\n",
      "✅ DONE DefineProjection LakeHuron (0.00 min)\n",
      "[LakeHuron] Project -> NAD_1983_Great_Lakes_Basin_Albers | transform=WGS_1984_(ITRF00)_To_NAD_1983\n",
      "▶ Project LakeHuron\n",
      "✅ DONE Project LakeHuron (0.01 min)\n",
      "▶ RepairGeometry lake\n",
      "✅ DONE RepairGeometry lake (0.00 min)\n",
      "▶ PolygonToRaster LakeHuron_mask_ras\n",
      "✅ DONE PolygonToRaster LakeHuron_mask_ras (0.14 min)\n",
      "✅ lake_mask_ras: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\\LakeHuron_mask_ras\n",
      "▶ Build flowacc_land = flowacc where NOT lake\n",
      "✅ flowacc_land: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\\flowacc_land\n",
      "\n",
      "==================== HIGH ====================\n",
      "▶ [high] Project wetlands\n",
      "✅ DONE [high] Project wetlands (0.01 min)\n",
      "▶ [high] RepairGeometry wetlands\n",
      "✅ DONE [high] RepairGeometry wetlands (0.08 min)\n",
      "▶ [high] Dissolve ORIGINAL wetlands by CW_Id\n",
      "✅ DONE [high] Dissolve ORIGINAL wetlands by CW_Id (0.06 min)\n",
      "[high] unique wetland IDs (original, dissolved): 12135\n",
      "▶ [high] Erase lake from wetlands (land-only)\n",
      "✅ DONE [high] Erase lake from wetlands (land-only) (0.03 min)\n",
      "▶ [high] Dissolve land-only wetlands by CW_Id\n",
      "✅ DONE [high] Dissolve land-only wetlands by CW_Id (0.04 min)\n",
      "[high] unique wetland IDs (land-only, dissolved): 7570\n",
      "▶ [high] FeatureToPoint INSIDE (land-only dissolved)\n",
      "✅ DONE [high] FeatureToPoint INSIDE (land-only dissolved) (0.01 min)\n",
      "⚠️ [high] 4565 wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\n",
      "▶ [high missing] Copy selected\n",
      "✅ DONE [high missing] Copy selected (0.01 min)\n",
      "▶ [high] FeatureToPoint INSIDE (fallback dissolved)\n",
      "✅ DONE [high] FeatureToPoint INSIDE (fallback dissolved) (0.01 min)\n",
      "▶ [high] Append fallback points\n",
      "✅ DONE [high] Append fallback points (0.01 min)\n",
      "▶ [high] PointToRaster pourpoints\n",
      "✅ DONE [high] PointToRaster pourpoints (0.16 min)\n",
      "[high] SnapPourPoint distance = 150 m (land-only)\n",
      "▶ [high] RasterToPoint snapped pourpoints\n",
      "✅ DONE [high] RasterToPoint snapped pourpoints (0.09 min)\n",
      "▶ [high] Calculate CW_Id on snapped points\n",
      "✅ DONE [high] Calculate CW_Id on snapped points (0.01 min)\n",
      "[high] unique snapped pourpoint IDs: 11630 (target 12135)\n",
      "▶ [high] PointToRaster snapped points\n",
      "✅ DONE [high] PointToRaster snapped points (0.15 min)\n",
      "▶ [high] Watershed\n",
      "✅ DONE [high] Watershed (0.87 min)\n",
      "▶ [high] RasterToPolygon\n",
      "✅ DONE [high] RasterToPolygon (0.14 min)\n",
      "▶ [high] Calculate CW_Id on watershed polygons\n",
      "✅ DONE [high] Calculate CW_Id on watershed polygons (0.01 min)\n",
      "▶ [high] Dissolve watersheds by CW_Id\n",
      "✅ DONE [high] Dissolve watersheds by CW_Id (0.11 min)\n",
      "[high] watersheds BEFORE clipping unique IDs: 11630 (target 12135)\n",
      "▶ [high] Erase lake from watersheds (clip)\n",
      "✅ DONE [high] Erase lake from watersheds (clip) (0.03 min)\n",
      "▶ [high] Erase stream mask from watersheds (clip)\n",
      "✅ DONE [high] Erase stream mask from watersheds (clip) (0.01 min)\n",
      "▶ [high] Dissolve final output (clip result)\n",
      "✅ DONE [high] Dissolve final output (clip result) (0.04 min)\n",
      "[high] final watersheds AFTER clip unique IDs: 8412 (target 12135)\n",
      "[high] Missing IDs after clip: 3723\n",
      "▶ [high] Copy missing pourpoints\n",
      "✅ DONE [high] Copy missing pourpoints (0.01 min)\n",
      "▶ [high] Near(missing pts -> final watersheds)\n",
      "✅ DONE [high] Near(missing pts -> final watersheds) (0.02 min)\n",
      "▶ [high] Create assigned FC\n",
      "✅ DONE [high] Create assigned FC (0.01 min)\n",
      "[high] Assigned polygons added: 3723\n",
      "▶ [high] Append assigned -> final\n",
      "✅ DONE [high] Append assigned -> final (0.01 min)\n",
      "▶ [high] PairwiseDissolve (enforce 1 per CW_Id)\n",
      "✅ DONE [high] PairwiseDissolve (enforce 1 per CW_Id) (0.02 min)\n",
      "▶ [high] Copy enforced final\n",
      "✅ DONE [high] Copy enforced final (0.03 min)\n",
      "[high] final watersheds AFTER assignment-repair: 12135 (target 12135)\n",
      "✅ final watershed: high -> CoastalWatershed_high_erase_lakedrain_LakeHuron.shp\n",
      "\n",
      "==================== LOW ====================\n",
      "▶ [low] Project wetlands\n",
      "✅ DONE [low] Project wetlands (0.01 min)\n",
      "▶ [low] RepairGeometry wetlands\n",
      "✅ DONE [low] RepairGeometry wetlands (0.03 min)\n",
      "▶ [low] Dissolve ORIGINAL wetlands by CW_Id\n",
      "✅ DONE [low] Dissolve ORIGINAL wetlands by CW_Id (0.02 min)\n",
      "[low] unique wetland IDs (original, dissolved): 4500\n",
      "▶ [low] Erase lake from wetlands (land-only)\n",
      "✅ DONE [low] Erase lake from wetlands (land-only) (0.02 min)\n",
      "▶ [low] Dissolve land-only wetlands by CW_Id\n",
      "✅ DONE [low] Dissolve land-only wetlands by CW_Id (0.01 min)\n",
      "[low] unique wetland IDs (land-only, dissolved): 1696\n",
      "▶ [low] FeatureToPoint INSIDE (land-only dissolved)\n",
      "✅ DONE [low] FeatureToPoint INSIDE (land-only dissolved) (0.01 min)\n",
      "⚠️ [low] 2804 wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\n",
      "▶ [low missing] Copy selected\n",
      "✅ DONE [low missing] Copy selected (0.01 min)\n",
      "▶ [low] FeatureToPoint INSIDE (fallback dissolved)\n",
      "✅ DONE [low] FeatureToPoint INSIDE (fallback dissolved) (0.01 min)\n",
      "▶ [low] Append fallback points\n",
      "✅ DONE [low] Append fallback points (0.00 min)\n",
      "▶ [low] PointToRaster pourpoints\n",
      "✅ DONE [low] PointToRaster pourpoints (0.13 min)\n",
      "[low] SnapPourPoint distance = 150 m (land-only)\n",
      "▶ [low] RasterToPoint snapped pourpoints\n",
      "✅ DONE [low] RasterToPoint snapped pourpoints (0.08 min)\n",
      "▶ [low] Calculate CW_Id on snapped points\n",
      "✅ DONE [low] Calculate CW_Id on snapped points (0.00 min)\n",
      "[low] unique snapped pourpoint IDs: 4346 (target 4500)\n",
      "▶ [low] PointToRaster snapped points\n",
      "✅ DONE [low] PointToRaster snapped points (0.12 min)\n",
      "▶ [low] Watershed\n",
      "✅ DONE [low] Watershed (0.78 min)\n",
      "▶ [low] RasterToPolygon\n",
      "✅ DONE [low] RasterToPolygon (0.15 min)\n",
      "▶ [low] Calculate CW_Id on watershed polygons\n",
      "✅ DONE [low] Calculate CW_Id on watershed polygons (0.01 min)\n",
      "▶ [low] Dissolve watersheds by CW_Id\n",
      "✅ DONE [low] Dissolve watersheds by CW_Id (0.05 min)\n",
      "[low] watersheds BEFORE clipping unique IDs: 4346 (target 4500)\n",
      "▶ [low] Erase lake from watersheds (clip)\n",
      "✅ DONE [low] Erase lake from watersheds (clip) (0.02 min)\n",
      "▶ [low] Erase stream mask from watersheds (clip)\n",
      "✅ DONE [low] Erase stream mask from watersheds (clip) (0.01 min)\n",
      "▶ [low] Dissolve final output (clip result)\n",
      "✅ DONE [low] Dissolve final output (clip result) (0.02 min)\n",
      "[low] final watersheds AFTER clip unique IDs: 2384 (target 4500)\n",
      "[low] Missing IDs after clip: 2116\n",
      "▶ [low] Copy missing pourpoints\n",
      "✅ DONE [low] Copy missing pourpoints (0.01 min)\n",
      "▶ [low] Near(missing pts -> final watersheds)\n",
      "✅ DONE [low] Near(missing pts -> final watersheds) (0.01 min)\n",
      "▶ [low] Create assigned FC\n",
      "✅ DONE [low] Create assigned FC (0.01 min)\n",
      "[low] Assigned polygons added: 2116\n",
      "▶ [low] Append assigned -> final\n",
      "✅ DONE [low] Append assigned -> final (0.01 min)\n",
      "▶ [low] PairwiseDissolve (enforce 1 per CW_Id)\n",
      "✅ DONE [low] PairwiseDissolve (enforce 1 per CW_Id) (0.01 min)\n",
      "▶ [low] Copy enforced final\n",
      "✅ DONE [low] Copy enforced final (0.02 min)\n",
      "[low] final watersheds AFTER assignment-repair: 4500 (target 4500)\n",
      "✅ final watershed: low -> CoastalWatershed_low_erase_lakedrain_LakeHuron.shp\n",
      "\n",
      "==================== SURGE ====================\n",
      "▶ [surge] Project wetlands\n",
      "✅ DONE [surge] Project wetlands (0.01 min)\n",
      "▶ [surge] RepairGeometry wetlands\n",
      "✅ DONE [surge] RepairGeometry wetlands (0.12 min)\n",
      "▶ [surge] Dissolve ORIGINAL wetlands by CW_Id\n",
      "✅ DONE [surge] Dissolve ORIGINAL wetlands by CW_Id (0.08 min)\n",
      "[surge] unique wetland IDs (original, dissolved): 17071\n",
      "▶ [surge] Erase lake from wetlands (land-only)\n",
      "✅ DONE [surge] Erase lake from wetlands (land-only) (0.04 min)\n",
      "▶ [surge] Dissolve land-only wetlands by CW_Id\n",
      "✅ DONE [surge] Dissolve land-only wetlands by CW_Id (0.09 min)\n",
      "[surge] unique wetland IDs (land-only, dissolved): 11715\n",
      "▶ [surge] FeatureToPoint INSIDE (land-only dissolved)\n",
      "✅ DONE [surge] FeatureToPoint INSIDE (land-only dissolved) (0.02 min)\n",
      "⚠️ [surge] 5356 wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\n",
      "▶ [surge missing] Copy selected\n",
      "✅ DONE [surge missing] Copy selected (0.01 min)\n",
      "▶ [surge] FeatureToPoint INSIDE (fallback dissolved)\n",
      "✅ DONE [surge] FeatureToPoint INSIDE (fallback dissolved) (0.01 min)\n",
      "▶ [surge] Append fallback points\n",
      "✅ DONE [surge] Append fallback points (0.01 min)\n",
      "▶ [surge] PointToRaster pourpoints\n",
      "✅ DONE [surge] PointToRaster pourpoints (0.17 min)\n",
      "[surge] SnapPourPoint distance = 150 m (land-only)\n",
      "▶ [surge] RasterToPoint snapped pourpoints\n",
      "✅ DONE [surge] RasterToPoint snapped pourpoints (0.08 min)\n",
      "▶ [surge] Calculate CW_Id on snapped points\n",
      "✅ DONE [surge] Calculate CW_Id on snapped points (0.01 min)\n",
      "[surge] unique snapped pourpoint IDs: 16309 (target 17071)\n",
      "▶ [surge] PointToRaster snapped points\n",
      "✅ DONE [surge] PointToRaster snapped points (0.13 min)\n",
      "▶ [surge] Watershed\n",
      "✅ DONE [surge] Watershed (0.82 min)\n",
      "▶ [surge] RasterToPolygon\n",
      "✅ DONE [surge] RasterToPolygon (0.13 min)\n",
      "▶ [surge] Calculate CW_Id on watershed polygons\n",
      "✅ DONE [surge] Calculate CW_Id on watershed polygons (0.01 min)\n",
      "▶ [surge] Dissolve watersheds by CW_Id\n",
      "✅ DONE [surge] Dissolve watersheds by CW_Id (0.15 min)\n",
      "[surge] watersheds BEFORE clipping unique IDs: 16309 (target 17071)\n",
      "▶ [surge] Erase lake from watersheds (clip)\n",
      "✅ DONE [surge] Erase lake from watersheds (clip) (0.03 min)\n",
      "▶ [surge] Erase stream mask from watersheds (clip)\n",
      "✅ DONE [surge] Erase stream mask from watersheds (clip) (0.02 min)\n",
      "▶ [surge] Dissolve final output (clip result)\n",
      "✅ DONE [surge] Dissolve final output (clip result) (0.06 min)\n",
      "[surge] final watersheds AFTER clip unique IDs: 12540 (target 17071)\n",
      "[surge] Missing IDs after clip: 4531\n",
      "▶ [surge] Copy missing pourpoints\n",
      "✅ DONE [surge] Copy missing pourpoints (0.01 min)\n",
      "▶ [surge] Near(missing pts -> final watersheds)\n",
      "✅ DONE [surge] Near(missing pts -> final watersheds) (0.03 min)\n",
      "▶ [surge] Create assigned FC\n",
      "✅ DONE [surge] Create assigned FC (0.01 min)\n",
      "[surge] Assigned polygons added: 4531\n",
      "▶ [surge] Append assigned -> final\n",
      "✅ DONE [surge] Append assigned -> final (0.02 min)\n",
      "▶ [surge] PairwiseDissolve (enforce 1 per CW_Id)\n",
      "✅ DONE [surge] PairwiseDissolve (enforce 1 per CW_Id) (0.02 min)\n",
      "▶ [surge] Copy enforced final\n",
      "✅ DONE [surge] Copy enforced final (0.04 min)\n",
      "[surge] final watersheds AFTER assignment-repair: 17071 (target 17071)\n",
      "✅ final watershed: surge -> CoastalWatershed_surge_erase_lakedrain_LakeHuron.shp\n",
      "\n",
      "🎉 DONE\n"
     ]
    }
   ],
   "source": [
    "# # --- FINAL ROBUST CELL (UPDATED): 1 Coastal Watershed per Coastal Wetland (CW_Id)\n",
    "# # Goal:\n",
    "# #   - ALWAYS produce one watershed per CW_Id\n",
    "# #   - Then CLIP OUT only the portions inside Lake Huron or inside Stream-Watershed mask\n",
    "# #   - Do NOT drop whole IDs due to tiny overlaps\n",
    "# #   - No C:\\ temp writes (all temp in ws_gdb / pp_gdb)\n",
    "# # Notes:\n",
    "# #   - This workflow can still lose some CW_Ids due to SnapPourPoint raster collisions.\n",
    "# #     We fix that with a \"REPAIR missing IDs\" step that rebuilds only missing CW_Ids one-by-one.\n",
    "\n",
    "# import os, gc, time, sys\n",
    "# import arcpy\n",
    "# from arcpy import sa\n",
    "\n",
    "# arcpy.env.overwriteOutput = True\n",
    "# arcpy.env.addOutputsToMap = False\n",
    "# arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# # -------------------------\n",
    "# # REQUIRED: folders exist (must be defined in your notebook)\n",
    "# # -------------------------\n",
    "# # outPourpoints, outWatersheds, inStreamsWatershed, Lake_Huron, D8_flow\n",
    "# # erase_buffer_avg/high/low/surge\n",
    "# # CoastalWatershed_* output paths must exist in your notebook variables\n",
    "# os.makedirs(outPourpoints, exist_ok=True)\n",
    "# os.makedirs(outWatersheds, exist_ok=True)\n",
    "\n",
    "# # -------------------------\n",
    "# # Reliable workspaces (GDBs)\n",
    "# # -------------------------\n",
    "# pp_gdb = os.path.join(outPourpoints, \"pourpoints.gdb\")\n",
    "# if not arcpy.Exists(pp_gdb):\n",
    "#     arcpy.management.CreateFileGDB(outPourpoints, \"pourpoints.gdb\")\n",
    "\n",
    "# ws_gdb = os.path.join(outWatersheds, \"watersheds.gdb\")\n",
    "# if not arcpy.Exists(ws_gdb):\n",
    "#     arcpy.management.CreateFileGDB(outWatersheds, \"watersheds.gdb\")\n",
    "\n",
    "# # FORCE all scratch/workspace to your ws_gdb (no C:\\temp)\n",
    "# arcpy.env.workspace = ws_gdb\n",
    "# arcpy.env.scratchWorkspace = ws_gdb\n",
    "\n",
    "# # -------------------------\n",
    "# # Inputs\n",
    "# # -------------------------\n",
    "# flowacc = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\"\n",
    "# print(f\"✅ flowacc: {flowacc}\", flush=True)\n",
    "\n",
    "# cats = {\n",
    "#     #\"avg\":   (erase_buffer_avg,   CoastalWatershed_avg_erase_lakedrain,   CoastalWatershed_avg_erase_lakedrain_LakeHuron),\n",
    "#     \"high\":  (erase_buffer_high,  CoastalWatershed_high_erase_lakedrain,  CoastalWatershed_high_erase_lakedrain_LakeHuron),\n",
    "#     \"low\":   (erase_buffer_low,   CoastalWatershed_low_erase_lakedrain,   CoastalWatershed_low_erase_lakedrain_LakeHuron),\n",
    "#     \"surge\": (erase_buffer_surge, CoastalWatershed_surge_erase_lakedrain, CoastalWatershed_surge_erase_lakedrain_LakeHuron),\n",
    "# }\n",
    "\n",
    "# CW_ID_FIELD = \"CW_Id\"\n",
    "\n",
    "# # -------------------------\n",
    "# # Align env to D8 grid\n",
    "# # -------------------------\n",
    "# D8_SR = arcpy.Describe(D8_flow).spatialReference\n",
    "# arcpy.env.snapRaster = D8_flow\n",
    "# arcpy.env.cellSize   = D8_flow\n",
    "# arcpy.env.extent     = D8_flow\n",
    "# arcpy.env.outputCoordinateSystem = D8_SR\n",
    "# cellsize = float(arcpy.Describe(D8_flow).meanCellWidth)\n",
    "\n",
    "# print(f\"✅ workspace: {ws_gdb}\", flush=True)\n",
    "# print(f\"✅ scratch:   {ws_gdb}\", flush=True)\n",
    "# print(f\"✅ D8_flow CRS: {D8_SR.name} (factoryCode={D8_SR.factoryCode})\", flush=True)\n",
    "\n",
    "# # ============================================================\n",
    "# # Helpers\n",
    "# # ============================================================\n",
    "# def _log(msg):\n",
    "#     print(msg, flush=True)\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "# def _clear_locks():\n",
    "#     try:\n",
    "#         arcpy.ClearWorkspaceCache_management()\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     gc.collect()\n",
    "\n",
    "# def _safe_delete(p):\n",
    "#     try:\n",
    "#         if arcpy.Exists(p):\n",
    "#             arcpy.management.Delete(p)\n",
    "#     except Exception:\n",
    "#         _clear_locks()\n",
    "#         if arcpy.Exists(p):\n",
    "#             arcpy.management.Delete(p)\n",
    "\n",
    "# def _field_map_lower(fc):\n",
    "#     return {f.name.lower(): f.name for f in arcpy.ListFields(fc)}\n",
    "\n",
    "# def _find_field(fc, candidates):\n",
    "#     fmap = _field_map_lower(fc)\n",
    "#     for c in candidates:\n",
    "#         if c and c.lower() in fmap:\n",
    "#             return fmap[c.lower()]\n",
    "#     return None\n",
    "\n",
    "# def get_field_name_ci(fc, target_name):\n",
    "#     if not target_name:\n",
    "#         return None\n",
    "#     t = target_name.lower()\n",
    "#     for f in arcpy.ListFields(fc):\n",
    "#         if f.name.lower() == t:\n",
    "#             return f.name\n",
    "#     return None\n",
    "\n",
    "# def _is_shp(path):\n",
    "#     return isinstance(path, str) and path.lower().endswith(\".shp\")\n",
    "\n",
    "# def _ensure_field(fc, desired_name, field_type=\"LONG\", fallbacks=()):\n",
    "#     if not desired_name or not str(desired_name).strip():\n",
    "#         desired_name = \"CW_Id\"\n",
    "\n",
    "#     existing = get_field_name_ci(fc, desired_name)\n",
    "#     if existing:\n",
    "#         return existing\n",
    "\n",
    "#     candidates = [desired_name] + list(fallbacks)\n",
    "#     for nm in candidates:\n",
    "#         if not nm:\n",
    "#             continue\n",
    "\n",
    "#         safe = arcpy.ValidateFieldName(nm, os.path.dirname(fc) if isinstance(fc, str) else \"\")\n",
    "#         if _is_shp(fc) and len(safe) > 10:\n",
    "#             safe = safe[:10]\n",
    "\n",
    "#         existing = get_field_name_ci(fc, safe)\n",
    "#         if existing:\n",
    "#             return existing\n",
    "\n",
    "#         try:\n",
    "#             arcpy.management.AddField(fc, safe, field_type)\n",
    "#             return get_field_name_ci(fc, safe) or safe\n",
    "#         except Exception:\n",
    "#             _clear_locks()\n",
    "#             continue\n",
    "\n",
    "#     raise RuntimeError(f\"Cannot add field '{desired_name}' to {fc}\")\n",
    "\n",
    "# def count_unique(fc, id_field):\n",
    "#     fld = get_field_name_ci(fc, id_field) or _find_field(fc, [id_field])\n",
    "#     if not fld:\n",
    "#         return 0\n",
    "#     vals = set()\n",
    "#     with arcpy.da.SearchCursor(fc, [fld]) as cur:\n",
    "#         for (v,) in cur:\n",
    "#             if v is not None:\n",
    "#                 vals.add(int(v))\n",
    "#     return len(vals)\n",
    "\n",
    "# def _idset(fc, id_field):\n",
    "#     fld = get_field_name_ci(fc, id_field) or _find_field(fc, [id_field])\n",
    "#     s = set()\n",
    "#     with arcpy.da.SearchCursor(fc, [fld]) as cur:\n",
    "#         for (v,) in cur:\n",
    "#             if v is not None:\n",
    "#                 s.add(int(v))\n",
    "#     return s\n",
    "\n",
    "# def calculate_area_m2(fc, field=\"WS_AREAM2\"):\n",
    "#     try:\n",
    "#         field = _ensure_field(fc, field, \"DOUBLE\", fallbacks=(\"AREA_M2\",\"A_M2\",\"AREA\"))\n",
    "#         arcpy.management.CalculateGeometryAttributes(fc, [[field, \"AREA\"]], area_unit=\"SQUARE_METERS\")\n",
    "#     except Exception as e:\n",
    "#         _log(f\"⚠️ area field skipped: {e}\")\n",
    "#     return field\n",
    "\n",
    "# def add_xy_ll(fc, prefix=\"WS\"):\n",
    "#     try:\n",
    "#         cx = _ensure_field(fc, f\"{prefix}_cx\", \"DOUBLE\", fallbacks=(f\"{prefix}X\",))\n",
    "#         cy = _ensure_field(fc, f\"{prefix}_cy\", \"DOUBLE\", fallbacks=(f\"{prefix}Y\",))\n",
    "#         arcpy.management.CalculateField(fc, cx, \"!SHAPE.centroid.X!\", \"PYTHON3\")\n",
    "#         arcpy.management.CalculateField(fc, cy, \"!SHAPE.centroid.Y!\", \"PYTHON3\")\n",
    "\n",
    "#         lon = _ensure_field(fc, f\"{prefix}_lon\", \"DOUBLE\", fallbacks=(f\"{prefix}LON\",))\n",
    "#         lat = _ensure_field(fc, f\"{prefix}_lat\", \"DOUBLE\", fallbacks=(f\"{prefix}LAT\",))\n",
    "#         arcpy.management.CalculateGeometryAttributes(\n",
    "#             fc,\n",
    "#             [[lat, \"CENTROID_Y\"], [lon, \"CENTROID_X\"]],\n",
    "#             coordinate_system=arcpy.SpatialReference(4326),\n",
    "#             coordinate_format=\"DD\"\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         _log(f\"⚠️ xy/ll fields skipped: {e}\")\n",
    "\n",
    "# def gp(label, func, *args, **kwargs):\n",
    "#     _log(f\"▶ {label}\")\n",
    "#     t0 = time.time()\n",
    "#     out = func(*args, **kwargs)\n",
    "#     _log(f\"✅ DONE {label} ({(time.time()-t0)/60:.2f} min)\")\n",
    "#     return out\n",
    "\n",
    "# # ---------- CRS FIX + PROJECT (TEMP WRITES INTO ws_gdb) ----------\n",
    "# def fix_define_and_project_to_gdb(in_fc, out_fc, out_sr, assumed_src_if_mislabeled=None, name=\"layer\"):\n",
    "#     \"\"\"\n",
    "#     Robust CRS fixer:\n",
    "#     - If dataset is mislabeled but coordinates already match out_sr, we:\n",
    "#         CopyFeatures -> DefineProjection(out_sr) and STOP (no Project).\n",
    "#     - Otherwise we DefineProjection to known source CRS (e.g. EPSG:4326) then Project.\n",
    "#     All temp writes stay in ws_gdb (no C:\\).\n",
    "#     \"\"\"\n",
    "#     def _looks_like_degrees(ext):\n",
    "#         return (abs(ext.XMin) <= 180 and abs(ext.XMax) <= 180 and abs(ext.YMin) <= 90 and abs(ext.YMax) <= 90)\n",
    "\n",
    "#     def _looks_like_projected(ext):\n",
    "#         return (max(abs(ext.XMin), abs(ext.XMax), abs(ext.YMin), abs(ext.YMax)) > 1000)\n",
    "\n",
    "#     def _pick_transform(in_sr, out_sr):\n",
    "#         try:\n",
    "#             tx = arcpy.ListTransformations(in_sr, out_sr)\n",
    "#             return tx[0] if tx else None\n",
    "#         except Exception:\n",
    "#             return None\n",
    "\n",
    "#     _safe_delete(out_fc)\n",
    "\n",
    "#     d = arcpy.Describe(in_fc)\n",
    "#     sr = d.spatialReference\n",
    "#     ext = d.extent\n",
    "\n",
    "#     _log(f\"\\n[{name}] input: {in_fc}\")\n",
    "#     _log(f\"[{name}] sr: {sr.name if sr else None} | factoryCode={getattr(sr,'factoryCode',None)} | type={getattr(sr,'type',None)}\")\n",
    "#     _log(f\"[{name}] extent: XMin={ext.XMin:.3f} XMax={ext.XMax:.3f} YMin={ext.YMin:.3f} YMax={ext.YMax:.3f}\")\n",
    "\n",
    "#     tmp_copy = os.path.join(ws_gdb, f\"tmp_{name}_copy\")\n",
    "#     _safe_delete(tmp_copy)\n",
    "\n",
    "#     # Copy without any implicit projection\n",
    "#     with arcpy.EnvManager(outputCoordinateSystem=None, extent=None, snapRaster=None, cellSize=None):\n",
    "#         gp(f\"CopyFeatures {name}\", arcpy.management.CopyFeatures, in_fc, tmp_copy)\n",
    "\n",
    "#     d2 = arcpy.Describe(tmp_copy)\n",
    "#     sr2 = d2.spatialReference\n",
    "#     ext2 = d2.extent\n",
    "\n",
    "#     mislabeled_projected = (\n",
    "#         sr2 is not None and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "#         and _looks_like_projected(ext2) and not _looks_like_degrees(ext2)\n",
    "#     )\n",
    "\n",
    "#     if mislabeled_projected:\n",
    "#         _log(f\"[{name}] ⚠️ MISLABELED Geographic but coords are projected. SKIP Project; DefineProjection -> {out_sr.name}\")\n",
    "#         gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, out_sr)\n",
    "#         gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "#         _safe_delete(tmp_copy)\n",
    "#         return out_fc\n",
    "\n",
    "#     generic_degrees = (\n",
    "#         sr2 is not None and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "#         and _looks_like_degrees(ext2)\n",
    "#         and getattr(sr2, \"factoryCode\", 0) in (0, None)\n",
    "#     )\n",
    "\n",
    "#     if generic_degrees:\n",
    "#         if assumed_src_if_mislabeled is None:\n",
    "#             assumed_src_if_mislabeled = arcpy.SpatialReference(4326)\n",
    "#         _log(f\"[{name}] ⚠️ GENERIC geographic degrees. DefineProjection -> EPSG:4326 then Project.\")\n",
    "#         gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, assumed_src_if_mislabeled)\n",
    "\n",
    "#     sr_fixed = arcpy.Describe(tmp_copy).spatialReference\n",
    "#     if sr_fixed and (sr_fixed.factoryCode == out_sr.factoryCode) and (sr_fixed.name == out_sr.name):\n",
    "#         _log(f\"[{name}] Already in target CRS. CopyFeatures only (no Project).\")\n",
    "#         gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "#         _safe_delete(tmp_copy)\n",
    "#         return out_fc\n",
    "\n",
    "#     transform = _pick_transform(sr_fixed, out_sr)\n",
    "#     _log(f\"[{name}] Project -> {out_sr.name} | transform={transform}\")\n",
    "\n",
    "#     if transform:\n",
    "#         gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr, transform)\n",
    "#     else:\n",
    "#         gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr)\n",
    "\n",
    "#     _safe_delete(tmp_copy)\n",
    "#     return out_fc\n",
    "\n",
    "# def polygon_to_mask_raster(poly_fc, out_ras, value=1):\n",
    "#     \"\"\"\n",
    "#     Polygon -> raster aligned to D8 (snap/cellsize/extent already set).\n",
    "#     Uses a constant field to burn 'value' into raster.\n",
    "#     \"\"\"\n",
    "#     _safe_delete(out_ras)\n",
    "#     fld = \"MASKVAL\"\n",
    "#     if fld not in [f.name for f in arcpy.ListFields(poly_fc)]:\n",
    "#         arcpy.management.AddField(poly_fc, fld, \"SHORT\")\n",
    "#         arcpy.management.CalculateField(poly_fc, fld, value, \"PYTHON3\")\n",
    "#     gp(f\"PolygonToRaster {os.path.basename(out_ras)}\", arcpy.conversion.PolygonToRaster,\n",
    "#        poly_fc, fld, out_ras, \"CELL_CENTER\", \"\", cellsize)\n",
    "#     return out_ras\n",
    "\n",
    "# # ============================================================\n",
    "# # 0) Build projected masks ONCE (stored in ws_gdb)\n",
    "# # ============================================================\n",
    "# # Stream watershed mask: mislabeled as 4326 but projected coords\n",
    "# inStreamsWS_tgt = os.path.join(ws_gdb, \"inStreamsWS_tgt\")\n",
    "# fix_define_and_project_to_gdb(\n",
    "#     in_fc=inStreamsWatershed,\n",
    "#     out_fc=inStreamsWS_tgt,\n",
    "#     out_sr=D8_SR,\n",
    "#     name=\"inStreamsWS\"\n",
    "# )\n",
    "\n",
    "# gp(\"RepairGeometry stream mask\", arcpy.management.RepairGeometry, inStreamsWS_tgt)\n",
    "\n",
    "# inStreams_single = os.path.join(ws_gdb, \"inStreamsWS_single\")\n",
    "# _safe_delete(inStreams_single)\n",
    "# gp(\"MultipartToSinglepart stream mask\", arcpy.management.MultipartToSinglepart, inStreamsWS_tgt, inStreams_single)\n",
    "\n",
    "# inStreamsWS_tgt_diss = os.path.join(ws_gdb, \"inStreamsWS_tgt_diss\")\n",
    "# _safe_delete(inStreamsWS_tgt_diss)\n",
    "# gp(\"Dissolve stream mask\", arcpy.management.Dissolve, inStreams_single, inStreamsWS_tgt_diss)\n",
    "\n",
    "# # Buffer stream mask (helps remove slivers; does NOT delete entire IDs because we clip polygons later)\n",
    "# stream_buf_m = 60\n",
    "# inStreamsWS_buf = os.path.join(ws_gdb, f\"inStreamsWS_buf{stream_buf_m}m\")\n",
    "# _safe_delete(inStreamsWS_buf)\n",
    "# gp(\"Buffer stream mask\", arcpy.analysis.Buffer, inStreamsWS_tgt_diss, inStreamsWS_buf, f\"{stream_buf_m} Meters\", \"FULL\", \"ROUND\", \"ALL\")\n",
    "\n",
    "# # Lake polygon: generic geographic in degrees\n",
    "# Lake_tgt = os.path.join(ws_gdb, \"LakeHuron_tgt\")\n",
    "# fix_define_and_project_to_gdb(\n",
    "#     in_fc=Lake_Huron,\n",
    "#     out_fc=Lake_tgt,\n",
    "#     out_sr=D8_SR,\n",
    "#     assumed_src_if_mislabeled=arcpy.SpatialReference(4326),\n",
    "#     name=\"LakeHuron\"\n",
    "# )\n",
    "\n",
    "# gp(\"RepairGeometry lake\", arcpy.management.RepairGeometry, Lake_tgt)\n",
    "\n",
    "# # Lake mask raster (for flowacc_land only)\n",
    "# lake_mask_ras = os.path.join(ws_gdb, \"LakeHuron_mask_ras\")\n",
    "# polygon_to_mask_raster(Lake_tgt, lake_mask_ras, value=1)\n",
    "# _log(f\"✅ lake_mask_ras: {lake_mask_ras}\")\n",
    "\n",
    "# # Land-only flowacc for snapping (NoData on lake)\n",
    "# flowacc_land = os.path.join(ws_gdb, \"flowacc_land\")\n",
    "# _safe_delete(flowacc_land)\n",
    "# _log(\"▶ Build flowacc_land = flowacc where NOT lake\")\n",
    "# fa_land = sa.SetNull(sa.Raster(lake_mask_ras), sa.Raster(flowacc))\n",
    "# fa_land.save(flowacc_land)\n",
    "# _log(f\"✅ flowacc_land: {flowacc_land}\")\n",
    "\n",
    "# # ============================================================\n",
    "# # MAIN LOOP\n",
    "# # ============================================================\n",
    "# for cat, (wet_fc, out_ws_drain, out_ws_lake) in cats.items():\n",
    "\n",
    "#     _log(f\"\\n==================== {cat.upper()} ====================\")\n",
    "\n",
    "#     # --- 1) Project wetlands into D8 SR (work in GDB)\n",
    "#     wet_tgt = os.path.join(ws_gdb, f\"{cat}_wet_tgt\")\n",
    "#     _safe_delete(wet_tgt)\n",
    "#     gp(f\"[{cat}] Project wetlands\", arcpy.management.Project, wet_fc, wet_tgt, D8_SR)\n",
    "\n",
    "#     wet_id_f = _ensure_field(wet_tgt, CW_ID_FIELD, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "#     gp(f\"[{cat}] RepairGeometry wetlands\", arcpy.management.RepairGeometry, wet_tgt)\n",
    "\n",
    "#     # --- 2) Dissolve ORIGINAL wetlands by CW_Id (guarantees 1 polygon per CW_Id)\n",
    "#     wet_orig_diss = os.path.join(ws_gdb, f\"{cat}_wet_orig_diss\")\n",
    "#     _safe_delete(wet_orig_diss)\n",
    "#     gp(f\"[{cat}] Dissolve ORIGINAL wetlands by CW_Id\", arcpy.management.Dissolve, wet_tgt, wet_orig_diss, wet_id_f)\n",
    "\n",
    "#     wet_n = count_unique(wet_orig_diss, wet_id_f)\n",
    "#     _log(f\"[{cat}] unique wetland IDs (original, dissolved): {wet_n}\")\n",
    "\n",
    "#     # --- 3) LAND-ONLY wetlands (erase lake) then dissolve (for land pourpoints)\n",
    "#     wet_land = os.path.join(ws_gdb, f\"{cat}_wet_land\")\n",
    "#     _safe_delete(wet_land)\n",
    "#     gp(f\"[{cat}] Erase lake from wetlands (land-only)\", arcpy.analysis.Erase, wet_tgt, Lake_tgt, wet_land)\n",
    "\n",
    "#     wet_land_diss = os.path.join(ws_gdb, f\"{cat}_wet_land_diss\")\n",
    "#     _safe_delete(wet_land_diss)\n",
    "#     gp(f\"[{cat}] Dissolve land-only wetlands by CW_Id\", arcpy.management.Dissolve, wet_land, wet_land_diss, wet_id_f)\n",
    "\n",
    "#     land_n = count_unique(wet_land_diss, wet_id_f)\n",
    "#     _log(f\"[{cat}] unique wetland IDs (land-only, dissolved): {land_n}\")\n",
    "\n",
    "#     # --- 4) Pourpoints from land-only dissolved (1 per CW_Id)\n",
    "#     pp_inside = os.path.join(pp_gdb, f\"{cat}_pp_inside\")\n",
    "#     _safe_delete(pp_inside)\n",
    "#     gp(f\"[{cat}] FeatureToPoint INSIDE (land-only dissolved)\", arcpy.management.FeatureToPoint, wet_land_diss, pp_inside, \"INSIDE\")\n",
    "\n",
    "#     # --- 5) Add fallback pourpoints for lake-only IDs from ORIGINAL dissolved (still 1 per CW_Id)\n",
    "#     orig_ids = _idset(wet_orig_diss, wet_id_f)\n",
    "#     land_ids = _idset(wet_land_diss, wet_id_f)\n",
    "#     missing_lakeonly = sorted(list(orig_ids - land_ids))\n",
    "\n",
    "#     if missing_lakeonly:\n",
    "#         _log(f\"⚠️ [{cat}] {len(missing_lakeonly)} wetlands appear fully in-lake after erase; adding 1 fallback point per CW_Id.\")\n",
    "\n",
    "#         # Select missing polygons from wet_orig_diss using a chunked IN() approach\n",
    "#         wet_missing_poly = os.path.join(ws_gdb, f\"{cat}_wet_missing_poly\")\n",
    "#         _safe_delete(wet_missing_poly)\n",
    "\n",
    "#         lyr = f\"lyr_{cat}_missing\"\n",
    "#         arcpy.management.MakeFeatureLayer(wet_orig_diss, lyr)\n",
    "#         chunk = 900\n",
    "#         for i in range(0, len(missing_lakeonly), chunk):\n",
    "#             sub = missing_lakeonly[i:i+chunk]\n",
    "#             where = f\"{arcpy.AddFieldDelimiters(lyr, wet_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "#             arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "#         gp(f\"[{cat} missing] Copy selected\", arcpy.management.CopyFeatures, lyr, wet_missing_poly)\n",
    "#         arcpy.management.Delete(lyr)\n",
    "\n",
    "#         pp_fallback = os.path.join(pp_gdb, f\"{cat}_pp_fallback\")\n",
    "#         _safe_delete(pp_fallback)\n",
    "#         gp(f\"[{cat}] FeatureToPoint INSIDE (fallback dissolved)\", arcpy.management.FeatureToPoint, wet_missing_poly, pp_fallback, \"INSIDE\")\n",
    "\n",
    "#         gp(f\"[{cat}] Append fallback points\", arcpy.management.Append, pp_fallback, pp_inside, \"NO_TEST\")\n",
    "#         _safe_delete(pp_fallback)\n",
    "#         _safe_delete(wet_missing_poly)\n",
    "\n",
    "#     # ensure ID field exists on points\n",
    "#     pp_id_f = _ensure_field(pp_inside, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "\n",
    "#     # --- 6) SnapPourPoint in raster space (bulk) using LAND-ONLY flowacc\n",
    "#     pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_ras\")\n",
    "#     _safe_delete(pp_ras)\n",
    "#     gp(f\"[{cat}] PointToRaster pourpoints\", arcpy.conversion.PointToRaster,\n",
    "#        pp_inside, pp_id_f, pp_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "#     snapped_pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_snapped_ras\")\n",
    "#     _safe_delete(snapped_pp_ras)\n",
    "\n",
    "#     # For lake-only points you typically need a larger snap distance to reach land.\n",
    "#     # But larger distances increase collisions. We'll keep it moderate and REPAIR missing IDs later.\n",
    "#     snap_dist_m = 150\n",
    "#     _log(f\"[{cat}] SnapPourPoint distance = {snap_dist_m} m (land-only)\")\n",
    "#     sa.SnapPourPoint(sa.Raster(pp_ras), sa.Raster(flowacc_land), snap_dist_m).save(snapped_pp_ras)\n",
    "\n",
    "#     # Convert snapped raster to points (bulk snapped pourpoints)\n",
    "#     snapped_pts = os.path.join(pp_gdb, f\"{cat}_pp_snapped_pts\")\n",
    "#     _safe_delete(snapped_pts)\n",
    "#     gp(f\"[{cat}] RasterToPoint snapped pourpoints\", arcpy.conversion.RasterToPoint, snapped_pp_ras, snapped_pts, \"VALUE\")\n",
    "\n",
    "#     val_field = _find_field(snapped_pts, [\"GRID_CODE\", \"GRIDCODE\", \"VALUE\"])\n",
    "#     if not val_field:\n",
    "#         raise RuntimeError(f\"[{cat}] Could not find VALUE/GRIDCODE in snapped points.\")\n",
    "\n",
    "#     pp_final_id = _ensure_field(snapped_pts, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "#     gp(f\"[{cat}] Calculate CW_Id on snapped points\", arcpy.management.CalculateField,\n",
    "#        snapped_pts, pp_final_id, f\"!{val_field}!\", \"PYTHON3\")\n",
    "\n",
    "#     uniq_pp = count_unique(snapped_pts, pp_final_id)\n",
    "#     _log(f\"[{cat}] unique snapped pourpoint IDs: {uniq_pp} (target {wet_n})\")\n",
    "\n",
    "#     # --- 7) Convert snapped points back to raster for Watershed\n",
    "#     pp_snap_ras = os.path.join(pp_gdb, f\"{cat}_pp_snap_ras\")\n",
    "#     _safe_delete(pp_snap_ras)\n",
    "#     gp(f\"[{cat}] PointToRaster snapped points\", arcpy.conversion.PointToRaster,\n",
    "#        snapped_pts, pp_final_id, pp_snap_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "#     # --- 8) Watershed raster (NO lake/stream raster masking here!)\n",
    "#     ws_ras = os.path.join(ws_gdb, f\"{cat}_ws_ras\")\n",
    "#     _safe_delete(ws_ras)\n",
    "#     _log(f\"▶ [{cat}] Watershed\")\n",
    "#     t0 = time.time()\n",
    "#     sa.Watershed(D8_flow, pp_snap_ras).save(ws_ras)\n",
    "#     _log(f\"✅ DONE [{cat}] Watershed ({(time.time()-t0)/60:.2f} min)\")\n",
    "\n",
    "#     # --- 9) RasterToPolygon (NO raster masking)\n",
    "#     ws_poly_raw = os.path.join(ws_gdb, f\"{cat}_ws_poly_raw\")\n",
    "#     _safe_delete(ws_poly_raw)\n",
    "#     gp(f\"[{cat}] RasterToPolygon\", arcpy.conversion.RasterToPolygon, ws_ras, ws_poly_raw, \"NO_SIMPLIFY\", \"VALUE\")\n",
    "\n",
    "#     grid_field = _find_field(ws_poly_raw, [\"GRIDCODE\",\"GRID_CODE\"])\n",
    "#     if not grid_field:\n",
    "#         raise RuntimeError(f\"[{cat}] GRIDCODE missing in watershed polygons.\")\n",
    "\n",
    "#     ws_id_f = _ensure_field(ws_poly_raw, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "#     gp(f\"[{cat}] Calculate CW_Id on watershed polygons\", arcpy.management.CalculateField,\n",
    "#        ws_poly_raw, ws_id_f, f\"!{grid_field}!\", \"PYTHON3\")\n",
    "\n",
    "#     ws_poly = os.path.join(ws_gdb, f\"{cat}_ws_poly\")\n",
    "#     _safe_delete(ws_poly)\n",
    "#     gp(f\"[{cat}] Dissolve watersheds by CW_Id\", arcpy.management.Dissolve, ws_poly_raw, ws_poly, ws_id_f)\n",
    "\n",
    "#     ws_before = count_unique(ws_poly, ws_id_f)\n",
    "#     _log(f\"[{cat}] watersheds BEFORE clipping unique IDs: {ws_before} (target {wet_n})\")\n",
    "\n",
    "#     # --- 10) CLIP OUT ONLY overlap parts (lake + stream) as polygons\n",
    "#     tmp_no_lake = os.path.join(ws_gdb, f\"{cat}_ws_no_lake\")\n",
    "#     tmp_no_stream = os.path.join(ws_gdb, f\"{cat}_ws_no_stream\")\n",
    "#     _safe_delete(tmp_no_lake); _safe_delete(tmp_no_stream)\n",
    "\n",
    "#     gp(f\"[{cat}] Erase lake from watersheds (clip)\", arcpy.analysis.Erase, ws_poly, Lake_tgt, tmp_no_lake)\n",
    "#     gp(f\"[{cat}] Erase stream mask from watersheds (clip)\", arcpy.analysis.Erase, tmp_no_lake, inStreamsWS_buf, tmp_no_stream)\n",
    "\n",
    "#     _safe_delete(out_ws_lake)\n",
    "#     gp(f\"[{cat}] Dissolve final output (clip result)\", arcpy.management.Dissolve, tmp_no_stream, out_ws_lake, ws_id_f)\n",
    "\n",
    "#     ws_after = count_unique(out_ws_lake, ws_id_f)\n",
    "#     _log(f\"[{cat}] final watersheds AFTER clip unique IDs: {ws_after} (target {wet_n})\")\n",
    "\n",
    "#     # ============================================================\n",
    "# # 11) REPAIR missing IDs (FAST VERSION)\n",
    "# # ============================================================\n",
    "# # 11) REPAIR missing IDs (ASSIGNMENT ONLY - FAST)\n",
    "# #     This guarantees 1 feature per CW_Id without per-ID watershed rebuild.\n",
    "# # ============================================================\n",
    "# # ============================================================\n",
    "# # 11) REPAIR missing IDs (ASSIGNMENT ONLY - FAST)\n",
    "# #     This guarantees 1 feature per CW_Id without per-ID watershed rebuild.\n",
    "# # ============================================================\n",
    "\n",
    "#     final_ids = _idset(out_ws_lake, ws_id_f)\n",
    "#     missing_ids = sorted(list(orig_ids - final_ids))\n",
    "#     _log(f\"[{cat}] Missing IDs after clip: {len(missing_ids)}\")\n",
    "\n",
    "#     if missing_ids:\n",
    "#         # Extract pourpoints for missing IDs\n",
    "#         pp_layer = f\"lyr_{cat}_pp_inside\"\n",
    "#         arcpy.management.MakeFeatureLayer(pp_inside, pp_layer)\n",
    "\n",
    "#         miss_pts = os.path.join(pp_gdb, f\"{cat}_missing_pts\")\n",
    "#         _safe_delete(miss_pts)\n",
    "\n",
    "#         arcpy.management.SelectLayerByAttribute(pp_layer, \"CLEAR_SELECTION\")\n",
    "#         chunk = 900\n",
    "#         for i in range(0, len(missing_ids), chunk):\n",
    "#             sub = missing_ids[i:i+chunk]\n",
    "#             where = f\"{arcpy.AddFieldDelimiters(pp_layer, pp_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "#             arcpy.management.SelectLayerByAttribute(pp_layer, \"ADD_TO_SELECTION\", where)\n",
    "\n",
    "#         gp(f\"[{cat}] Copy missing pourpoints\", arcpy.management.CopyFeatures, pp_layer, miss_pts)\n",
    "#         arcpy.management.Delete(pp_layer)\n",
    "\n",
    "#         # Near -> closest existing final watershed polygon\n",
    "#         gp(f\"[{cat}] Near(missing pts -> final watersheds)\", arcpy.analysis.Near, miss_pts, out_ws_lake)\n",
    "\n",
    "#         # Build donor geometry lookup (OID -> geometry)\n",
    "#         oid_field = arcpy.Describe(out_ws_lake).OIDFieldName\n",
    "#         donor_geom = {}\n",
    "#         with arcpy.da.SearchCursor(out_ws_lake, [oid_field, \"SHAPE@\"]) as cur:\n",
    "#             for oid, geom in cur:\n",
    "#                 donor_geom[int(oid)] = geom\n",
    "\n",
    "#         # Create assigned FC (one polygon per missing CW_Id)\n",
    "#         assigned_fc = os.path.join(ws_gdb, f\"{cat}_assigned_missing\")\n",
    "#         _safe_delete(assigned_fc)\n",
    "#         gp(f\"[{cat}] Create assigned FC\", arcpy.management.CreateFeatureclass,\n",
    "#         ws_gdb, os.path.basename(assigned_fc), \"POLYGON\", None, \"DISABLED\", \"DISABLED\", D8_SR)\n",
    "\n",
    "#         assigned_id = _ensure_field(assigned_fc, ws_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "\n",
    "#         near_fld = _find_field(miss_pts, [\"NEAR_FID\"])\n",
    "#         n_assigned = 0\n",
    "#         with arcpy.da.SearchCursor(miss_pts, [pp_id_f, near_fld]) as cur, \\\n",
    "#             arcpy.da.InsertCursor(assigned_fc, [assigned_id, \"SHAPE@\"]) as ic:\n",
    "#             for cw, near_fid in cur:\n",
    "#                 if near_fid is None or int(near_fid) < 0:\n",
    "#                     continue\n",
    "#                 geom = donor_geom.get(int(near_fid))\n",
    "#                 if geom is None:\n",
    "#                     continue\n",
    "#                 ic.insertRow((int(cw), geom))\n",
    "#                 n_assigned += 1\n",
    "\n",
    "#         _log(f\"[{cat}] Assigned polygons added: {n_assigned}\")\n",
    "\n",
    "#         if int(arcpy.management.GetCount(assigned_fc)[0]) > 0:\n",
    "#             gp(f\"[{cat}] Append assigned -> final\", arcpy.management.Append, assigned_fc, out_ws_lake, \"NO_TEST\")\n",
    "\n",
    "#             out_ws_lake_diss2 = os.path.join(ws_gdb, f\"{cat}_final_diss2\")\n",
    "#             _safe_delete(out_ws_lake_diss2)\n",
    "\n",
    "#             # Use PairwiseDissolve if available (faster)\n",
    "#             if hasattr(arcpy.analysis, \"PairwiseDissolve\"):\n",
    "#                 gp(f\"[{cat}] PairwiseDissolve (enforce 1 per CW_Id)\", arcpy.analysis.PairwiseDissolve,\n",
    "#                 out_ws_lake, out_ws_lake_diss2, ws_id_f)\n",
    "#             else:\n",
    "#                 gp(f\"[{cat}] Dissolve (enforce 1 per CW_Id)\", arcpy.management.Dissolve,\n",
    "#                 out_ws_lake, out_ws_lake_diss2, ws_id_f)\n",
    "\n",
    "#             _safe_delete(out_ws_lake)\n",
    "#             gp(f\"[{cat}] Copy enforced final\", arcpy.management.CopyFeatures, out_ws_lake_diss2, out_ws_lake)\n",
    "\n",
    "#         _safe_delete(miss_pts)\n",
    "\n",
    "#     ws_after_final = count_unique(out_ws_lake, ws_id_f)\n",
    "#     _log(f\"[{cat}] final watersheds AFTER assignment-repair: {ws_after_final} (target {len(orig_ids)})\")\n",
    "\n",
    "\n",
    "#     # --- 12) Add attributes safely (do not crash if locked)\n",
    "#     calculate_area_m2(out_ws_lake, \"WS_AREAM2\")\n",
    "#     add_xy_ll(out_ws_lake, prefix=\"WS\")\n",
    "\n",
    "#     _log(f\"✅ final watershed: {cat} -> {os.path.basename(out_ws_lake)}\")\n",
    "#     _clear_locks()\n",
    "\n",
    "# _log(\"\\n🎉 DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52e53f",
   "metadata": {},
   "source": [
    "## What this cell does (end-to-end)\n",
    "\n",
    "This cell builds **coastal watershed polygons for each coastal wetland ID (`CW_Id`)**, using a D8 flow–direction grid, while ensuring that any **parts overlapping Lake Huron and the Stream-Watershed mask are clipped out (removed as pieces, not whole features)**. All intermediate outputs are written into your **project geodatabases** (no `C:\\temp` scratch).\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Sets up safe workspaces (no C:\\ temp)\n",
    "- Creates/uses two file geodatabases:\n",
    "  - `pourpoints.gdb` (stores pourpoints and intermediate rasters/points)\n",
    "  - `watersheds.gdb` (stores intermediate and final watershed polygons)\n",
    "- Forces `arcpy.env.workspace` and `arcpy.env.scratchWorkspace` to `watersheds.gdb`.\n",
    "- Aligns processing to the D8 grid by setting:\n",
    "  - `snapRaster = D8_flow`\n",
    "  - `cellSize = D8_flow`\n",
    "  - `extent = D8_flow`\n",
    "  - `outputCoordinateSystem = D8_flow spatial reference`\n",
    "\n",
    "**Result:** all rasters/vectors line up exactly with the D8 grid.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Builds the two “mask” polygons in the D8 coordinate system (once)\n",
    "This happens once before looping over categories.\n",
    "\n",
    "#### A) Stream-watershed mask (project + clean)\n",
    "- Fixes CRS issues (handles “mislabeled geographic but projected coordinates” cases).\n",
    "- Projects/defines the stream-watershed polygon into the D8 CRS.\n",
    "- Repairs geometry, converts multipart to singlepart, then dissolves into one polygon.\n",
    "- Buffers the dissolved stream mask by `stream_buf_m` meters (default: 60 m).\n",
    "\n",
    "**Why buffer?** Helps remove tiny slivers and boundary artifacts when erasing.\n",
    "\n",
    "#### B) Lake Huron polygon (project + clean)\n",
    "- Fixes CRS issues (handles generic geographic degrees).\n",
    "- Projects the lake polygon into the D8 CRS.\n",
    "- Repairs geometry.\n",
    "- Converts the lake polygon into a raster mask aligned to the D8 grid.\n",
    "- Creates `flowacc_land = flowacc where NOT lake` using `SetNull`.\n",
    "\n",
    "**Purpose of `flowacc_land`:** Pourpoints snap to *land* flow-accumulation cells, not lake cells.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) For each inundation category (`high`, `low`, `surge`), it builds watersheds\n",
    "\n",
    "#### Step 3.1 — Project wetlands into D8 CRS\n",
    "- Projects the wetland feature class (for this category) into the D8 CRS.\n",
    "- Ensures the `CW_Id` field exists.\n",
    "- Repairs geometry.\n",
    "\n",
    "#### Step 3.2 — Remove only the overlapped PART of wetlands inside stream-watershed mask\n",
    "- Runs `Erase(wetlands, stream_mask_buffered)` and outputs `wet_no_stream`.\n",
    "\n",
    "✅ This **does NOT delete entire wetlands**.  \n",
    "It only removes the *pieces* of wetlands that fall inside the stream-watershed mask.\n",
    "\n",
    "#### Step 3.3 — Create “land-only” wetlands (used to place pourpoints)\n",
    "- Runs `Erase(wet_no_stream, LakeHuron)` to remove lake-covered pieces.\n",
    "- Output: `wet_land`.\n",
    "\n",
    "This is used only to create pourpoints on land.\n",
    "\n",
    "#### Step 3.4 — Create pourpoints (potentially multiple per `CW_Id`)\n",
    "- Runs `FeatureToPoint(wet_land, INSIDE)` to get a point inside each land polygon feature.\n",
    "- Because this is done on **non-dissolved** polygons, a single `CW_Id` can generate **multiple pourpoints** if it has multiple polygons.\n",
    "\n",
    "✅ All points preserve and carry `CW_Id`.\n",
    "\n",
    "#### Step 3.5 — Fallback points for CW_Ids with no remaining land\n",
    "Some `CW_Id` polygons might be completely removed by lake/stream erasing (e.g., “lake-only” or fully masked).\n",
    "\n",
    "- The code detects CW_Ids that exist in the original wetlands but are missing after land-only erase.\n",
    "- For those CW_Ids:\n",
    "  - Dissolves the **original** wetlands by `CW_Id`\n",
    "  - Creates **one fallback point per missing CW_Id** using `FeatureToPoint(INSIDE)`\n",
    "  - Appends these fallback points into the main pourpoints feature class\n",
    "\n",
    "✅ This prevents losing CW_Ids just because their wetland is fully in-lake or fully masked.\n",
    "\n",
    "---\n",
    "\n",
    "### 4) Snaps pourpoints to the land flow-accumulation grid\n",
    "To generate hydrologically valid outlets:\n",
    "\n",
    "1. Converts pourpoints to a raster (`PointToRaster`) with cell values = `CW_Id`\n",
    "2. Snaps those raster points to high-flow-accumulation cells using:\n",
    "   - `SnapPourPoint(pp_raster, flowacc_land, snap_dist_m)`\n",
    "3. Converts snapped raster back to points (`RasterToPoint`)\n",
    "4. Copies the snapped point raster VALUE/GRIDCODE into a proper `CW_Id` field\n",
    "\n",
    "✅ After snapping, each snapped point has a valid `CW_Id`.\n",
    "\n",
    "---\n",
    "\n",
    "### 5) Builds watershed polygons from the snapped outlets\n",
    "1. Converts snapped points back to raster (value = `CW_Id`)\n",
    "2. Runs `sa.Watershed(D8_flow, snapped_outlet_raster)` to produce a watershed raster\n",
    "3. Converts watershed raster to polygons (`RasterToPolygon`)\n",
    "4. Copies raster zone value into `CW_Id`\n",
    "5. Dissolves polygons by `CW_Id` so final watersheds are grouped by ID\n",
    "\n",
    "**Important:** `Watershed()` assigns each D8 cell to exactly one outlet zone, so the resulting watershed zones generally do not overlap between CW_Ids.\n",
    "\n",
    "---\n",
    "\n",
    "### 6) Clips out only the overlapped PARTS of the watersheds (lake + stream)\n",
    "After watersheds are created, the code removes overlap *as pieces*:\n",
    "\n",
    "- `Erase(watersheds, LakeHuron)` → removes parts that fall inside the lake polygon\n",
    "- `Erase(result, StreamMaskBuffered)` → removes parts that fall inside the buffered stream-watershed mask\n",
    "\n",
    "✅ This **does NOT delete whole CW_Ids**.  \n",
    "It removes only the overlapping portions, keeping the rest.\n",
    "\n",
    "Then it dissolves again by `CW_Id` and saves to your final output path (`out_ws_lake`).\n",
    "\n",
    "---\n",
    "\n",
    "### 7) Fast “repair missing IDs” (assignment fallback)\n",
    "Sometimes CW_Ids can still disappear (usually due to SnapPourPoint collisions or tiny/empty results after clipping).\n",
    "\n",
    "If CW_Ids are missing after final clipping:\n",
    "- The code selects the missing pourpoints\n",
    "- Runs `Near(missing_pts, final_watersheds)` to find the nearest existing watershed polygon\n",
    "- Copies that nearest polygon geometry and assigns it to the missing CW_Id\n",
    "- Appends those assigned polygons to the final output\n",
    "- Dissolves again by `CW_Id`\n",
    "\n",
    "✅ This guarantees each missing CW_Id is represented, without re-running Watershed per ID.\n",
    "\n",
    "(But note: this “assignment repair” copies geometry from a neighbor, so it is a pragmatic fallback—not a true hydrologic rebuild.)\n",
    "\n",
    "---\n",
    "\n",
    "### 8) Adds attributes to the final watershed polygons\n",
    "For the final watershed output:\n",
    "- Adds/updates `WS_AREAM2` (area in square meters)\n",
    "- Adds centroid coordinates:\n",
    "  - `WS_cx`, `WS_cy` (projected CRS)\n",
    "  - `WS_lon`, `WS_lat` (WGS84 geographic)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of the main outputs you get\n",
    "For each category (`high`, `low`, `surge`), you get:\n",
    "- A final watershed polygon feature class where:\n",
    "  - Each feature has `CW_Id`\n",
    "  - Watershed pieces overlapping **Lake Huron** are removed\n",
    "  - Watershed pieces overlapping **Stream-Watershed mask** are removed\n",
    "  - Missing CW_Ids are optionally “repaired” via nearest-polygon assignment\n",
    "  - Area + centroid fields are added\n",
    "\n",
    "Note:\n",
    "once we create pourpoints it rasterizes the pourpoints using CW_ids and if multiple pourpoint land in a same raster cell only one CW_id survide and watershed assigns each raster cell to one outlet values and the we dissovlve it by CW_Id.\n",
    "So even if CW_Id had multiple pourpoints, the watershed output is effectively:\n",
    "\n",
    "- sa.Watershed(D8_flow, pp_snap_ras)  # outlets are CW_Id values\n",
    "- RasterToPolygon(...)\n",
    "- Dissolve(..., dissolve_field=CW_Id)\n",
    "\n",
    "“all cells that drain to any outlet that has value CW_Id”\n",
    "\n",
    "then merged into one multipart polygon per CW_Id\n",
    "\n",
    "✅ Final result: you do NOT get multiple coastal watersheds per CW_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa7a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ flowacc: S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\n",
      "✅ workspace: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n",
      "✅ scratch:   D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n",
      "✅ D8_flow CRS: NAD_1983_Great_Lakes_Basin_Albers (factoryCode=3174)\n",
      "\n",
      "[inStreamsWS] input: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Streamwatershed\\PointWaterdhed_LH.shp\n",
      "[inStreamsWS] sr: GCS_WGS_1984 | factoryCode=4326 | type=Geographic\n",
      "[inStreamsWS] extent: XMin=929846.850 XMax=1166434.867 YMin=651452.122 YMax=1020243.911\n",
      "▶ CopyFeatures inStreamsWS\n",
      "✅ DONE CopyFeatures inStreamsWS (0.01 min)\n",
      "[inStreamsWS] ⚠️ MISLABELED Geographic but coords are projected. DefineProjection -> NAD_1983_Great_Lakes_Basin_Albers\n",
      "▶ DefineProjection inStreamsWS\n",
      "✅ DONE DefineProjection inStreamsWS (0.00 min)\n",
      "▶ Copy to output inStreamsWS\n",
      "✅ DONE Copy to output inStreamsWS (0.01 min)\n",
      "▶ RepairGeometry stream mask\n",
      "✅ DONE RepairGeometry stream mask (0.00 min)\n",
      "▶ MultipartToSinglepart stream mask\n",
      "✅ DONE MultipartToSinglepart stream mask (0.01 min)\n",
      "▶ Dissolve stream mask\n",
      "✅ DONE Dissolve stream mask (0.01 min)\n",
      "▶ Buffer stream mask\n",
      "✅ DONE Buffer stream mask (0.01 min)\n",
      "\n",
      "==================== AVG ====================\n",
      "▶ [avg] Project wetlands\n",
      "✅ DONE [avg] Project wetlands (0.01 min)\n",
      "▶ [avg] RepairGeometry wetlands\n",
      "✅ DONE [avg] RepairGeometry wetlands (0.06 min)\n",
      "[avg] unique CW_Ids in ORIGINAL wetlands: 9503\n",
      "▶ [avg] PairwiseErase wetlands ∖ streammask (partial)\n",
      "✅ DONE [avg] PairwiseErase wetlands ∖ streammask (partial) (0.01 min)\n",
      "[avg] CW_Ids remaining after wetland stream-erase: 9503\n",
      "▶ [avg] FeatureToPoint INSIDE (stream-clean wetlands)\n",
      "✅ DONE [avg] FeatureToPoint INSIDE (stream-clean wetlands) (0.01 min)\n",
      "▶ [avg] DeleteIdentical points (Shape)\n",
      "✅ DONE [avg] DeleteIdentical points (Shape) (0.00 min)\n",
      "▶ [avg] PointToRaster pourpoints (PP_ID)\n",
      "✅ DONE [avg] PointToRaster pourpoints (PP_ID) (0.11 min)\n",
      "[avg] SnapPourPoint distance = 150 m (PP_ID raster)\n",
      "▶ [avg] Watershed\n",
      "✅ DONE [avg] Watershed (0.88 min)\n",
      "▶ [avg] RasterToPolygon\n",
      "✅ DONE [avg] RasterToPolygon (0.16 min)\n",
      "▶ [avg] Calculate PP_ID on ws polys\n",
      "✅ DONE [avg] Calculate PP_ID on ws polys (0.01 min)\n",
      "▶ [avg] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id\n",
      "✅ DONE [avg] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id (0.02 min)\n",
      "▶ [avg] Dissolve watersheds by CW_Id\n",
      "✅ DONE [avg] Dissolve watersheds by CW_Id (0.06 min)\n",
      "[avg] watersheds BEFORE stream erase unique CW_Ids: 7614 (orig wetlands 9503)\n",
      "▶ [avg] PairwiseErase watersheds ∖ streammask (partial)\n",
      "✅ DONE [avg] PairwiseErase watersheds ∖ streammask (partial) (0.01 min)\n",
      "▶ [avg] Dissolve final output\n",
      "✅ DONE [avg] Dissolve final output (0.04 min)\n",
      "[avg] final watersheds AFTER stream erase unique CW_Ids: 7614 (orig wetlands 9503)\n",
      "\n",
      "==================== HIGH ====================\n",
      "▶ [high] Project wetlands\n",
      "✅ DONE [high] Project wetlands (0.01 min)\n",
      "▶ [high] RepairGeometry wetlands\n",
      "✅ DONE [high] RepairGeometry wetlands (0.10 min)\n",
      "[high] unique CW_Ids in ORIGINAL wetlands: 17890\n",
      "▶ [high] PairwiseErase wetlands ∖ streammask (partial)\n",
      "✅ DONE [high] PairwiseErase wetlands ∖ streammask (partial) (0.02 min)\n",
      "[high] CW_Ids remaining after wetland stream-erase: 17890\n",
      "▶ [high] FeatureToPoint INSIDE (stream-clean wetlands)\n",
      "✅ DONE [high] FeatureToPoint INSIDE (stream-clean wetlands) (0.02 min)\n",
      "▶ [high] DeleteIdentical points (Shape)\n",
      "✅ DONE [high] DeleteIdentical points (Shape) (0.00 min)\n",
      "▶ [high] PointToRaster pourpoints (PP_ID)\n",
      "✅ DONE [high] PointToRaster pourpoints (PP_ID) (0.13 min)\n",
      "[high] SnapPourPoint distance = 150 m (PP_ID raster)\n",
      "▶ [high] Watershed\n",
      "✅ DONE [high] Watershed (0.93 min)\n",
      "▶ [high] RasterToPolygon\n",
      "✅ DONE [high] RasterToPolygon (0.18 min)\n",
      "▶ [high] Calculate PP_ID on ws polys\n",
      "✅ DONE [high] Calculate PP_ID on ws polys (0.01 min)\n",
      "▶ [high] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id\n",
      "✅ DONE [high] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id (0.05 min)\n",
      "▶ [high] Dissolve watersheds by CW_Id\n",
      "✅ DONE [high] Dissolve watersheds by CW_Id (0.12 min)\n",
      "[high] watersheds BEFORE stream erase unique CW_Ids: 13798 (orig wetlands 17890)\n",
      "▶ [high] PairwiseErase watersheds ∖ streammask (partial)\n",
      "✅ DONE [high] PairwiseErase watersheds ∖ streammask (partial) (0.01 min)\n",
      "▶ [high] Dissolve final output\n",
      "✅ DONE [high] Dissolve final output (0.07 min)\n",
      "[high] final watersheds AFTER stream erase unique CW_Ids: 13798 (orig wetlands 17890)\n",
      "\n",
      "==================== LOW ====================\n",
      "▶ [low] Project wetlands\n",
      "✅ DONE [low] Project wetlands (0.01 min)\n",
      "▶ [low] RepairGeometry wetlands\n",
      "✅ DONE [low] RepairGeometry wetlands (0.04 min)\n",
      "[low] unique CW_Ids in ORIGINAL wetlands: 4882\n",
      "▶ [low] PairwiseErase wetlands ∖ streammask (partial)\n",
      "✅ DONE [low] PairwiseErase wetlands ∖ streammask (partial) (0.01 min)\n",
      "[low] CW_Ids remaining after wetland stream-erase: 4882\n",
      "▶ [low] FeatureToPoint INSIDE (stream-clean wetlands)\n",
      "✅ DONE [low] FeatureToPoint INSIDE (stream-clean wetlands) (0.01 min)\n",
      "▶ [low] DeleteIdentical points (Shape)\n",
      "✅ DONE [low] DeleteIdentical points (Shape) (0.00 min)\n",
      "▶ [low] PointToRaster pourpoints (PP_ID)\n",
      "✅ DONE [low] PointToRaster pourpoints (PP_ID) (0.12 min)\n",
      "[low] SnapPourPoint distance = 150 m (PP_ID raster)\n",
      "▶ [low] Watershed\n",
      "✅ DONE [low] Watershed (0.87 min)\n",
      "▶ [low] RasterToPolygon\n",
      "✅ DONE [low] RasterToPolygon (0.16 min)\n",
      "▶ [low] Calculate PP_ID on ws polys\n",
      "✅ DONE [low] Calculate PP_ID on ws polys (0.01 min)\n",
      "▶ [low] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id\n",
      "✅ DONE [low] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id (0.01 min)\n",
      "▶ [low] Dissolve watersheds by CW_Id\n",
      "✅ DONE [low] Dissolve watersheds by CW_Id (0.04 min)\n",
      "[low] watersheds BEFORE stream erase unique CW_Ids: 4063 (orig wetlands 4882)\n",
      "▶ [low] PairwiseErase watersheds ∖ streammask (partial)\n",
      "✅ DONE [low] PairwiseErase watersheds ∖ streammask (partial) (0.01 min)\n",
      "▶ [low] Dissolve final output\n",
      "✅ DONE [low] Dissolve final output (0.02 min)\n",
      "[low] final watersheds AFTER stream erase unique CW_Ids: 4063 (orig wetlands 4882)\n",
      "\n",
      "==================== SURGE ====================\n",
      "▶ [surge] Project wetlands\n",
      "✅ DONE [surge] Project wetlands (0.02 min)\n",
      "▶ [surge] RepairGeometry wetlands\n",
      "✅ DONE [surge] RepairGeometry wetlands (0.15 min)\n",
      "[surge] unique CW_Ids in ORIGINAL wetlands: 23805\n",
      "▶ [surge] PairwiseErase wetlands ∖ streammask (partial)\n",
      "✅ DONE [surge] PairwiseErase wetlands ∖ streammask (partial) (0.02 min)\n",
      "[surge] CW_Ids remaining after wetland stream-erase: 23805\n",
      "▶ [surge] FeatureToPoint INSIDE (stream-clean wetlands)\n",
      "✅ DONE [surge] FeatureToPoint INSIDE (stream-clean wetlands) (0.02 min)\n",
      "▶ [surge] DeleteIdentical points (Shape)\n",
      "✅ DONE [surge] DeleteIdentical points (Shape) (0.00 min)\n",
      "▶ [surge] PointToRaster pourpoints (PP_ID)\n",
      "✅ DONE [surge] PointToRaster pourpoints (PP_ID) (0.13 min)\n",
      "[surge] SnapPourPoint distance = 150 m (PP_ID raster)\n",
      "▶ [surge] Watershed\n",
      "✅ DONE [surge] Watershed (0.92 min)\n",
      "▶ [surge] RasterToPolygon\n",
      "✅ DONE [surge] RasterToPolygon (0.16 min)\n",
      "▶ [surge] Calculate PP_ID on ws polys\n",
      "✅ DONE [surge] Calculate PP_ID on ws polys (0.01 min)\n",
      "▶ [surge] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id\n",
      "✅ DONE [surge] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id (0.06 min)\n",
      "▶ [surge] Dissolve watersheds by CW_Id\n",
      "✅ DONE [surge] Dissolve watersheds by CW_Id (0.13 min)\n",
      "[surge] watersheds BEFORE stream erase unique CW_Ids: 18063 (orig wetlands 23805)\n",
      "▶ [surge] PairwiseErase watersheds ∖ streammask (partial)\n",
      "✅ DONE [surge] PairwiseErase watersheds ∖ streammask (partial) (0.01 min)\n",
      "▶ [surge] Dissolve final output\n",
      "✅ DONE [surge] Dissolve final output (0.08 min)\n",
      "[surge] final watersheds AFTER stream erase unique CW_Ids: 18063 (orig wetlands 23805)\n",
      "\n",
      "🎉 DONE\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL ROBUST CELL (STREAM ERASE ON WETLANDS + WATERSHEDS, NO LAKE ERASE) ---\n",
    "# ✅ Wetlands: ERASE stream overlap portion (optionally buffered) -> keeps remaining wetland parts\n",
    "# ✅ Watersheds: ERASE stream overlap portion (optionally buffered) -> keeps remaining watershed parts\n",
    "# ✅ SnapPourPoint uses PP_ID (NOT CW_Id) to avoid losing CW_Ids\n",
    "# ❌ No lake erase anywhere\n",
    "\n",
    "import os, gc, time, sys\n",
    "import arcpy\n",
    "from arcpy import sa\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.addOutputsToMap = False\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# -------------------------\n",
    "# REQUIRED: these must already exist in your notebook\n",
    "# -------------------------\n",
    "# outPourpoints, outWatersheds, inStreamsWatershed, D8_flow\n",
    "# erase_buffer_avg/high/low/surge\n",
    "# CoastalWatershed_* output paths\n",
    "\n",
    "os.makedirs(outPourpoints, exist_ok=True)\n",
    "os.makedirs(outWatersheds, exist_ok=True)\n",
    "\n",
    "pp_gdb = os.path.join(outPourpoints, \"pourpoints.gdb\")\n",
    "if not arcpy.Exists(pp_gdb):\n",
    "    arcpy.management.CreateFileGDB(outPourpoints, \"pourpoints.gdb\")\n",
    "\n",
    "ws_gdb = os.path.join(outWatersheds, \"watersheds.gdb\")\n",
    "if not arcpy.Exists(ws_gdb):\n",
    "    arcpy.management.CreateFileGDB(outWatersheds, \"watersheds.gdb\")\n",
    "\n",
    "arcpy.env.workspace = ws_gdb\n",
    "arcpy.env.scratchWorkspace = ws_gdb\n",
    "\n",
    "flowacc = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\"\n",
    "print(f\"✅ flowacc: {flowacc}\", flush=True)\n",
    "\n",
    "cats = {\n",
    "    \"avg\":   (erase_buffer_avg,   CoastalWatershed_avg_erase_lakedrain_LakeHuron),\n",
    "    \"high\":  (erase_buffer_high,  CoastalWatershed_high_erase_lakedrain_LakeHuron),\n",
    "    \"low\":   (erase_buffer_low,   CoastalWatershed_low_erase_lakedrain_LakeHuron),\n",
    "    \"surge\": (erase_buffer_surge, CoastalWatershed_surge_erase_lakedrain_LakeHuron),\n",
    "}\n",
    "CW_ID_FIELD = \"CW_Id\"\n",
    "\n",
    "# -------------------------\n",
    "# Align env to D8 grid\n",
    "# -------------------------\n",
    "D8_SR = arcpy.Describe(D8_flow).spatialReference\n",
    "arcpy.env.snapRaster = D8_flow\n",
    "arcpy.env.cellSize = D8_flow\n",
    "arcpy.env.extent = D8_flow\n",
    "arcpy.env.outputCoordinateSystem = D8_SR\n",
    "cellsize = float(arcpy.Describe(D8_flow).meanCellWidth)\n",
    "\n",
    "print(f\"✅ workspace: {ws_gdb}\", flush=True)\n",
    "print(f\"✅ scratch:   {ws_gdb}\", flush=True)\n",
    "print(f\"✅ D8_flow CRS: {D8_SR.name} (factoryCode={D8_SR.factoryCode})\", flush=True)\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def _log(msg):\n",
    "    print(msg, flush=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def _clear_locks():\n",
    "    try:\n",
    "        arcpy.ClearWorkspaceCache_management()\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "def _safe_delete(p):\n",
    "    try:\n",
    "        if arcpy.Exists(p):\n",
    "            arcpy.management.Delete(p)\n",
    "    except Exception:\n",
    "        _clear_locks()\n",
    "        if arcpy.Exists(p):\n",
    "            arcpy.management.Delete(p)\n",
    "\n",
    "def has_rows(fc):\n",
    "    try:\n",
    "        return int(arcpy.management.GetCount(fc)[0]) > 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _field_map_lower(fc):\n",
    "    return {f.name.lower(): f.name for f in arcpy.ListFields(fc)}\n",
    "\n",
    "def _find_field(fc, candidates):\n",
    "    fmap = _field_map_lower(fc)\n",
    "    for c in candidates:\n",
    "        if c and c.lower() in fmap:\n",
    "            return fmap[c.lower()]\n",
    "    return None\n",
    "\n",
    "def get_field_name_ci(fc, target_name):\n",
    "    if not target_name:\n",
    "        return None\n",
    "    t = target_name.lower()\n",
    "    for f in arcpy.ListFields(fc):\n",
    "        if f.name.lower() == t:\n",
    "            return f.name\n",
    "    return None\n",
    "\n",
    "def _is_shp(path):\n",
    "    return isinstance(path, str) and path.lower().endswith(\".shp\")\n",
    "\n",
    "def _ensure_field(fc, desired_name, field_type=\"LONG\", fallbacks=()):\n",
    "    if not desired_name or not str(desired_name).strip():\n",
    "        desired_name = \"CW_Id\"\n",
    "\n",
    "    existing = get_field_name_ci(fc, desired_name)\n",
    "    if existing:\n",
    "        return existing\n",
    "\n",
    "    candidates = [desired_name] + list(fallbacks)\n",
    "    for nm in candidates:\n",
    "        if not nm:\n",
    "            continue\n",
    "\n",
    "        safe = arcpy.ValidateFieldName(nm, os.path.dirname(fc) if isinstance(fc, str) else \"\")\n",
    "        if _is_shp(fc) and len(safe) > 10:\n",
    "            safe = safe[:10]\n",
    "\n",
    "        existing = get_field_name_ci(fc, safe)\n",
    "        if existing:\n",
    "            return existing\n",
    "\n",
    "        try:\n",
    "            arcpy.management.AddField(fc, safe, field_type)\n",
    "            return get_field_name_ci(fc, safe) or safe\n",
    "        except Exception:\n",
    "            _clear_locks()\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(f\"Cannot add field '{desired_name}' to {fc}\")\n",
    "\n",
    "def _idset(fc, id_field):\n",
    "    fld = get_field_name_ci(fc, id_field) or _find_field(fc, [id_field])\n",
    "    s = set()\n",
    "    if (not fld) or (not has_rows(fc)):\n",
    "        return s\n",
    "    with arcpy.da.SearchCursor(fc, [fld]) as cur:\n",
    "        for (v,) in cur:\n",
    "            if v is not None:\n",
    "                s.add(int(v))\n",
    "    return s\n",
    "\n",
    "def gp(label, func, *args, **kwargs):\n",
    "    _log(f\"▶ {label}\")\n",
    "    t0 = time.time()\n",
    "    out = func(*args, **kwargs)\n",
    "    _log(f\"✅ DONE {label} ({(time.time()-t0)/60:.2f} min)\")\n",
    "    return out\n",
    "\n",
    "# ---------- CRS FIX + PROJECT (TEMP WRITES INTO ws_gdb) ----------\n",
    "def fix_define_and_project_to_gdb(in_fc, out_fc, out_sr, name=\"layer\"):\n",
    "    def _looks_like_degrees(ext):\n",
    "        return (abs(ext.XMin) <= 180 and abs(ext.XMax) <= 180 and abs(ext.YMin) <= 90 and abs(ext.YMax) <= 90)\n",
    "    def _looks_like_projected(ext):\n",
    "        return (max(abs(ext.XMin), abs(ext.XMax), abs(ext.YMin), abs(ext.YMax)) > 1000)\n",
    "\n",
    "    _safe_delete(out_fc)\n",
    "\n",
    "    d = arcpy.Describe(in_fc)\n",
    "    sr = d.spatialReference\n",
    "    ext = d.extent\n",
    "\n",
    "    _log(f\"\\n[{name}] input: {in_fc}\")\n",
    "    _log(f\"[{name}] sr: {sr.name if sr else None} | factoryCode={getattr(sr,'factoryCode',None)} | type={getattr(sr,'type',None)}\")\n",
    "    _log(f\"[{name}] extent: XMin={ext.XMin:.3f} XMax={ext.XMax:.3f} YMin={ext.YMin:.3f} YMax={ext.YMax:.3f}\")\n",
    "\n",
    "    tmp_copy = os.path.join(ws_gdb, f\"tmp_{name}_copy\")\n",
    "    _safe_delete(tmp_copy)\n",
    "\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=None, extent=None, snapRaster=None, cellSize=None):\n",
    "        gp(f\"CopyFeatures {name}\", arcpy.management.CopyFeatures, in_fc, tmp_copy)\n",
    "\n",
    "    d2 = arcpy.Describe(tmp_copy)\n",
    "    sr2 = d2.spatialReference\n",
    "    ext2 = d2.extent\n",
    "\n",
    "    mislabeled_projected = (\n",
    "        sr2 is not None\n",
    "        and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "        and _looks_like_projected(ext2)\n",
    "        and not _looks_like_degrees(ext2)\n",
    "    )\n",
    "\n",
    "    if mislabeled_projected:\n",
    "        _log(f\"[{name}] ⚠️ MISLABELED Geographic but coords are projected. DefineProjection -> {out_sr.name}\")\n",
    "        gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, out_sr)\n",
    "        gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "        _safe_delete(tmp_copy)\n",
    "        return out_fc\n",
    "\n",
    "    # Normal Project\n",
    "    tx = None\n",
    "    try:\n",
    "        txs = arcpy.ListTransformations(sr2, out_sr)\n",
    "        tx = txs[0] if txs else None\n",
    "    except Exception:\n",
    "        tx = None\n",
    "\n",
    "    if tx:\n",
    "        gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr, tx)\n",
    "    else:\n",
    "        gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr)\n",
    "\n",
    "    _safe_delete(tmp_copy)\n",
    "    return out_fc\n",
    "\n",
    "# ============================================================\n",
    "# 0) Build projected STREAM mask ONCE (stored in ws_gdb)\n",
    "# ============================================================\n",
    "inStreamsWS_tgt = os.path.join(ws_gdb, \"inStreamsWS_tgt\")\n",
    "fix_define_and_project_to_gdb(inStreamsWatershed, inStreamsWS_tgt, D8_SR, name=\"inStreamsWS\")\n",
    "gp(\"RepairGeometry stream mask\", arcpy.management.RepairGeometry, inStreamsWS_tgt)\n",
    "\n",
    "inStreams_single = os.path.join(ws_gdb, \"inStreamsWS_single\")\n",
    "_safe_delete(inStreams_single)\n",
    "gp(\"MultipartToSinglepart stream mask\", arcpy.management.MultipartToSinglepart, inStreamsWS_tgt, inStreams_single)\n",
    "\n",
    "inStreamsWS_tgt_diss = os.path.join(ws_gdb, \"inStreamsWS_tgt_diss\")\n",
    "_safe_delete(inStreamsWS_tgt_diss)\n",
    "gp(\"Dissolve stream mask\", arcpy.management.Dissolve, inStreams_single, inStreamsWS_tgt_diss)\n",
    "\n",
    "# ---- Choose how aggressive the wetland/watershed removal should be ----\n",
    "# If you want EXACT removal only where it truly overlaps the stream watershed, set stream_buf_m = 0.\n",
    "# If you want \"remove within distance\", set >0 (e.g., 60m, 120m, etc.).\n",
    "stream_buf_m = 60\n",
    "\n",
    "if stream_buf_m > 0:\n",
    "    inStreamsWS_mask = os.path.join(ws_gdb, f\"inStreamsWS_buf{stream_buf_m}m\")\n",
    "    _safe_delete(inStreamsWS_mask)\n",
    "    gp(\"Buffer stream mask\", arcpy.analysis.Buffer, inStreamsWS_tgt_diss, inStreamsWS_mask,\n",
    "       f\"{stream_buf_m} Meters\", \"FULL\", \"ROUND\", \"ALL\")\n",
    "else:\n",
    "    inStreamsWS_mask = inStreamsWS_tgt_diss\n",
    "    _log(\"▶ stream_buf_m=0 -> using stream watershed polygons WITHOUT buffer\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "for cat, (wet_fc, out_ws_final) in cats.items():\n",
    "\n",
    "    _log(f\"\\n==================== {cat.upper()} ====================\")\n",
    "\n",
    "    # --- 1) Project wetlands to D8 SR\n",
    "    wet_tgt = os.path.join(ws_gdb, f\"{cat}_wet_tgt\")\n",
    "    _safe_delete(wet_tgt)\n",
    "    gp(f\"[{cat}] Project wetlands\", arcpy.management.Project, wet_fc, wet_tgt, D8_SR)\n",
    "\n",
    "    wet_id_f = _ensure_field(wet_tgt, CW_ID_FIELD, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] RepairGeometry wetlands\", arcpy.management.RepairGeometry, wet_tgt)\n",
    "\n",
    "    orig_ids = _idset(wet_tgt, wet_id_f)\n",
    "    _log(f\"[{cat}] unique CW_Ids in ORIGINAL wetlands: {len(orig_ids)}\")\n",
    "\n",
    "    # --- 2) ERASE wetlands by stream watershed (THIS is what you said you need)\n",
    "    wet_no_stream = os.path.join(ws_gdb, f\"{cat}_wet_no_stream\")\n",
    "    _safe_delete(wet_no_stream)\n",
    "    if hasattr(arcpy.analysis, \"PairwiseErase\"):\n",
    "        gp(f\"[{cat}] PairwiseErase wetlands ∖ streammask (partial)\", arcpy.analysis.PairwiseErase, wet_tgt, inStreamsWS_mask, wet_no_stream)\n",
    "    else:\n",
    "        gp(f\"[{cat}] Erase wetlands ∖ streammask (partial)\", arcpy.analysis.Erase, wet_tgt, inStreamsWS_mask, wet_no_stream)\n",
    "\n",
    "    ns_ids = _idset(wet_no_stream, wet_id_f)\n",
    "    _log(f\"[{cat}] CW_Ids remaining after wetland stream-erase: {len(ns_ids)}\")\n",
    "\n",
    "    # --- 3) Pourpoints from wet_no_stream (stream-clean wetlands)\n",
    "    pp_inside = os.path.join(pp_gdb, f\"{cat}_pp_inside\")\n",
    "    _safe_delete(pp_inside)\n",
    "    gp(f\"[{cat}] FeatureToPoint INSIDE (stream-clean wetlands)\", arcpy.management.FeatureToPoint, wet_no_stream, pp_inside, \"INSIDE\")\n",
    "\n",
    "    pp_cw_f = _ensure_field(pp_inside, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "\n",
    "    # --- 4) Fallback pourpoints for CW_Ids that lost ALL wetland area after erase\n",
    "    missing_ids_for_points = sorted(list(orig_ids - ns_ids))\n",
    "    if missing_ids_for_points:\n",
    "        _log(f\"⚠️ [{cat}] {len(missing_ids_for_points)} CW_Ids have NO wetland left after stream-erase; adding fallback points from ORIGINAL wetlands.\")\n",
    "\n",
    "        wet_orig_diss = os.path.join(ws_gdb, f\"{cat}_wet_orig_diss\")\n",
    "        _safe_delete(wet_orig_diss)\n",
    "        gp(f\"[{cat}] Dissolve ORIGINAL wetlands by CW_Id (fallback)\", arcpy.management.Dissolve, wet_tgt, wet_orig_diss, wet_id_f)\n",
    "\n",
    "        wet_missing_poly = os.path.join(ws_gdb, f\"{cat}_wet_missing_poly\")\n",
    "        _safe_delete(wet_missing_poly)\n",
    "\n",
    "        lyr = f\"lyr_{cat}_missing\"\n",
    "        arcpy.management.MakeFeatureLayer(wet_orig_diss, lyr)\n",
    "        arcpy.management.SelectLayerByAttribute(lyr, \"CLEAR_SELECTION\")\n",
    "\n",
    "        chunk = 900\n",
    "        for i in range(0, len(missing_ids_for_points), chunk):\n",
    "            sub = missing_ids_for_points[i:i+chunk]\n",
    "            where = f\"{arcpy.AddFieldDelimiters(lyr, wet_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "            arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "\n",
    "        gp(f\"[{cat}] Copy fallback polys\", arcpy.management.CopyFeatures, lyr, wet_missing_poly)\n",
    "        arcpy.management.Delete(lyr)\n",
    "\n",
    "        pp_fallback = os.path.join(pp_gdb, f\"{cat}_pp_fallback\")\n",
    "        _safe_delete(pp_fallback)\n",
    "        gp(f\"[{cat}] FeatureToPoint INSIDE (fallback)\", arcpy.management.FeatureToPoint, wet_missing_poly, pp_fallback, \"INSIDE\")\n",
    "\n",
    "        gp(f\"[{cat}] Append fallback points\", arcpy.management.Append, pp_fallback, pp_inside, \"NO_TEST\")\n",
    "\n",
    "        _safe_delete(pp_fallback)\n",
    "        _safe_delete(wet_missing_poly)\n",
    "        _safe_delete(wet_orig_diss)\n",
    "\n",
    "    # Optional de-dup\n",
    "    try:\n",
    "        gp(f\"[{cat}] DeleteIdentical points (Shape)\", arcpy.management.DeleteIdentical, pp_inside, [\"Shape\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --- 5) Assign unique PP_ID per point (prevents CW_Id loss)\n",
    "    PP_ID = _ensure_field(pp_inside, \"PP_ID\", \"LONG\", fallbacks=(\"PPID\",))\n",
    "    oid = arcpy.Describe(pp_inside).OIDFieldName\n",
    "    with arcpy.da.UpdateCursor(pp_inside, [oid, PP_ID]) as cur:\n",
    "        i = 1\n",
    "        for row in cur:\n",
    "            row[1] = i\n",
    "            cur.updateRow(row)\n",
    "            i += 1\n",
    "\n",
    "    # --- 6) SnapPourPoint on PP_ID raster (NOT CW_Id raster)\n",
    "    pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_ras\")\n",
    "    _safe_delete(pp_ras)\n",
    "    gp(f\"[{cat}] PointToRaster pourpoints (PP_ID)\", arcpy.conversion.PointToRaster, pp_inside, PP_ID, pp_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "    snapped_pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_snapped_ras\")\n",
    "    _safe_delete(snapped_pp_ras)\n",
    "    snap_dist_m = 150\n",
    "    _log(f\"[{cat}] SnapPourPoint distance = {snap_dist_m} m (PP_ID raster)\")\n",
    "    sa.SnapPourPoint(sa.Raster(pp_ras), sa.Raster(flowacc), snap_dist_m).save(snapped_pp_ras)\n",
    "\n",
    "    # --- 7) Watershed using snapped PP_ID raster\n",
    "    ws_ras = os.path.join(ws_gdb, f\"{cat}_ws_ras\")\n",
    "    _safe_delete(ws_ras)\n",
    "    _log(f\"▶ [{cat}] Watershed\")\n",
    "    t0 = time.time()\n",
    "    sa.Watershed(D8_flow, snapped_pp_ras).save(ws_ras)\n",
    "    _log(f\"✅ DONE [{cat}] Watershed ({(time.time()-t0)/60:.2f} min)\")\n",
    "\n",
    "    # --- 8) RasterToPolygon (GRIDCODE = PP_ID), join PP_ID -> CW_Id, then dissolve by CW_Id\n",
    "    ws_poly_raw = os.path.join(ws_gdb, f\"{cat}_ws_poly_raw\")\n",
    "    _safe_delete(ws_poly_raw)\n",
    "    gp(f\"[{cat}] RasterToPolygon\", arcpy.conversion.RasterToPolygon, ws_ras, ws_poly_raw, \"NO_SIMPLIFY\", \"VALUE\")\n",
    "\n",
    "    grid_field = _find_field(ws_poly_raw, [\"GRIDCODE\",\"GRID_CODE\"])\n",
    "    if not grid_field:\n",
    "        raise RuntimeError(f\"[{cat}] GRIDCODE missing in watershed polygons.\")\n",
    "\n",
    "    PP_SRC = _ensure_field(ws_poly_raw, \"PP_ID\", \"LONG\", fallbacks=(\"PPID\",))\n",
    "    gp(f\"[{cat}] Calculate PP_ID on ws polys\", arcpy.management.CalculateField, ws_poly_raw, PP_SRC, f\"!{grid_field}!\", \"PYTHON3\")\n",
    "\n",
    "    gp(f\"[{cat}] JoinField ws_poly_raw.PP_ID -> pp_inside.PP_ID to bring CW_Id\",\n",
    "       arcpy.management.JoinField, ws_poly_raw, PP_SRC, pp_inside, PP_ID, [pp_cw_f])\n",
    "\n",
    "    ws_cw = get_field_name_ci(ws_poly_raw, pp_cw_f) or get_field_name_ci(ws_poly_raw, CW_ID_FIELD)\n",
    "    if not ws_cw:\n",
    "        raise RuntimeError(f\"[{cat}] CW_Id not found after JoinField. Fields: {[f.name for f in arcpy.ListFields(ws_poly_raw)]}\")\n",
    "\n",
    "    ws_poly = os.path.join(ws_gdb, f\"{cat}_ws_poly\")\n",
    "    _safe_delete(ws_poly)\n",
    "    gp(f\"[{cat}] Dissolve watersheds by CW_Id\", arcpy.management.Dissolve, ws_poly_raw, ws_poly, ws_cw)\n",
    "\n",
    "    _log(f\"[{cat}] watersheds BEFORE stream erase unique CW_Ids: {len(_idset(ws_poly, ws_cw))} (orig wetlands {len(orig_ids)})\")\n",
    "\n",
    "    # --- 9) ERASE watersheds by stream watershed (partial)\n",
    "    tmp_no_stream = os.path.join(ws_gdb, f\"{cat}_ws_no_stream\")\n",
    "    _safe_delete(tmp_no_stream)\n",
    "\n",
    "    if hasattr(arcpy.analysis, \"PairwiseErase\"):\n",
    "        gp(f\"[{cat}] PairwiseErase watersheds ∖ streammask (partial)\", arcpy.analysis.PairwiseErase, ws_poly, inStreamsWS_mask, tmp_no_stream)\n",
    "    else:\n",
    "        gp(f\"[{cat}] Erase watersheds ∖ streammask (partial)\", arcpy.analysis.Erase, ws_poly, inStreamsWS_mask, tmp_no_stream)\n",
    "\n",
    "    _safe_delete(out_ws_final)\n",
    "    if has_rows(tmp_no_stream):\n",
    "        gp(f\"[{cat}] Dissolve final output\", arcpy.management.Dissolve, tmp_no_stream, out_ws_final, ws_cw)\n",
    "    else:\n",
    "        gp(f\"[{cat}] Copy empty output\", arcpy.management.CopyFeatures, tmp_no_stream, out_ws_final)\n",
    "\n",
    "    _log(f\"[{cat}] final watersheds AFTER stream erase unique CW_Ids: {len(_idset(out_ws_final, ws_cw))} (orig wetlands {len(orig_ids)})\")\n",
    "\n",
    "    _clear_locks()\n",
    "\n",
    "_log(\"\\n🎉 DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c846a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ flowacc: S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\n",
      "✅ workspace: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n",
      "✅ scratch:   D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\n",
      "✅ D8_flow CRS: NAD_1983_Great_Lakes_Basin_Albers (factoryCode=3174)\n",
      "\n",
      "[inStreamsWS] input: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\Streamwatershed\\PointWaterdhed_LH.shp\n",
      "[inStreamsWS] sr: GCS_WGS_1984 | factoryCode=4326 | type=Geographic\n",
      "[inStreamsWS] extent: XMin=929846.850 XMax=1166434.867 YMin=651452.122 YMax=1020243.911\n",
      "▶ CopyFeatures inStreamsWS\n",
      "✅ DONE CopyFeatures inStreamsWS (0.01 min)\n",
      "[inStreamsWS] ⚠️ MISLABELED Geographic but coords are projected. DefineProjection -> NAD_1983_Great_Lakes_Basin_Albers\n",
      "▶ DefineProjection inStreamsWS\n",
      "✅ DONE DefineProjection inStreamsWS (0.00 min)\n",
      "▶ Copy to output inStreamsWS\n",
      "✅ DONE Copy to output inStreamsWS (0.01 min)\n",
      "▶ RepairGeometry stream mask\n",
      "✅ DONE RepairGeometry stream mask (0.00 min)\n",
      "▶ MultipartToSinglepart stream mask\n",
      "✅ DONE MultipartToSinglepart stream mask (0.01 min)\n",
      "▶ Dissolve stream mask\n",
      "✅ DONE Dissolve stream mask (0.00 min)\n",
      "▶ Buffer stream mask\n",
      "✅ DONE Buffer stream mask (0.01 min)\n",
      "\n",
      "[LakeHuron] input: D:\\Users\\abolmaal\\code\\boundry\\hydro_p_LakeHuron\\hydro_p_LakeHuron.shp\n",
      "[LakeHuron] sr: Geographic | factoryCode=0 | type=Geographic\n",
      "[LakeHuron] extent: XMin=-84.752 XMax=-79.668 YMin=42.996 YMax=46.333\n",
      "▶ CopyFeatures LakeHuron\n",
      "✅ DONE CopyFeatures LakeHuron (0.00 min)\n",
      "[LakeHuron] ⚠️ GENERIC geographic degrees. DefineProjection -> EPSG:4326 then Project.\n",
      "▶ DefineProjection LakeHuron\n",
      "✅ DONE DefineProjection LakeHuron (0.00 min)\n",
      "[LakeHuron] Project -> NAD_1983_Great_Lakes_Basin_Albers | transform=WGS_1984_(ITRF00)_To_NAD_1983\n",
      "▶ Project LakeHuron\n",
      "✅ DONE Project LakeHuron (0.01 min)\n",
      "▶ RepairGeometry lake\n",
      "✅ DONE RepairGeometry lake (0.00 min)\n",
      "▶ PolygonToRaster LakeHuron_mask_ras\n",
      "✅ DONE PolygonToRaster LakeHuron_mask_ras (0.11 min)\n",
      "▶ Build flowacc_land = flowacc where NOT lake\n",
      "✅ flowacc_land: D:\\Users\\abolmaal\\Arcgis\\NASAOceanProject\\GIS_layer\\CoastalWatersheds\\Watershed_rasters\\watersheds.gdb\\flowacc_land\n",
      "\n",
      "==================== AVG ====================\n",
      "▶ [avg] Project wetlands\n",
      "✅ DONE [avg] Project wetlands (0.01 min)\n",
      "▶ [avg] RepairGeometry wetlands\n",
      "✅ DONE [avg] RepairGeometry wetlands (0.07 min)\n",
      "[avg] unique CW_Ids in ORIGINAL wetlands: 9503\n",
      "▶ [avg] Erase stream-mask from wetlands (PARTIAL)\n",
      "✅ DONE [avg] Erase stream-mask from wetlands (PARTIAL) (0.01 min)\n",
      "▶ [avg] Erase lake from wetlands (land-only)\n",
      "✅ DONE [avg] Erase lake from wetlands (land-only) (0.03 min)\n",
      "▶ [avg] Build pourpoints (boundary from wet_land)\n",
      "▶ PolygonToLine (wet boundary)\n",
      "✅ DONE PolygonToLine (wet boundary) (0.02 min)\n",
      "▶ FeatureVerticesToPoints (ALL)\n",
      "✅ DONE FeatureVerticesToPoints (ALL) (0.03 min)\n",
      "▶ SpatialJoin vertices -> wetlands (attach CW_Id)\n",
      "✅ DONE SpatialJoin vertices -> wetlands (attach CW_Id) (0.09 min)\n",
      "▶ ExtractValuesToPoints (flowacc)\n",
      "✅ DONE ExtractValuesToPoints (flowacc) (0.05 min)\n",
      "▶ Select non-null flowacc\n",
      "✅ DONE Select non-null flowacc (0.00 min)\n",
      "▶ Copy non-null flowacc pts\n",
      "✅ DONE Copy non-null flowacc pts (0.01 min)\n",
      "⚠️ boundary flowacc sampling returned ALL NULL; using boundary vertices (no flowacc ranking) as pourpoints.\n",
      "▶ Create output pourpoints FC\n",
      "✅ DONE Create output pourpoints FC (0.01 min)\n",
      "✅ DONE [avg] Build pourpoints (boundary from wet_land) (0.24 min)\n",
      "[avg] CW_Ids missing pourpoints from wet_land: 4038\n",
      "▶ [avg] Dissolve ORIGINAL wetlands by CW_Id (fallback pourpoints)\n",
      "✅ DONE [avg] Dissolve ORIGINAL wetlands by CW_Id (fallback pourpoints) (0.04 min)\n",
      "▶ [avg] Copy missing CW_Id polygons (fallback)\n",
      "✅ DONE [avg] Copy missing CW_Id polygons (fallback) (0.01 min)\n",
      "▶ [avg] Build fallback boundary pourpoints (missing IDs)\n",
      "▶ PolygonToLine (wet boundary)\n",
      "✅ DONE PolygonToLine (wet boundary) (0.01 min)\n",
      "▶ FeatureVerticesToPoints (ALL)\n",
      "✅ DONE FeatureVerticesToPoints (ALL) (0.01 min)\n",
      "▶ SpatialJoin vertices -> wetlands (attach CW_Id)\n",
      "✅ DONE SpatialJoin vertices -> wetlands (attach CW_Id) (0.03 min)\n",
      "▶ ExtractValuesToPoints (flowacc)\n",
      "✅ DONE ExtractValuesToPoints (flowacc) (0.03 min)\n",
      "▶ Select non-null flowacc\n",
      "✅ DONE Select non-null flowacc (0.00 min)\n",
      "▶ Copy non-null flowacc pts\n",
      "✅ DONE Copy non-null flowacc pts (0.01 min)\n",
      "⚠️ boundary flowacc sampling returned ALL NULL; using boundary vertices (no flowacc ranking) as pourpoints.\n",
      "▶ Create output pourpoints FC\n",
      "✅ DONE Create output pourpoints FC (0.01 min)\n",
      "✅ DONE [avg] Build fallback boundary pourpoints (missing IDs) (0.13 min)\n",
      "▶ [avg] Append fallback -> main pourpoints\n",
      "✅ DONE [avg] Append fallback -> main pourpoints (0.01 min)\n",
      "[avg] pourpoints CW_Ids present (after fallback): 9503\n",
      "▶ [avg] PointToRaster pourpoints (CW_Id)\n",
      "✅ DONE [avg] PointToRaster pourpoints (CW_Id) (0.12 min)\n",
      "[avg] SnapPourPoint pass1 = 150 m\n",
      "▶ [avg] RasterToPoint snapped pourpoints (pass1)\n",
      "✅ DONE [avg] RasterToPoint snapped pourpoints (pass1) (0.09 min)\n",
      "▶ [avg] Calculate CW_Id on snapped points (pass1)\n",
      "✅ DONE [avg] Calculate CW_Id on snapped points (pass1) (0.01 min)\n",
      "[avg] snapped CW_Ids pass1: 8582 | missing after pass1: 921\n",
      "▶ [avg] Copy snapped pass1 -> combined\n",
      "✅ DONE [avg] Copy snapped pass1 -> combined (0.01 min)\n",
      "▶ [avg] Copy missing pourpoints for snap2\n",
      "✅ DONE [avg] Copy missing pourpoints for snap2 (0.01 min)\n",
      "▶ [avg] PointToRaster missing pourpoints\n",
      "✅ DONE [avg] PointToRaster missing pourpoints (0.12 min)\n",
      "[avg] SnapPourPoint pass2 = 2000 m (missing CW_Ids only)\n",
      "▶ [avg] RasterToPoint snapped pourpoints (pass2)\n",
      "✅ DONE [avg] RasterToPoint snapped pourpoints (pass2) (0.08 min)\n",
      "▶ [avg] Calculate CW_Id on snapped points (pass2)\n",
      "✅ DONE [avg] Calculate CW_Id on snapped points (pass2) (0.00 min)\n",
      "▶ [avg] Append snapped pass2 -> combined\n",
      "✅ DONE [avg] Append snapped pass2 -> combined (0.00 min)\n",
      "[avg] combined snapped CW_Ids: 9441 (target 9503)\n",
      "[avg] duplicate snapped-cell CW_Ids: 859\n",
      "▶ [avg] Copy duplicate CW_Id pourpoints\n",
      "✅ DONE [avg] Copy duplicate CW_Id pourpoints (0.00 min)\n",
      "▶ [avg] PointToRaster dupe pourpoints\n",
      "✅ DONE [avg] PointToRaster dupe pourpoints (0.11 min)\n",
      "[avg] Re-snap duplicates with distance = 300 m\n",
      "▶ [avg] RasterToPoint dupe snapped\n",
      "✅ DONE [avg] RasterToPoint dupe snapped (0.08 min)\n",
      "▶ [avg] Calc CW_Id dupe snapped\n",
      "✅ DONE [avg] Calc CW_Id dupe snapped (0.00 min)\n",
      "▶ [avg] Copy snapped (without dupes)\n",
      "✅ DONE [avg] Copy snapped (without dupes) (0.01 min)\n",
      "▶ [avg] Append re-snapped dupes\n",
      "✅ DONE [avg] Append re-snapped dupes (0.00 min)\n",
      "▶ [avg] Replace snapped_pts with de-collided version\n",
      "✅ DONE [avg] Replace snapped_pts with de-collided version (0.01 min)\n",
      "[avg] snapped CW_Ids AFTER collision repair: 9441 (target 9503)\n",
      "▶ [avg] PointToRaster snapped points (CW_Id)\n",
      "✅ DONE [avg] PointToRaster snapped points (CW_Id) (0.13 min)\n",
      "▶ [avg] Watershed\n",
      "✅ DONE [avg] Watershed (0.78 min)\n",
      "▶ [avg] RasterToPolygon\n",
      "✅ DONE [avg] RasterToPolygon (0.13 min)\n",
      "▶ [avg] Calculate CW_Id on watershed polygons\n",
      "✅ DONE [avg] Calculate CW_Id on watershed polygons (0.01 min)\n",
      "▶ [avg] Dissolve watersheds by CW_Id\n",
      "✅ DONE [avg] Dissolve watersheds by CW_Id (0.07 min)\n",
      "[avg] watersheds BEFORE clip: 8582 CW_Ids (target 9503)\n",
      "▶ [avg] Erase lake from watersheds (partial)\n",
      "✅ DONE [avg] Erase lake from watersheds (partial) (0.02 min)\n",
      "▶ [avg] Erase stream mask from watersheds (partial)\n",
      "✅ DONE [avg] Erase stream mask from watersheds (partial) (0.01 min)\n",
      "▶ [avg] Dissolve final output (after clips)\n",
      "✅ DONE [avg] Dissolve final output (after clips) (0.03 min)\n",
      "[avg] final watersheds AFTER clip: 5841 CW_Ids (target 9503)\n",
      "[avg] missing CW_Ids after clip: 3662\n",
      "▶ [avg] Copy missing CW_Ids from UNCLIPPED watersheds (fallback)\n",
      "✅ DONE [avg] Copy missing CW_Ids from UNCLIPPED watersheds (fallback) (0.01 min)\n",
      "▶ [avg] Append unclipped fallback -> final\n"
     ]
    },
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 000464: Cannot get exclusive schema lock.  Either being edited or in use by another application or service.\nFailed to execute (Append).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 740\u001b[0m\n\u001b[0;32m    737\u001b[0m gp(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Copy missing CW_Ids from UNCLIPPED watersheds (fallback)\u001b[39m\u001b[38;5;124m\"\u001b[39m, arcpy\u001b[38;5;241m.\u001b[39mmanagement\u001b[38;5;241m.\u001b[39mCopyFeatures, lyr, ws_missing)\n\u001b[0;32m    738\u001b[0m arcpy\u001b[38;5;241m.\u001b[39mmanagement\u001b[38;5;241m.\u001b[39mDelete(lyr)\n\u001b[1;32m--> 740\u001b[0m \u001b[43mgp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcat\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m] Append unclipped fallback -> final\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanagement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAppend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mws_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_ws_lake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNO_TEST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    742\u001b[0m out_ws_lake_diss \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ws_gdb, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_final_diss_after_fallback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    743\u001b[0m _safe_delete(out_ws_lake_diss)\n",
      "Cell \u001b[1;32mIn[7], line 196\u001b[0m, in \u001b[0;36mgp\u001b[1;34m(label, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m _log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m▶ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 196\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m _log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ DONE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py:11421\u001b[0m, in \u001b[0;36mAppend\u001b[1;34m(inputs, target, schema_type, field_mapping, subtype, expression, match_fields, update_geometry, enforce_domains, feature_service_mode)\u001b[0m\n\u001b[0;32m  11419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m  11420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m> 11421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py:11401\u001b[0m, in \u001b[0;36mAppend\u001b[1;34m(inputs, target, schema_type, field_mapping, subtype, expression, match_fields, update_geometry, enforce_domains, feature_service_mode)\u001b[0m\n\u001b[0;32m  11397\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marcpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marcobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marcobjectconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convertArcObjectToPythonObject\n\u001b[0;32m  11399\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m  11400\u001b[0m     retval \u001b[38;5;241m=\u001b[39m convertArcObjectToPythonObject(\n\u001b[1;32m> 11401\u001b[0m         \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAppend_management\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11402\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgp_fixargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11403\u001b[0m \u001b[43m                \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11404\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11405\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11406\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mschema_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11407\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfield_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11408\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11409\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11410\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmatch_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11411\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mupdate_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11412\u001b[0m \u001b[43m                    \u001b[49m\u001b[43menforce_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11413\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeature_service_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11414\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11415\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  11416\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11417\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11418\u001b[0m     )\n\u001b[0;32m  11419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m  11420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py:533\u001b[0m, in \u001b[0;36mGeoprocessor.__getattr__.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    531\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp, attr)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(val):\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgp_fixargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convertArcObjectToPythonObject(val)\n",
      "\u001b[1;31mExecuteError\u001b[0m: ERROR 000464: Cannot get exclusive schema lock.  Either being edited or in use by another application or service.\nFailed to execute (Append).\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL ROBUST CELL (OPTION A, UPDATED v7)\n",
    "# Option A = boundary-based pourpoints (NOT interior FeatureToPoint), Top-N per CW_Id.\n",
    "#\n",
    "# What this version fixes (based on your AVG log):\n",
    "#  1) ✅ Pourpoints coverage: uses wet_land boundary + fallback boundary points from ORIGINAL wetlands\n",
    "#     so pourpoints CW_Ids present == original CW_Ids.\n",
    "#  2) ✅ SnapPourPoint: two-pass snapping (missing-only pass with larger distance).\n",
    "#  3) ✅ BIG missing watersheds BEFORE clip: fixes SnapPourPoint collisions (multiple CW_Ids snapped to same cell),\n",
    "#     which otherwise get dropped at PointToRaster and never become watersheds.\n",
    "#  4) ✅ BIG missing watersheds AFTER clip: optional \"clip fallback\" to keep CW_Id if clip erases entire polygon.\n",
    "#\n",
    "# IMPORTANT CHOICE:\n",
    "#  - If you truly want \"remove overlap parts no matter what\", then you must accept that some CW_Ids disappear\n",
    "#    after clip if the whole polygon is inside the clip mask. In that case, set CLIP_FALLBACK=False below.\n",
    "#  - If you want to keep CW_Id coverage, set CLIP_FALLBACK=True (default).\n",
    "\n",
    "import os, gc, time, sys, math\n",
    "import arcpy\n",
    "from arcpy import sa\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.addOutputsToMap = False\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# -------------------------\n",
    "# REQUIRED (must exist in notebook)\n",
    "# -------------------------\n",
    "# outPourpoints, outWatersheds, inStreamsWatershed, Lake_Huron, D8_flow\n",
    "# erase_buffer_avg/high/low/surge\n",
    "# CoastalWatershed_avg_erase_lakedrain, CoastalWatershed_avg_erase_lakedrain_LakeHuron\n",
    "# CoastalWatershed_high_erase_lakedrain, CoastalWatershed_high_erase_lakedrain_LakeHuron\n",
    "# CoastalWatershed_low_erase_lakedrain,  CoastalWatershed_low_erase_lakedrain_LakeHuron\n",
    "# CoastalWatershed_surge_erase_lakedrain, CoastalWatershed_surge_erase_lakedrain_LakeHuron\n",
    "\n",
    "os.makedirs(outPourpoints, exist_ok=True)\n",
    "os.makedirs(outWatersheds, exist_ok=True)\n",
    "\n",
    "pp_gdb = os.path.join(outPourpoints, \"pourpoints.gdb\")\n",
    "if not arcpy.Exists(pp_gdb):\n",
    "    arcpy.management.CreateFileGDB(outPourpoints, \"pourpoints.gdb\")\n",
    "\n",
    "ws_gdb = os.path.join(outWatersheds, \"watersheds.gdb\")\n",
    "if not arcpy.Exists(ws_gdb):\n",
    "    arcpy.management.CreateFileGDB(outWatersheds, \"watersheds.gdb\")\n",
    "\n",
    "# Force all workspace/scratch into ws_gdb (avoid C:\\ temp)\n",
    "arcpy.env.workspace = ws_gdb\n",
    "arcpy.env.scratchWorkspace = ws_gdb\n",
    "\n",
    "# -------------------------\n",
    "# Inputs\n",
    "# -------------------------\n",
    "flowacc = r\"S:\\Projects\\Active\\GLB_Nutrient_Transport\\DEM_rasters\\GLB_Bdry_buff10km_dem_fill_flowaccu.tif\"\n",
    "print(f\"✅ flowacc: {flowacc}\", flush=True)\n",
    "\n",
    "cats = {\n",
    "    \"avg\":   (erase_buffer_avg,   CoastalWatershed_avg_erase_lakedrain,   CoastalWatershed_avg_erase_lakedrain_LakeHuron),\n",
    "    \"high\":  (erase_buffer_high,  CoastalWatershed_high_erase_lakedrain,  CoastalWatershed_high_erase_lakedrain_LakeHuron),\n",
    "    \"low\":   (erase_buffer_low,   CoastalWatershed_low_erase_lakedrain,   CoastalWatershed_low_erase_lakedrain_LakeHuron),\n",
    "    \"surge\": (erase_buffer_surge, CoastalWatershed_surge_erase_lakedrain, CoastalWatershed_surge_erase_lakedrain_LakeHuron),\n",
    "}\n",
    "\n",
    "CW_ID_FIELD = \"CW_Id\"\n",
    "\n",
    "# -------------------------\n",
    "# Align env to D8 grid\n",
    "# -------------------------\n",
    "D8_SR = arcpy.Describe(D8_flow).spatialReference\n",
    "arcpy.env.snapRaster = D8_flow\n",
    "arcpy.env.cellSize   = D8_flow\n",
    "arcpy.env.extent     = D8_flow\n",
    "arcpy.env.outputCoordinateSystem = D8_SR\n",
    "cellsize = float(arcpy.Describe(D8_flow).meanCellWidth)\n",
    "\n",
    "print(f\"✅ workspace: {ws_gdb}\", flush=True)\n",
    "print(f\"✅ scratch:   {ws_gdb}\", flush=True)\n",
    "print(f\"✅ D8_flow CRS: {D8_SR.name} (factoryCode={D8_SR.factoryCode})\", flush=True)\n",
    "\n",
    "# -------------------------\n",
    "# Tunables\n",
    "# -------------------------\n",
    "TOP_N_PER_CWID = 1\n",
    "snap_dist_1 = 150\n",
    "snap_dist_2 = 2000          # missing-only pass; try 3000 if still missing snapped IDs\n",
    "stream_buf_m = 60\n",
    "CLIP_FALLBACK = True        # keep CW_Id coverage if clip erases everything\n",
    "COLLISION_REPAIR = True     # repair snapped-cell collisions BEFORE watershed\n",
    "COLLISION_RESNAP_DIST = 300 # how far to re-snap duplicates (>=snap_dist_1)\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def _log(msg):\n",
    "    print(msg, flush=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def _clear_locks():\n",
    "    try:\n",
    "        arcpy.ClearWorkspaceCache_management()\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "def _safe_delete(p):\n",
    "    try:\n",
    "        if arcpy.Exists(p):\n",
    "            arcpy.management.Delete(p)\n",
    "    except Exception:\n",
    "        _clear_locks()\n",
    "        if arcpy.Exists(p):\n",
    "            arcpy.management.Delete(p)\n",
    "\n",
    "def _field_map_lower(fc):\n",
    "    return {f.name.lower(): f.name for f in arcpy.ListFields(fc)}\n",
    "\n",
    "def _find_field(fc, candidates):\n",
    "    fmap = _field_map_lower(fc)\n",
    "    for c in candidates:\n",
    "        if c and c.lower() in fmap:\n",
    "            return fmap[c.lower()]\n",
    "    return None\n",
    "\n",
    "def get_field_name_ci(fc, target_name):\n",
    "    if not target_name:\n",
    "        return None\n",
    "    t = target_name.lower()\n",
    "    for f in arcpy.ListFields(fc):\n",
    "        if f.name.lower() == t:\n",
    "            return f.name\n",
    "    return None\n",
    "\n",
    "def _ensure_field(fc, desired_name, field_type=\"LONG\", fallbacks=()):\n",
    "    if not desired_name or not str(desired_name).strip():\n",
    "        desired_name = \"CW_Id\"\n",
    "    existing = get_field_name_ci(fc, desired_name)\n",
    "    if existing:\n",
    "        return existing\n",
    "    for nm in [desired_name] + list(fallbacks):\n",
    "        if not nm:\n",
    "            continue\n",
    "        safe = arcpy.ValidateFieldName(nm, os.path.dirname(fc) if isinstance(fc, str) else \"\")\n",
    "        if isinstance(fc, str) and fc.lower().endswith(\".shp\") and len(safe) > 10:\n",
    "            safe = safe[:10]\n",
    "        existing = get_field_name_ci(fc, safe)\n",
    "        if existing:\n",
    "            return existing\n",
    "        try:\n",
    "            arcpy.management.AddField(fc, safe, field_type)\n",
    "            return get_field_name_ci(fc, safe) or safe\n",
    "        except Exception:\n",
    "            _clear_locks()\n",
    "            continue\n",
    "    raise RuntimeError(f\"Cannot add field '{desired_name}' to {fc}\")\n",
    "\n",
    "def _idset(fc, id_field):\n",
    "    fld = get_field_name_ci(fc, id_field) or _find_field(fc, [id_field])\n",
    "    s = set()\n",
    "    with arcpy.da.SearchCursor(fc, [fld]) as cur:\n",
    "        for (v,) in cur:\n",
    "            if v is not None:\n",
    "                s.add(int(v))\n",
    "    return s\n",
    "\n",
    "def count_unique(fc, id_field):\n",
    "    return len(_idset(fc, id_field))\n",
    "\n",
    "def calculate_area_m2(fc, field=\"WS_AREAM2\"):\n",
    "    try:\n",
    "        field = _ensure_field(fc, field, \"DOUBLE\", fallbacks=(\"AREA_M2\",\"A_M2\",\"AREA\"))\n",
    "        arcpy.management.CalculateGeometryAttributes(fc, [[field, \"AREA\"]], area_unit=\"SQUARE_METERS\")\n",
    "    except Exception as e:\n",
    "        _log(f\"⚠️ area field skipped: {e}\")\n",
    "    return field\n",
    "\n",
    "def add_xy_ll(fc, prefix=\"WS\"):\n",
    "    try:\n",
    "        cx = _ensure_field(fc, f\"{prefix}_cx\", \"DOUBLE\", fallbacks=(f\"{prefix}X\",))\n",
    "        cy = _ensure_field(fc, f\"{prefix}_cy\", \"DOUBLE\", fallbacks=(f\"{prefix}Y\",))\n",
    "        arcpy.management.CalculateField(fc, cx, \"!SHAPE.centroid.X!\", \"PYTHON3\")\n",
    "        arcpy.management.CalculateField(fc, cy, \"!SHAPE.centroid.Y!\", \"PYTHON3\")\n",
    "\n",
    "        lon = _ensure_field(fc, f\"{prefix}_lon\", \"DOUBLE\", fallbacks=(f\"{prefix}LON\",))\n",
    "        lat = _ensure_field(fc, f\"{prefix}_lat\", \"DOUBLE\", fallbacks=(f\"{prefix}LAT\",))\n",
    "        arcpy.management.CalculateGeometryAttributes(\n",
    "            fc,\n",
    "            [[lat, \"CENTROID_Y\"], [lon, \"CENTROID_X\"]],\n",
    "            coordinate_system=arcpy.SpatialReference(4326),\n",
    "            coordinate_format=\"DD\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        _log(f\"⚠️ xy/ll fields skipped: {e}\")\n",
    "\n",
    "def gp(label, func, *args, **kwargs):\n",
    "    _log(f\"▶ {label}\")\n",
    "    t0 = time.time()\n",
    "    out = func(*args, **kwargs)\n",
    "    _log(f\"✅ DONE {label} ({(time.time()-t0)/60:.2f} min)\")\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# CRS Fixer (mislabeled geographic -> define/project safely)\n",
    "# ============================================================\n",
    "def fix_define_and_project_to_gdb(in_fc, out_fc, out_sr, assumed_src_if_mislabeled=None, name=\"layer\"):\n",
    "    def _looks_like_degrees(ext):\n",
    "        return (abs(ext.XMin) <= 180 and abs(ext.XMax) <= 180 and abs(ext.YMin) <= 90 and abs(ext.YMax) <= 90)\n",
    "    def _looks_like_projected(ext):\n",
    "        return (max(abs(ext.XMin), abs(ext.XMax), abs(ext.YMin), abs(ext.YMax)) > 1000)\n",
    "    def _pick_transform(in_sr, out_sr):\n",
    "        try:\n",
    "            tx = arcpy.ListTransformations(in_sr, out_sr)\n",
    "            return tx[0] if tx else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    _safe_delete(out_fc)\n",
    "\n",
    "    d = arcpy.Describe(in_fc)\n",
    "    sr = d.spatialReference\n",
    "    ext = d.extent\n",
    "\n",
    "    _log(f\"\\n[{name}] input: {in_fc}\")\n",
    "    _log(f\"[{name}] sr: {sr.name if sr else None} | factoryCode={getattr(sr,'factoryCode',None)} | type={getattr(sr,'type',None)}\")\n",
    "    _log(f\"[{name}] extent: XMin={ext.XMin:.3f} XMax={ext.XMax:.3f} YMin={ext.YMin:.3f} YMax={ext.YMax:.3f}\")\n",
    "\n",
    "    tmp_copy = os.path.join(ws_gdb, f\"tmp_{name}_copy\")\n",
    "    _safe_delete(tmp_copy)\n",
    "\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=None, extent=None, snapRaster=None, cellSize=None):\n",
    "        gp(f\"CopyFeatures {name}\", arcpy.management.CopyFeatures, in_fc, tmp_copy)\n",
    "\n",
    "    d2 = arcpy.Describe(tmp_copy)\n",
    "    sr2 = d2.spatialReference\n",
    "    ext2 = d2.extent\n",
    "\n",
    "    mislabeled_projected = (\n",
    "        sr2 is not None and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "        and _looks_like_projected(ext2) and not _looks_like_degrees(ext2)\n",
    "    )\n",
    "    if mislabeled_projected:\n",
    "        _log(f\"[{name}] ⚠️ MISLABELED Geographic but coords are projected. DefineProjection -> {out_sr.name}\")\n",
    "        gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, out_sr)\n",
    "        gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "        _safe_delete(tmp_copy)\n",
    "        return out_fc\n",
    "\n",
    "    generic_degrees = (\n",
    "        sr2 is not None and getattr(sr2, \"type\", None) == \"Geographic\"\n",
    "        and _looks_like_degrees(ext2)\n",
    "        and getattr(sr2, \"factoryCode\", 0) in (0, None)\n",
    "    )\n",
    "    if generic_degrees:\n",
    "        if assumed_src_if_mislabeled is None:\n",
    "            assumed_src_if_mislabeled = arcpy.SpatialReference(4326)\n",
    "        _log(f\"[{name}] ⚠️ GENERIC geographic degrees. DefineProjection -> EPSG:4326 then Project.\")\n",
    "        gp(f\"DefineProjection {name}\", arcpy.management.DefineProjection, tmp_copy, assumed_src_if_mislabeled)\n",
    "\n",
    "    sr_fixed = arcpy.Describe(tmp_copy).spatialReference\n",
    "    if sr_fixed and (sr_fixed.factoryCode == out_sr.factoryCode) and (sr_fixed.name == out_sr.name):\n",
    "        _log(f\"[{name}] Already in target CRS. Copy only.\")\n",
    "        gp(f\"Copy to output {name}\", arcpy.management.CopyFeatures, tmp_copy, out_fc)\n",
    "        _safe_delete(tmp_copy)\n",
    "        return out_fc\n",
    "\n",
    "    transform = _pick_transform(sr_fixed, out_sr)\n",
    "    _log(f\"[{name}] Project -> {out_sr.name} | transform={transform}\")\n",
    "    if transform:\n",
    "        gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr, transform)\n",
    "    else:\n",
    "        gp(f\"Project {name}\", arcpy.management.Project, tmp_copy, out_fc, out_sr)\n",
    "\n",
    "    _safe_delete(tmp_copy)\n",
    "    return out_fc\n",
    "\n",
    "def polygon_to_mask_raster(poly_fc, out_ras, value=1):\n",
    "    _safe_delete(out_ras)\n",
    "    fld = \"MASKVAL\"\n",
    "    if fld not in [f.name for f in arcpy.ListFields(poly_fc)]:\n",
    "        arcpy.management.AddField(poly_fc, fld, \"SHORT\")\n",
    "        arcpy.management.CalculateField(poly_fc, fld, value, \"PYTHON3\")\n",
    "    gp(f\"PolygonToRaster {os.path.basename(out_ras)}\", arcpy.conversion.PolygonToRaster,\n",
    "       poly_fc, fld, out_ras, \"CELL_CENTER\", \"\", cellsize)\n",
    "    return out_ras\n",
    "\n",
    "# ============================================================\n",
    "# Option A pourpoints: boundary vertices TOP-N by flowacc (or boundary fallback)\n",
    "# (Fixed: never Sort by OID field type; uses SQL ORDER BY or OID_LONG)\n",
    "# ============================================================\n",
    "def pourpoints_boundary_topN_flowacc_or_boundary(wet_poly_fc, out_points_fc, id_field, flowacc_raster, scratch_gdb, top_n=5):\n",
    "    tmp_line   = os.path.join(scratch_gdb, \"tmp_wet_boundary_line\")\n",
    "    tmp_vtx    = os.path.join(scratch_gdb, \"tmp_wet_boundary_vtx\")\n",
    "    tmp_join   = os.path.join(scratch_gdb, \"tmp_vtx_join_cwid\")\n",
    "    tmp_vals   = os.path.join(scratch_gdb, \"tmp_vtx_flowacc\")\n",
    "    tmp_keep   = os.path.join(scratch_gdb, \"tmp_vtx_keep\")\n",
    "    tmp_sorted = os.path.join(scratch_gdb, \"tmp_vtx_sorted\")\n",
    "\n",
    "    for p in [tmp_line, tmp_vtx, tmp_join, tmp_vals, tmp_keep, tmp_sorted, out_points_fc]:\n",
    "        _safe_delete(p)\n",
    "\n",
    "    gp(\"PolygonToLine (wet boundary)\", arcpy.management.PolygonToLine, wet_poly_fc, tmp_line)\n",
    "    gp(\"FeatureVerticesToPoints (ALL)\", arcpy.management.FeatureVerticesToPoints, tmp_line, tmp_vtx, \"ALL\")\n",
    "\n",
    "    gp(\"SpatialJoin vertices -> wetlands (attach CW_Id)\", arcpy.analysis.SpatialJoin,\n",
    "       tmp_vtx, wet_poly_fc, tmp_join,\n",
    "       \"JOIN_ONE_TO_ONE\", \"KEEP_COMMON\", None, \"INTERSECT\")\n",
    "\n",
    "    id_on_pts = get_field_name_ci(tmp_join, id_field) or _find_field(tmp_join, [id_field, \"CWID\", \"CW_ID\", \"CW_Id\"])\n",
    "    if not id_on_pts:\n",
    "        raise RuntimeError(f\"After SpatialJoin, could not find '{id_field}' on boundary points.\")\n",
    "\n",
    "    gp(\"ExtractValuesToPoints (flowacc)\", sa.ExtractValuesToPoints,\n",
    "       tmp_join, flowacc_raster, tmp_vals, \"NONE\", \"VALUE_ONLY\")\n",
    "\n",
    "    flds = [f.name for f in arcpy.ListFields(tmp_vals)]\n",
    "    val_field = None\n",
    "    for cand in [\"RASTERVALU\", \"RASTERVALU1\", \"VALUE\", \"GridCode\", \"GRIDCODE\"]:\n",
    "        if cand in flds:\n",
    "            val_field = cand\n",
    "            break\n",
    "    if val_field is None:\n",
    "        float_fields = [f.name for f in arcpy.ListFields(tmp_vals) if f.type in (\"Double\",\"Single\")]\n",
    "        val_field = float_fields[0] if float_fields else None\n",
    "\n",
    "    if val_field:\n",
    "        lyr = \"lyr_flowacc\"\n",
    "        arcpy.management.MakeFeatureLayer(tmp_vals, lyr)\n",
    "        where_valid = f\"{arcpy.AddFieldDelimiters(lyr, val_field)} IS NOT NULL\"\n",
    "        gp(\"Select non-null flowacc\", arcpy.management.SelectLayerByAttribute, lyr, \"NEW_SELECTION\", where_valid)\n",
    "        gp(\"Copy non-null flowacc pts\", arcpy.management.CopyFeatures, lyr, tmp_keep)\n",
    "        arcpy.management.Delete(lyr)\n",
    "\n",
    "    # Fallback: all flowacc NULL -> boundary vertices (no ranking)\n",
    "    if (not val_field) or int(arcpy.management.GetCount(tmp_keep)[0]) == 0:\n",
    "        _log(\"⚠️ boundary flowacc sampling returned ALL NULL; using boundary vertices (no flowacc ranking) as pourpoints.\")\n",
    "        oid = arcpy.Describe(tmp_join).OIDFieldName\n",
    "\n",
    "        gp(\"Create output pourpoints FC\", arcpy.management.CreateFeatureclass,\n",
    "           os.path.dirname(out_points_fc), os.path.basename(out_points_fc),\n",
    "           \"POINT\", tmp_join, \"DISABLED\", \"DISABLED\", D8_SR)\n",
    "\n",
    "        out_id = _ensure_field(out_points_fc, id_field, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "        _ensure_field(out_points_fc, \"FA\", \"DOUBLE\", fallbacks=(\"FLOWACC\",\"FLOW_ACC\"))\n",
    "\n",
    "        used_sql = False\n",
    "        try:\n",
    "            sql = (None, f\"ORDER BY {id_on_pts}, {oid}\")\n",
    "            with arcpy.da.SearchCursor(tmp_join, [id_on_pts, \"SHAPE@\"], sql_clause=sql) as cur, \\\n",
    "                 arcpy.da.InsertCursor(out_points_fc, [out_id, \"SHAPE@\"]) as ic:\n",
    "                counts = {}\n",
    "                for cw, geom in cur:\n",
    "                    if cw is None:\n",
    "                        continue\n",
    "                    cw = int(cw)\n",
    "                    counts.setdefault(cw, 0)\n",
    "                    if counts[cw] < int(top_n):\n",
    "                        ic.insertRow((cw, geom))\n",
    "                        counts[cw] += 1\n",
    "            used_sql = True\n",
    "        except Exception as e:\n",
    "            _log(f\"⚠️ SQL ORDER BY failed ({e}). Falling back to Sort using a LONG copy of OID.\")\n",
    "\n",
    "        if not used_sql:\n",
    "            oid_long = _ensure_field(tmp_join, \"OID_LONG\", \"LONG\", fallbacks=(\"OIDL\",))\n",
    "            gp(\"Calc OID_LONG\", arcpy.management.CalculateField, tmp_join, oid_long, f\"!{oid}!\", \"PYTHON3\")\n",
    "            _safe_delete(tmp_sorted)\n",
    "            gp(\"Sort boundary vertices (CW_Id asc, OID_LONG asc)\", arcpy.management.Sort,\n",
    "               tmp_join, tmp_sorted, [[id_on_pts, \"ASCENDING\"], [oid_long, \"ASCENDING\"]])\n",
    "\n",
    "            with arcpy.da.SearchCursor(tmp_sorted, [id_on_pts, \"SHAPE@\"]) as cur, \\\n",
    "                 arcpy.da.InsertCursor(out_points_fc, [out_id, \"SHAPE@\"]) as ic:\n",
    "                counts = {}\n",
    "                for cw, geom in cur:\n",
    "                    if cw is None:\n",
    "                        continue\n",
    "                    cw = int(cw)\n",
    "                    counts.setdefault(cw, 0)\n",
    "                    if counts[cw] < int(top_n):\n",
    "                        ic.insertRow((cw, geom))\n",
    "                        counts[cw] += 1\n",
    "\n",
    "    else:\n",
    "        gp(\"Sort (CW_Id asc, flowacc desc)\", arcpy.management.Sort, tmp_keep, tmp_sorted,\n",
    "           [[id_on_pts, \"ASCENDING\"], [val_field, \"DESCENDING\"]])\n",
    "\n",
    "        gp(\"Create output pourpoints FC\", arcpy.management.CreateFeatureclass,\n",
    "           os.path.dirname(out_points_fc), os.path.basename(out_points_fc),\n",
    "           \"POINT\", tmp_sorted, \"DISABLED\", \"DISABLED\", D8_SR)\n",
    "\n",
    "        out_id = _ensure_field(out_points_fc, id_field, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "        out_fa = _ensure_field(out_points_fc, \"FA\", \"DOUBLE\", fallbacks=(\"FLOWACC\",\"FLOW_ACC\"))\n",
    "\n",
    "        with arcpy.da.SearchCursor(tmp_sorted, [id_on_pts, val_field, \"SHAPE@\"]) as cur, \\\n",
    "             arcpy.da.InsertCursor(out_points_fc, [out_id, out_fa, \"SHAPE@\"]) as ic:\n",
    "            counts = {}\n",
    "            for cw, fa, geom in cur:\n",
    "                if cw is None:\n",
    "                    continue\n",
    "                cw = int(cw)\n",
    "                counts.setdefault(cw, 0)\n",
    "                if counts[cw] < int(top_n):\n",
    "                    ic.insertRow((cw, float(fa) if fa is not None else None, geom))\n",
    "                    counts[cw] += 1\n",
    "\n",
    "    for p in [tmp_line, tmp_vtx, tmp_join, tmp_vals, tmp_keep, tmp_sorted]:\n",
    "        _safe_delete(p)\n",
    "\n",
    "    return out_points_fc\n",
    "\n",
    "# ============================================================\n",
    "# 0) Build projected masks ONCE\n",
    "# ============================================================\n",
    "inStreamsWS_tgt = os.path.join(ws_gdb, \"inStreamsWS_tgt\")\n",
    "fix_define_and_project_to_gdb(inStreamsWatershed, inStreamsWS_tgt, D8_SR, name=\"inStreamsWS\")\n",
    "gp(\"RepairGeometry stream mask\", arcpy.management.RepairGeometry, inStreamsWS_tgt)\n",
    "\n",
    "inStreams_single = os.path.join(ws_gdb, \"inStreamsWS_single\")\n",
    "_safe_delete(inStreams_single)\n",
    "gp(\"MultipartToSinglepart stream mask\", arcpy.management.MultipartToSinglepart, inStreamsWS_tgt, inStreams_single)\n",
    "\n",
    "inStreamsWS_tgt_diss = os.path.join(ws_gdb, \"inStreamsWS_tgt_diss\")\n",
    "_safe_delete(inStreamsWS_tgt_diss)\n",
    "gp(\"Dissolve stream mask\", arcpy.management.Dissolve, inStreams_single, inStreamsWS_tgt_diss)\n",
    "\n",
    "inStreamsWS_buf = os.path.join(ws_gdb, f\"inStreamsWS_buf{stream_buf_m}m\")\n",
    "_safe_delete(inStreamsWS_buf)\n",
    "gp(\"Buffer stream mask\", arcpy.analysis.Buffer, inStreamsWS_tgt_diss, inStreamsWS_buf,\n",
    "   f\"{stream_buf_m} Meters\", \"FULL\", \"ROUND\", \"ALL\")\n",
    "\n",
    "Lake_tgt = os.path.join(ws_gdb, \"LakeHuron_tgt\")\n",
    "fix_define_and_project_to_gdb(Lake_Huron, Lake_tgt, D8_SR, assumed_src_if_mislabeled=arcpy.SpatialReference(4326), name=\"LakeHuron\")\n",
    "gp(\"RepairGeometry lake\", arcpy.management.RepairGeometry, Lake_tgt)\n",
    "\n",
    "lake_mask_ras = os.path.join(ws_gdb, \"LakeHuron_mask_ras\")\n",
    "polygon_to_mask_raster(Lake_tgt, lake_mask_ras, value=1)\n",
    "\n",
    "flowacc_land = os.path.join(ws_gdb, \"flowacc_land\")\n",
    "_safe_delete(flowacc_land)\n",
    "_log(\"▶ Build flowacc_land = flowacc where NOT lake\")\n",
    "sa.SetNull(sa.Raster(lake_mask_ras), sa.Raster(flowacc)).save(flowacc_land)\n",
    "_log(f\"✅ flowacc_land: {flowacc_land}\")\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "for cat, (wet_fc, out_ws_drain, out_ws_lake) in cats.items():\n",
    "    _log(f\"\\n==================== {cat.upper()} ====================\")\n",
    "\n",
    "    # 1) Project wetlands to D8 CRS\n",
    "    wet_tgt = os.path.join(ws_gdb, f\"{cat}_wet_tgt\")\n",
    "    _safe_delete(wet_tgt)\n",
    "    gp(f\"[{cat}] Project wetlands\", arcpy.management.Project, wet_fc, wet_tgt, D8_SR)\n",
    "\n",
    "    wet_id_f = _ensure_field(wet_tgt, CW_ID_FIELD, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] RepairGeometry wetlands\", arcpy.management.RepairGeometry, wet_tgt)\n",
    "\n",
    "    orig_ids = _idset(wet_tgt, wet_id_f)\n",
    "    _log(f\"[{cat}] unique CW_Ids in ORIGINAL wetlands: {len(orig_ids)}\")\n",
    "\n",
    "    # 2) Wetlands: remove ONLY overlapped part with stream mask (partial erase)\n",
    "    wet_no_stream = os.path.join(ws_gdb, f\"{cat}_wet_no_stream\")\n",
    "    _safe_delete(wet_no_stream)\n",
    "    gp(f\"[{cat}] Erase stream-mask from wetlands (PARTIAL)\", arcpy.analysis.Erase, wet_tgt, inStreamsWS_buf, wet_no_stream)\n",
    "\n",
    "    # 3) Land-only wetlands for outlets (also remove lake)\n",
    "    wet_land = os.path.join(ws_gdb, f\"{cat}_wet_land\")\n",
    "    _safe_delete(wet_land)\n",
    "    gp(f\"[{cat}] Erase lake from wetlands (land-only)\", arcpy.analysis.Erase, wet_no_stream, Lake_tgt, wet_land)\n",
    "\n",
    "    # 4) Primary pourpoints from wet_land boundary (Option A)\n",
    "    pp_inside = os.path.join(pp_gdb, f\"{cat}_pp_boundary_top{TOP_N_PER_CWID}\")\n",
    "    _safe_delete(pp_inside)\n",
    "    gp(f\"[{cat}] Build pourpoints (boundary from wet_land)\", pourpoints_boundary_topN_flowacc_or_boundary,\n",
    "       wet_land, pp_inside, wet_id_f, flowacc_land, ws_gdb, TOP_N_PER_CWID)\n",
    "\n",
    "    # 4b) Fallback boundary pourpoints for CW_Ids that disappeared after wet_land erases\n",
    "    pp_ids = _idset(pp_inside, wet_id_f)\n",
    "    missing_for_pp = sorted(list(orig_ids - pp_ids))\n",
    "    _log(f\"[{cat}] CW_Ids missing pourpoints from wet_land: {len(missing_for_pp)}\")\n",
    "\n",
    "    if missing_for_pp:\n",
    "        wet_orig_diss = os.path.join(ws_gdb, f\"{cat}_wet_orig_diss\")\n",
    "        _safe_delete(wet_orig_diss)\n",
    "        gp(f\"[{cat}] Dissolve ORIGINAL wetlands by CW_Id (fallback pourpoints)\", arcpy.management.Dissolve, wet_tgt, wet_orig_diss, wet_id_f)\n",
    "\n",
    "        wet_missing_poly = os.path.join(ws_gdb, f\"{cat}_wet_missing_poly\")\n",
    "        _safe_delete(wet_missing_poly)\n",
    "\n",
    "        lyr = f\"lyr_{cat}_miss_poly\"\n",
    "        arcpy.management.MakeFeatureLayer(wet_orig_diss, lyr)\n",
    "        arcpy.management.SelectLayerByAttribute(lyr, \"CLEAR_SELECTION\")\n",
    "        chunk = 900\n",
    "        for i in range(0, len(missing_for_pp), chunk):\n",
    "            sub = missing_for_pp[i:i+chunk]\n",
    "            where = f\"{arcpy.AddFieldDelimiters(lyr, wet_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "            arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "        gp(f\"[{cat}] Copy missing CW_Id polygons (fallback)\", arcpy.management.CopyFeatures, lyr, wet_missing_poly)\n",
    "        arcpy.management.Delete(lyr)\n",
    "\n",
    "        pp_fallback = os.path.join(pp_gdb, f\"{cat}_pp_fallback_boundary\")\n",
    "        _safe_delete(pp_fallback)\n",
    "        gp(f\"[{cat}] Build fallback boundary pourpoints (missing IDs)\", pourpoints_boundary_topN_flowacc_or_boundary,\n",
    "           wet_missing_poly, pp_fallback, wet_id_f, flowacc_land, ws_gdb, TOP_N_PER_CWID)\n",
    "\n",
    "        gp(f\"[{cat}] Append fallback -> main pourpoints\", arcpy.management.Append, pp_fallback, pp_inside, \"NO_TEST\")\n",
    "\n",
    "        for p in [wet_orig_diss, wet_missing_poly, pp_fallback]:\n",
    "            _safe_delete(p)\n",
    "\n",
    "    pp_id_f = _ensure_field(pp_inside, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    _log(f\"[{cat}] pourpoints CW_Ids present (after fallback): {count_unique(pp_inside, pp_id_f)}\")\n",
    "\n",
    "    # 5) Pass1 SnapPourPoint\n",
    "    pp_ras = os.path.join(pp_gdb, f\"{cat}_pp_ras\")\n",
    "    _safe_delete(pp_ras)\n",
    "    gp(f\"[{cat}] PointToRaster pourpoints (CW_Id)\", arcpy.conversion.PointToRaster,\n",
    "       pp_inside, pp_id_f, pp_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "    snapped_pp_ras1 = os.path.join(pp_gdb, f\"{cat}_pp_snapped_ras1\")\n",
    "    _safe_delete(snapped_pp_ras1)\n",
    "    _log(f\"[{cat}] SnapPourPoint pass1 = {snap_dist_1} m\")\n",
    "    sa.SnapPourPoint(sa.Raster(pp_ras), sa.Raster(flowacc_land), snap_dist_1).save(snapped_pp_ras1)\n",
    "\n",
    "    snapped_pts1 = os.path.join(pp_gdb, f\"{cat}_pp_snapped_pts1\")\n",
    "    _safe_delete(snapped_pts1)\n",
    "    gp(f\"[{cat}] RasterToPoint snapped pourpoints (pass1)\", arcpy.conversion.RasterToPoint, snapped_pp_ras1, snapped_pts1, \"VALUE\")\n",
    "\n",
    "    val_field1 = _find_field(snapped_pts1, [\"GRID_CODE\", \"GRIDCODE\", \"VALUE\"])\n",
    "    if not val_field1:\n",
    "        raise RuntimeError(f\"[{cat}] Could not find VALUE/GRIDCODE in snapped points pass1.\")\n",
    "\n",
    "    pp_final_id1 = _ensure_field(snapped_pts1, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] Calculate CW_Id on snapped points (pass1)\", arcpy.management.CalculateField,\n",
    "       snapped_pts1, pp_final_id1, f\"!{val_field1}!\", \"PYTHON3\")\n",
    "\n",
    "    snapped_ids1 = _idset(snapped_pts1, pp_final_id1)\n",
    "    missing_after_snap1 = sorted(list(orig_ids - snapped_ids1))\n",
    "    _log(f\"[{cat}] snapped CW_Ids pass1: {len(snapped_ids1)} | missing after pass1: {len(missing_after_snap1)}\")\n",
    "\n",
    "    # 6) Pass2 SnapPourPoint ONLY for missing CW_Ids (bigger distance), append\n",
    "    snapped_pts = os.path.join(pp_gdb, f\"{cat}_pp_snapped_pts\")\n",
    "    _safe_delete(snapped_pts)\n",
    "    gp(f\"[{cat}] Copy snapped pass1 -> combined\", arcpy.management.CopyFeatures, snapped_pts1, snapped_pts)\n",
    "\n",
    "    if missing_after_snap1:\n",
    "        miss_pp = os.path.join(pp_gdb, f\"{cat}_pp_missing_for_snap2\")\n",
    "        _safe_delete(miss_pp)\n",
    "\n",
    "        lyr = f\"lyr_{cat}_ppinside\"\n",
    "        arcpy.management.MakeFeatureLayer(pp_inside, lyr)\n",
    "        arcpy.management.SelectLayerByAttribute(lyr, \"CLEAR_SELECTION\")\n",
    "        chunk = 900\n",
    "        for i in range(0, len(missing_after_snap1), chunk):\n",
    "            sub = missing_after_snap1[i:i+chunk]\n",
    "            where = f\"{arcpy.AddFieldDelimiters(lyr, pp_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "            arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "        gp(f\"[{cat}] Copy missing pourpoints for snap2\", arcpy.management.CopyFeatures, lyr, miss_pp)\n",
    "        arcpy.management.Delete(lyr)\n",
    "\n",
    "        miss_ras = os.path.join(pp_gdb, f\"{cat}_pp_missing_ras\")\n",
    "        _safe_delete(miss_ras)\n",
    "        gp(f\"[{cat}] PointToRaster missing pourpoints\", arcpy.conversion.PointToRaster,\n",
    "           miss_pp, pp_id_f, miss_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "        snapped_pp_ras2 = os.path.join(pp_gdb, f\"{cat}_pp_snapped_ras2\")\n",
    "        _safe_delete(snapped_pp_ras2)\n",
    "        _log(f\"[{cat}] SnapPourPoint pass2 = {snap_dist_2} m (missing CW_Ids only)\")\n",
    "        sa.SnapPourPoint(sa.Raster(miss_ras), sa.Raster(flowacc_land), snap_dist_2).save(snapped_pp_ras2)\n",
    "\n",
    "        snapped_pts2 = os.path.join(pp_gdb, f\"{cat}_pp_snapped_pts2\")\n",
    "        _safe_delete(snapped_pts2)\n",
    "        gp(f\"[{cat}] RasterToPoint snapped pourpoints (pass2)\", arcpy.conversion.RasterToPoint, snapped_pp_ras2, snapped_pts2, \"VALUE\")\n",
    "\n",
    "        val_field2 = _find_field(snapped_pts2, [\"GRID_CODE\", \"GRIDCODE\", \"VALUE\"])\n",
    "        if not val_field2:\n",
    "            raise RuntimeError(f\"[{cat}] Could not find VALUE/GRIDCODE in snapped points pass2.\")\n",
    "\n",
    "        pp_final_id2 = _ensure_field(snapped_pts2, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "        gp(f\"[{cat}] Calculate CW_Id on snapped points (pass2)\", arcpy.management.CalculateField,\n",
    "           snapped_pts2, pp_final_id2, f\"!{val_field2}!\", \"PYTHON3\")\n",
    "\n",
    "        gp(f\"[{cat}] Append snapped pass2 -> combined\", arcpy.management.Append, snapped_pts2, snapped_pts, \"NO_TEST\")\n",
    "\n",
    "        for p in [miss_pp, miss_ras, snapped_pp_ras2, snapped_pts2]:\n",
    "            _safe_delete(p)\n",
    "\n",
    "    snapped_ids = _idset(snapped_pts, wet_id_f)\n",
    "    _log(f\"[{cat}] combined snapped CW_Ids: {len(snapped_ids)} (target {len(orig_ids)})\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # COLLISION REPAIR (critical):\n",
    "    # If multiple CW_Ids snapped to the SAME raster cell, PointToRaster will drop IDs.\n",
    "    # Fix by re-snapping duplicates (only duplicates) and replacing them.\n",
    "    # ------------------------------------------------------------\n",
    "    if COLLISION_REPAIR:\n",
    "        xy = [\"SHAPE@X\", \"SHAPE@Y\"]\n",
    "        idfld = wet_id_f\n",
    "\n",
    "        cell_to_ids = {}\n",
    "        with arcpy.da.SearchCursor(snapped_pts, [idfld] + xy) as cur:\n",
    "            for cw, x, y in cur:\n",
    "                if cw is None:\n",
    "                    continue\n",
    "                key = (round(x, 3), round(y, 3))\n",
    "                cell_to_ids.setdefault(key, []).append(int(cw))\n",
    "\n",
    "        dupe_ids = []\n",
    "        for key, ids in cell_to_ids.items():\n",
    "            if len(ids) > 1:\n",
    "                dupe_ids.extend(ids[1:])  # keep first, fix rest\n",
    "\n",
    "        _log(f\"[{cat}] duplicate snapped-cell CW_Ids: {len(dupe_ids)}\")\n",
    "\n",
    "        if dupe_ids:\n",
    "            dup_src = os.path.join(pp_gdb, f\"{cat}_pp_dupe_src\")\n",
    "            _safe_delete(dup_src)\n",
    "\n",
    "            lyr = f\"lyr_{cat}_pp_dupes\"\n",
    "            arcpy.management.MakeFeatureLayer(pp_inside, lyr)\n",
    "            arcpy.management.SelectLayerByAttribute(lyr, \"CLEAR_SELECTION\")\n",
    "            chunk = 900\n",
    "            for i in range(0, len(dupe_ids), chunk):\n",
    "                sub = dupe_ids[i:i+chunk]\n",
    "                where = f\"{arcpy.AddFieldDelimiters(lyr, pp_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "                arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "            gp(f\"[{cat}] Copy duplicate CW_Id pourpoints\", arcpy.management.CopyFeatures, lyr, dup_src)\n",
    "            arcpy.management.Delete(lyr)\n",
    "\n",
    "            dup_ras = os.path.join(pp_gdb, f\"{cat}_pp_dupe_ras\")\n",
    "            _safe_delete(dup_ras)\n",
    "            gp(f\"[{cat}] PointToRaster dupe pourpoints\", arcpy.conversion.PointToRaster,\n",
    "               dup_src, pp_id_f, dup_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "            dup_snap_ras = os.path.join(pp_gdb, f\"{cat}_pp_dupe_snapped_ras\")\n",
    "            _safe_delete(dup_snap_ras)\n",
    "            dup_dist = max(COLLISION_RESNAP_DIST, snap_dist_1)\n",
    "            _log(f\"[{cat}] Re-snap duplicates with distance = {dup_dist} m\")\n",
    "            sa.SnapPourPoint(sa.Raster(dup_ras), sa.Raster(flowacc_land), dup_dist).save(dup_snap_ras)\n",
    "\n",
    "            dup_snap_pts = os.path.join(pp_gdb, f\"{cat}_pp_dupe_snapped_pts\")\n",
    "            _safe_delete(dup_snap_pts)\n",
    "            gp(f\"[{cat}] RasterToPoint dupe snapped\", arcpy.conversion.RasterToPoint, dup_snap_ras, dup_snap_pts, \"VALUE\")\n",
    "\n",
    "            vfld = _find_field(dup_snap_pts, [\"GRID_CODE\",\"GRIDCODE\",\"VALUE\"])\n",
    "            dup_id = _ensure_field(dup_snap_pts, wet_id_f, \"LONG\")\n",
    "            gp(f\"[{cat}] Calc CW_Id dupe snapped\", arcpy.management.CalculateField, dup_snap_pts, dup_id, f\"!{vfld}!\", \"PYTHON3\")\n",
    "\n",
    "            snapped_clean = os.path.join(pp_gdb, f\"{cat}_snapped_clean\")\n",
    "            _safe_delete(snapped_clean)\n",
    "\n",
    "            lyr2 = f\"lyr_{cat}_snapped\"\n",
    "            arcpy.management.MakeFeatureLayer(snapped_pts, lyr2)\n",
    "            arcpy.management.SelectLayerByAttribute(lyr2, \"CLEAR_SELECTION\")  # start with all\n",
    "            # remove duplicates from selection => select all EXCEPT dupes\n",
    "            # easiest: select dupes then switch selection\n",
    "            chunk = 900\n",
    "            for i in range(0, len(dupe_ids), chunk):\n",
    "                sub = dupe_ids[i:i+chunk]\n",
    "                where = f\"{arcpy.AddFieldDelimiters(lyr2, wet_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "                arcpy.management.SelectLayerByAttribute(lyr2, \"ADD_TO_SELECTION\", where)\n",
    "            arcpy.management.SelectLayerByAttribute(lyr2, \"SWITCH_SELECTION\")\n",
    "            gp(f\"[{cat}] Copy snapped (without dupes)\", arcpy.management.CopyFeatures, lyr2, snapped_clean)\n",
    "            arcpy.management.Delete(lyr2)\n",
    "\n",
    "            gp(f\"[{cat}] Append re-snapped dupes\", arcpy.management.Append, dup_snap_pts, snapped_clean, \"NO_TEST\")\n",
    "\n",
    "            _safe_delete(snapped_pts)\n",
    "            gp(f\"[{cat}] Replace snapped_pts with de-collided version\", arcpy.management.CopyFeatures, snapped_clean, snapped_pts)\n",
    "\n",
    "            for p in [dup_src, dup_ras, dup_snap_ras, dup_snap_pts, snapped_clean]:\n",
    "                _safe_delete(p)\n",
    "\n",
    "        snapped_ids = _idset(snapped_pts, wet_id_f)\n",
    "        _log(f\"[{cat}] snapped CW_Ids AFTER collision repair: {len(snapped_ids)} (target {len(orig_ids)})\")\n",
    "\n",
    "    # 7) Snapped points -> raster for Watershed (after collision repair)\n",
    "    pp_snap_ras = os.path.join(pp_gdb, f\"{cat}_pp_snap_ras\")\n",
    "    _safe_delete(pp_snap_ras)\n",
    "    gp(f\"[{cat}] PointToRaster snapped points (CW_Id)\", arcpy.conversion.PointToRaster,\n",
    "       snapped_pts, wet_id_f, pp_snap_ras, \"MAXIMUM\", \"\", cellsize)\n",
    "\n",
    "    # 8) Watershed raster\n",
    "    ws_ras = os.path.join(ws_gdb, f\"{cat}_ws_ras\")\n",
    "    _safe_delete(ws_ras)\n",
    "    _log(f\"▶ [{cat}] Watershed\")\n",
    "    t0 = time.time()\n",
    "    sa.Watershed(D8_flow, pp_snap_ras).save(ws_ras)\n",
    "    _log(f\"✅ DONE [{cat}] Watershed ({(time.time()-t0)/60:.2f} min)\")\n",
    "\n",
    "    # 9) RasterToPolygon + dissolve by CW_Id\n",
    "    ws_poly_raw = os.path.join(ws_gdb, f\"{cat}_ws_poly_raw\")\n",
    "    _safe_delete(ws_poly_raw)\n",
    "    gp(f\"[{cat}] RasterToPolygon\", arcpy.conversion.RasterToPolygon, ws_ras, ws_poly_raw, \"NO_SIMPLIFY\", \"VALUE\")\n",
    "\n",
    "    grid_field = _find_field(ws_poly_raw, [\"GRIDCODE\", \"GRID_CODE\"])\n",
    "    if not grid_field:\n",
    "        raise RuntimeError(f\"[{cat}] GRIDCODE missing in watershed polygons.\")\n",
    "\n",
    "    ws_id_f = _ensure_field(ws_poly_raw, wet_id_f, \"LONG\", fallbacks=(\"CWID\",\"CW_ID\",\"CW_Id\"))\n",
    "    gp(f\"[{cat}] Calculate CW_Id on watershed polygons\", arcpy.management.CalculateField,\n",
    "       ws_poly_raw, ws_id_f, f\"!{grid_field}!\", \"PYTHON3\")\n",
    "\n",
    "    ws_poly = os.path.join(ws_gdb, f\"{cat}_ws_poly\")\n",
    "    _safe_delete(ws_poly)\n",
    "    gp(f\"[{cat}] Dissolve watersheds by CW_Id\", arcpy.management.Dissolve, ws_poly_raw, ws_poly, ws_id_f)\n",
    "\n",
    "    ws_before_ids = _idset(ws_poly, ws_id_f)\n",
    "    _log(f\"[{cat}] watersheds BEFORE clip: {len(ws_before_ids)} CW_Ids (target {len(orig_ids)})\")\n",
    "\n",
    "    # 10) Clip out ONLY overlap parts (lake + stream mask)\n",
    "    tmp_no_lake = os.path.join(ws_gdb, f\"{cat}_ws_no_lake\")\n",
    "    tmp_no_stream = os.path.join(ws_gdb, f\"{cat}_ws_no_stream\")\n",
    "    _safe_delete(tmp_no_lake); _safe_delete(tmp_no_stream)\n",
    "\n",
    "    gp(f\"[{cat}] Erase lake from watersheds (partial)\", arcpy.analysis.Erase, ws_poly, Lake_tgt, tmp_no_lake)\n",
    "    gp(f\"[{cat}] Erase stream mask from watersheds (partial)\", arcpy.analysis.Erase, tmp_no_lake, inStreamsWS_buf, tmp_no_stream)\n",
    "\n",
    "    _safe_delete(out_ws_lake)\n",
    "    gp(f\"[{cat}] Dissolve final output (after clips)\", arcpy.management.Dissolve, tmp_no_stream, out_ws_lake, ws_id_f)\n",
    "\n",
    "    final_ids = _idset(out_ws_lake, ws_id_f)\n",
    "    missing_after_clip = sorted(list(orig_ids - final_ids))\n",
    "    _log(f\"[{cat}] final watersheds AFTER clip: {len(final_ids)} CW_Ids (target {len(orig_ids)})\")\n",
    "    _log(f\"[{cat}] missing CW_Ids after clip: {len(missing_after_clip)}\")\n",
    "\n",
    "    # 10b) OPTIONAL: fallback if clip erased entire polygon (keeps CW_Id coverage)\n",
    "    if CLIP_FALLBACK and missing_after_clip:\n",
    "        ws_missing = os.path.join(ws_gdb, f\"{cat}_ws_missing_unclipped\")\n",
    "        _safe_delete(ws_missing)\n",
    "\n",
    "        lyr = f\"lyr_{cat}_ws_poly\"\n",
    "        arcpy.management.MakeFeatureLayer(ws_poly, lyr)\n",
    "        arcpy.management.SelectLayerByAttribute(lyr, \"CLEAR_SELECTION\")\n",
    "        chunk = 900\n",
    "        for i in range(0, len(missing_after_clip), chunk):\n",
    "            sub = missing_after_clip[i:i+chunk]\n",
    "            where = f\"{arcpy.AddFieldDelimiters(lyr, ws_id_f)} IN ({','.join(map(str, sub))})\"\n",
    "            arcpy.management.SelectLayerByAttribute(lyr, \"ADD_TO_SELECTION\", where)\n",
    "        gp(f\"[{cat}] Copy missing CW_Ids from UNCLIPPED watersheds (fallback)\", arcpy.management.CopyFeatures, lyr, ws_missing)\n",
    "        arcpy.management.Delete(lyr)\n",
    "\n",
    "        gp(f\"[{cat}] Append unclipped fallback -> final\", arcpy.management.Append, ws_missing, out_ws_lake, \"NO_TEST\")\n",
    "\n",
    "        out_ws_lake_diss = os.path.join(ws_gdb, f\"{cat}_final_diss_after_fallback\")\n",
    "        _safe_delete(out_ws_lake_diss)\n",
    "        if hasattr(arcpy.analysis, \"PairwiseDissolve\"):\n",
    "            gp(f\"[{cat}] PairwiseDissolve (enforce 1 per CW_Id)\", arcpy.analysis.PairwiseDissolve, out_ws_lake, out_ws_lake_diss, ws_id_f)\n",
    "        else:\n",
    "            gp(f\"[{cat}] Dissolve (enforce 1 per CW_Id)\", arcpy.management.Dissolve, out_ws_lake, out_ws_lake_diss, ws_id_f)\n",
    "\n",
    "        _safe_delete(out_ws_lake)\n",
    "        gp(f\"[{cat}] Copy final (with fallback)\", arcpy.management.CopyFeatures, out_ws_lake_diss, out_ws_lake)\n",
    "\n",
    "        final_ids = _idset(out_ws_lake, ws_id_f)\n",
    "        _log(f\"[{cat}] final CW_Ids AFTER clip-fallback: {len(final_ids)} (target {len(orig_ids)})\")\n",
    "\n",
    "        _safe_delete(ws_missing)\n",
    "        _safe_delete(out_ws_lake_diss)\n",
    "\n",
    "    # 11) Add attributes\n",
    "    calculate_area_m2(out_ws_lake, \"WS_AREAM2\")\n",
    "    add_xy_ll(out_ws_lake, prefix=\"WS\")\n",
    "\n",
    "    _log(f\"✅ final watershed: {cat} -> {os.path.basename(out_ws_lake)}\")\n",
    "    _clear_locks()\n",
    "\n",
    "_log(\"\\n🎉 DONE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samin-arcpy1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
