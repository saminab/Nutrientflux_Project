{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f9005e",
   "metadata": {},
   "source": [
    "# Running 2_PT_Senseflux_intersectionpoint for the whole year each two month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0df295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "FVCOM_DIR = '/mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/2024/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db768bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted([f for f in os.listdir(FVCOM_DIR) if f.endswith(\".nc\")])\n",
    "\n",
    "print(\"Earliest file:\", all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ba7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cftime\n",
    "from netCDF4 import num2date\n",
    "filename = 'lmhofs.t00z.20241101.fields.n006.nc'\n",
    "\n",
    "ds = xr.open_dataset(FVCOM_DIR + filename, decode_times=False)\n",
    "time_var = ds.variables['time']\n",
    "\n",
    "# Extract the values and metadata properly\n",
    "time_vals = time_var[:]\n",
    "units = time_var.attrs.get('units', None)\n",
    "calendar = time_var.attrs.get('calendar', 'standard')\n",
    "\n",
    "if units is None:\n",
    "    raise ValueError(\"The 'units' attribute is missing from the time variable.\")\n",
    "\n",
    "# Convert to datetime\n",
    "converted_time = num2date(time_vals, units=units, calendar=calendar)\n",
    "\n",
    "print(\"Start time:\", converted_time[0])\n",
    "print(\"End time:\", converted_time[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d797c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in sorted(os.listdir(FVCOM_DIR)):\n",
    "    if fname.endswith('.nc'):\n",
    "        ds = xr.open_dataset(os.path.join(FVCOM_DIR, fname), decode_times=False)\n",
    "        print(f\"{fname}: {ds['time'].values[0]} to {ds['time'].values[-1]}\")\n",
    "        ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc77441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "\n",
    "# Directory containing your (renamed) FVCOM files\n",
    "BASE_DIR = \"/mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/rename\"\n",
    "\n",
    "# File glob patterns to include. Adjust if needed.\n",
    "# If you've renamed nos.* files to lmhofs.*, one pattern is enough.\n",
    "PATTERNS = (\"lmhofs.\")  # we match startswith\n",
    "\n",
    "# Where to move problem files\n",
    "MISSING_SUBDIR = os.path.join(BASE_DIR, \"missing_Itime\")\n",
    "\n",
    "# Safety: do a dry run first. Set to False to actually move.\n",
    "DRY_RUN = True\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def has_Itime(path):\n",
    "    \"\"\"Return True if NetCDF file contains variable 'Itime'.\"\"\"\n",
    "    try:\n",
    "        with Dataset(path, \"r\") as ds:\n",
    "            return \"Itime\" in ds.variables\n",
    "    except Exception as e:\n",
    "        print(f\"!! ERROR reading {os.path.basename(path)}: {e}\")\n",
    "        return False  # treat unreadable as missing\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs(MISSING_SUBDIR, exist_ok=True)\n",
    "\n",
    "    files = sorted(\n",
    "        f for f in os.listdir(BASE_DIR)\n",
    "        if f.endswith(\".nc\") and f.startswith(PATTERNS)\n",
    "    )\n",
    "\n",
    "    if not files:\n",
    "        print(\"No matching NetCDF files found. Check BASE_DIR/PATTERNS.\")\n",
    "        return\n",
    "\n",
    "    keep = []\n",
    "    move = []\n",
    "\n",
    "    for fname in files:\n",
    "        fpath = os.path.join(BASE_DIR, fname)\n",
    "        if has_Itime(fpath):\n",
    "            keep.append(fname)\n",
    "        else:\n",
    "            move.append(fname)\n",
    "\n",
    "    print(\"\\nScan complete.\")\n",
    "    print(f\"  Files with Itime: {len(keep)}\")\n",
    "    print(f\"  Files MISSING Itime: {len(move)}\")\n",
    "\n",
    "    if not move:\n",
    "        print(\"Nothing to move. You're good!\")\n",
    "        return\n",
    "\n",
    "    # Show list of problem files\n",
    "    print(\"\\nProblem files (missing Itime):\")\n",
    "    for fname in move:\n",
    "        print(\"  \", fname)\n",
    "\n",
    "    if DRY_RUN:\n",
    "        print(\"\\nDRY RUN: No files moved. Set DRY_RUN = False to move them.\")\n",
    "        return\n",
    "\n",
    "    # Move them\n",
    "    for fname in move:\n",
    "        src = os.path.join(BASE_DIR, fname)\n",
    "        dst = os.path.join(MISSING_SUBDIR, fname)\n",
    "        print(f\"Moving {fname} -> missing_Itime/\")\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    print(\"\\nDone. Re-scan to confirm.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def get_earliest_valid_datetime(data_dir):\n",
    "    file_list = sorted(glob.glob(os.path.join(data_dir, \"*.nc\")))\n",
    "\n",
    "    all_times = []\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            print(f\"Checking: {f}\")\n",
    "            ds = Dataset(f)\n",
    "            if 'time' not in ds.variables:\n",
    "                ds.close()\n",
    "                continue\n",
    "\n",
    "            time_var = ds.variables['time']\n",
    "            if len(time_var[:]) == 0:\n",
    "                ds.close()\n",
    "                continue\n",
    "\n",
    "            units = time_var.units\n",
    "            calendar = getattr(time_var, 'calendar', 'standard')\n",
    "            times = num2date(time_var[:], units=units, calendar=calendar)\n",
    "\n",
    "            if isinstance(times, list) or hasattr(times, '__getitem__'):\n",
    "                all_times.append(times[0])\n",
    "            else:\n",
    "                all_times.append(times)\n",
    "\n",
    "            ds.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_times:\n",
    "        raise ValueError(\"No valid times found in any NetCDF file!\")\n",
    "\n",
    "    earliest = min(all_times)\n",
    "    print(f\"Earliest detected FVCOM time: {earliest}\")\n",
    "    return earliest.replace(microsecond=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3e104e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (file_reader.py, line 311)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniforge3/envs/pylag/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[2], line 14\u001b[0m\n    from pylag.regrid import regridder\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32mpylag/regrid/regridder.pyx:33\u001b[0m in \u001b[1;35minit pylag.regrid.regridder\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniforge3/envs/pylag/lib/python3.11/site-packages/pylag/mediator.py:14\u001b[0;36m\n\u001b[0;31m    from pylag.file_reader import FileReader\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniforge3/envs/pylag/lib/python3.11/site-packages/pylag/file_reader.py:311\u001b[0;36m\u001b[0m\n\u001b[0;31m    if not self._check_date_time_is_valid(start_datetime):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "import datetime\n",
    "import configparser\n",
    "import subprocess\n",
    "# FVCOM-specific visualization and utility tools\n",
    "from pylag.processing.plot import FVCOMPlotter, create_figure, colourmap\n",
    "from pylag.processing.utils import get_grid_bands\n",
    "from pylag.grid_metrics import create_fvcom_grid_metrics_file\n",
    "\n",
    "# Regridding, viewing, and garbage collection utilities\n",
    "from pylag.regrid import regridder\n",
    "from pylag.processing.ncview import Viewer\n",
    "####\n",
    "def run_pylag(start_datetime, end_datetime, config_file_name, out_dir, MODELLING_DIR, pylag_cfg_path):\n",
    "    start_str = start_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_str = end_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Update config files\n",
    "    update_datetime_in_config(config_file_name, start_str, end_str, out_dir)\n",
    "    print(f\"Updated start_datetime, end_datetime, and output_file in {config_file_name} and pylag.cfg.\")\n",
    "    print(f\"Output file for this run: {start_str[:7]}_run.nc\")\n",
    "\n",
    "    # Change to modelling directory\n",
    "    os.chdir(MODELLING_DIR)\n",
    "\n",
    "    # Run the model\n",
    "    run_command = f\"python -m pylag.main -c {pylag_cfg_path}\"\n",
    "    print(f\"Running model with command: {run_command}\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(run_command, shell=True, check=True, capture_output=True, text=True)\n",
    "        print(\"Model run completed.\")\n",
    "        print(f\"stdout: {result.stdout}\")\n",
    "        print(f\"stderr: {result.stderr}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"⚠️ Skipping run from {start_str} to {end_str} due to error.\")\n",
    "        print(f\"stdout: {e.stdout}\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "        \n",
    "def files_available_for_range(start_datetime, end_datetime, FVCOM_DIR, stem='lmhofs'):\n",
    "    # Generate all expected file patterns based on daily data assumption\n",
    "    current = start_datetime\n",
    "    while current <= end_datetime:\n",
    "        # Match either file format: lmhofs.t06z.YYYYMMDD.fields.nXXX.nc or lmhofs.fields.nXXX.YYYYMMDD.tXXz.nc\n",
    "        date_str1 = current.strftime('%Y%m%d')\n",
    "        pattern1 = f\"{FVCOM_DIR}/{stem}.t*z.{date_str1}.fields.n*.nc\"\n",
    "        pattern2 = f\"{FVCOM_DIR}/{stem}.fields.n*.{date_str1}.t*z.nc\"\n",
    "\n",
    "        files1 = glob.glob(pattern1)\n",
    "        files2 = glob.glob(pattern2)\n",
    "\n",
    "        if not (files1 or files2):\n",
    "            print(f\"⚠️ No files found for date {current.date()}\")\n",
    "            return False\n",
    "\n",
    "        current += datetime.timedelta(days=1)\n",
    "    \n",
    "    return True\n",
    "# Function to generate start and end datetimes for each two-month period\n",
    "def generate_date_ranges(year):\n",
    "    # Adjust to create correct date ranges from August to December\n",
    "    #months = [(2,3),(3,4),(4,5),(5,6),(6,7),(7,8),(8, 9),(9, 10),(10, 11),(11, 12)]\n",
    "    months = [(9,10),(10,11),(11,12)]\n",
    "    \n",
    "    date_ranges = []\n",
    "    for start_month, end_month in months:\n",
    "        start_datetime = datetime.datetime(year, start_month, 1)\n",
    "        \n",
    "        # Special case for September: Set end date to 29th\n",
    "        if start_month == 1:\n",
    "            start_datetime = datetime.datetime(year, start_month, 1, 5, 00, 00)\n",
    "        # if start_month == 8:\n",
    "        #     start_datetime = datetime.datetime(year, start_month, 1, 6, 00, 00)\n",
    "        # if start_month == 11:\n",
    "        #     start_datetime = datetime.datetime(year, start_month, 1, 23, 19, 32)\n",
    "        if end_month == 10:\n",
    "            end_datetime = datetime.datetime(year, end_month, 30, 00, 00, 00)\n",
    "        if end_month == 8:\n",
    "            end_datetime = datetime.datetime(year, end_month, 31, 6, 00, 00)\n",
    "        if end_month == 11:\n",
    "            end_datetime = datetime.datetime(year, end_month, 30, 00, 00, 00)\n",
    "        elif end_month == 12:\n",
    "            end_datetime = datetime.datetime(year, end_month, 31, 16, 00, 00)\n",
    "        else:\n",
    "            end_datetime = datetime.datetime(year, end_month + 1, 1) - datetime.timedelta(seconds=1)\n",
    "        \n",
    "        date_ranges.append((start_datetime, end_datetime))\n",
    "    \n",
    "    return date_ranges\n",
    "\n",
    "# Function to update the datetime and output filename in the config file\n",
    "def update_datetime_in_config(config_file_name, start_str, end_str, out_dir):\n",
    "    start_date = datetime.datetime.strptime(start_str, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = datetime.datetime.strptime(end_str, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    start_year = start_date.year\n",
    "    start_month = start_date.month\n",
    "    end_year = end_date.year\n",
    "    end_month = end_date.month\n",
    "    \n",
    "    month_range = f\"{start_date.strftime('%b')}{end_date.strftime('%b')}\"\n",
    "    output_filename = f\"FVCOM_Huron_{start_year % 100}{end_year % 100}_{month_range}\"\n",
    "\n",
    "    # Read the config file and update the necessary values\n",
    "    with open(config_file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(config_file_name, 'w') as file:\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"start_datetime\"):\n",
    "                file.write(f\"start_datetime = {start_str}\\n\")\n",
    "            elif line.strip().startswith(\"end_datetime\"):\n",
    "                file.write(f\"end_datetime = {end_str}\\n\")\n",
    "            elif line.strip().startswith(\"output_file\"):\n",
    "                # Ensure the output file name is updated correctly\n",
    "                file.write(f\"output_file = %(out_dir)s/{output_filename}\\n\")\n",
    "            else:\n",
    "                file.write(line)\n",
    "\n",
    "    # Now, update the pylag.cfg with the same changes\n",
    "    pylag_cfg_path = os.path.join(out_dir, 'pylag.cfg')\n",
    "    with open(pylag_cfg_path, 'w') as config_file:\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"start_datetime\"):\n",
    "                config_file.write(f\"start_datetime = {start_str}\\n\")\n",
    "            elif line.strip().startswith(\"end_datetime\"):\n",
    "                config_file.write(f\"end_datetime = {end_str}\\n\")\n",
    "            elif line.strip().startswith(\"output_file\"):\n",
    "                config_file.write(f\"output_file = %(out_dir)s/{output_filename}\\n\")\n",
    "            else:\n",
    "                config_file.write(line)\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    # Define directories and file paths\n",
    "    config_file_path = '/home/abolmaal/modelling/FVCOM/Huron/config_files'\n",
    "    config_file_name = os.path.join(config_file_path, 'Huron_Senseflux_Seasonal.cfg')\n",
    "    MODELLING_DIR = '/home/abolmaal/modelling/FVCOM/Huron'\n",
    "    out_dir = os.path.join(MODELLING_DIR, 'output')\n",
    "    FVCOM_DIR = '/mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/2024/'\n",
    "    input_dir = os.path.join(MODELLING_DIR, 'input')\n",
    "    grid_metrics_file_name = f'{input_dir}/gridfile/grid_metrics_huron_senseflux_Seasonal.nc'\n",
    "    pylag_cfg_path = os.path.join(out_dir, 'pylag.cfg')\n",
    "\n",
    "    # Create necessary directories\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize the configuration parser\n",
    "    cf = configparser.ConfigParser()\n",
    "    cf.read(config_file_name)\n",
    "\n",
    "    # Set configuration parameters\n",
    "    cf.set('OCEAN_DATA', 'data_dir', FVCOM_DIR)\n",
    "    cf.set('OCEAN_DATA', 'grid_metrics_file', grid_metrics_file_name)\n",
    "    cf.set('GENERAL', 'out_dir', out_dir)\n",
    "\n",
    "    # Save the updated configuration to pylag.cfg\n",
    "    with open(pylag_cfg_path, 'w') as config_file:\n",
    "        cf.write(config_file)\n",
    "\n",
    "    print(f\"Updated configuration and saved to {pylag_cfg_path}\")\n",
    "\n",
    "    # Generate date ranges for the year\n",
    "    year = 2024\n",
    "    date_ranges = generate_date_ranges(year)\n",
    "\n",
    "    # Loop through each date range and run the model\n",
    "    for start_datetime, end_datetime in date_ranges:\n",
    "        start_str = start_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(f\"Running for: {start_str} to {end_str}\")\n",
    "        \n",
    "        # # Update the datetime in the config file and pylag.cfg file\n",
    "        # update_datetime_in_config(config_file_name, start_str, end_str, out_dir)\n",
    "        # print(f\"Updated start_datetime, end_datetime, and output_file in {config_file_name} and pylag.cfg.\")\n",
    "        \n",
    "        # # Print the output filename to confirm it's unique for each run\n",
    "        # print(f\"Output file for this run: {start_str[:7]}_run.nc\")  # Example: FVCOM_Huron_2323_JanFeb_run.nc\n",
    "        \n",
    "        # # Change to the modeling directory\n",
    "        # os.chdir(MODELLING_DIR)\n",
    "\n",
    "        # # Run the model using the updated pylag.cfg file with a new output path\n",
    "        # run_command = f\"python -m pylag.main -c {pylag_cfg_path}\"\n",
    "        # print(f\"Running model with command: {run_command}\")\n",
    "\n",
    "        # # Execute the model with subprocess and capture output\n",
    "        # try:\n",
    "        #     result = subprocess.run(run_command, shell=True, check=True, capture_output=True, text=True)\n",
    "        #     print(\"Model run completed.\")\n",
    "        #     print(f\"stdout: {result.stdout}\")\n",
    "        #     print(f\"stderr: {result.stderr}\")\n",
    "        # except subprocess.CalledProcessError as e:\n",
    "        #     print(f\"Error occurred while running the model:\")\n",
    "        #     print(f\"stdout: {e.stdout}\")\n",
    "        #     print(f\"stderr: {e.stderr}\")\n",
    "        #     print(f\"Return code: {e.returncode}\")\n",
    "    if files_available_for_range(start_datetime, end_datetime, FVCOM_DIR):\n",
    "        run_pylag(start_datetime, end_datetime, config_file_name, out_dir, MODELLING_DIR, pylag_cfg_path)\n",
    "    else:\n",
    "        print(f\"⏭️ Skipping {start_datetime} to {end_datetime} due to missing input files.\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
