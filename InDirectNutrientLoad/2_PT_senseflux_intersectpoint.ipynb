{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814ab0ed",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664767c",
   "metadata": {},
   "source": [
    "Following Code Uses PyLag, offline Particle Tracking model and FVCOM outputs that are Downloaded from the following for 2023 https://noaa-nos-ofs-pds.s3.amazonaws.com/index.html#lmhofs/netcdf\n",
    "and Computes Lagrangian Particle Tracking for particles that are release at the mouth of Lake Huron's stream watersheds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d9afa",
   "metadata": {},
   "source": [
    "in the local directory they are placed here\n",
    "FVCOME files are in this location \n",
    "#S:\\Data\\External_Models\\Outputs\\GLCFS\\LakeHuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ca450-9df5-4770-92ab-1fb3397e6b87",
   "metadata": {},
   "source": [
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41dad765-f52b-43e8-a78f-0c01abd0aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File system and configuration management\n",
    "import os\n",
    "import glob\n",
    "import configparser\n",
    "import datetime\n",
    "\n",
    "# Data handling and processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# NetCDF data handling\n",
    "from netCDF4 import Dataset\n",
    "from cftime import num2pydate\n",
    "import xarray as xr\n",
    "\n",
    "# Visualization: general plotting, Cartopy, and Matplotlib utilities\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# FVCOM-specific visualization and utility tools\n",
    "from pylag.processing.plot import FVCOMPlotter, create_figure, colourmap\n",
    "from pylag.processing.utils import get_grid_bands\n",
    "from pylag.grid_metrics import create_fvcom_grid_metrics_file\n",
    "\n",
    "# Regridding, viewing, and garbage collection utilities\n",
    "from pylag.regrid import regridder\n",
    "from pylag.processing.ncview import Viewer\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bebed",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "470043bd-12f8-4d0b-8659-8e68d8ac3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FVCOM_DIR='/home/abolmaal/Data/FVCOMEDATA'.format(os.environ['HOME']) \n",
    "# fvcom model directory\n",
    "FVCOM_DIR = '/mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/'.format(os.environ['HOME'])\n",
    "\n",
    "# Create run directory\n",
    "cwd = os.getcwd()\n",
    "# Create run directory\n",
    "MODELLING_DIR = '/home/abolmaal/modelling/FVCOM/Huron'.format(cwd)\n",
    "try:\n",
    "    os.makedirs(MODELLING_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Create input sub-directory for input files\n",
    "input_dir = '{}/input'.format(MODELLING_DIR)\n",
    "try:\n",
    "    os.makedirs(input_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# input file to create grid metrics\n",
    "fvcom_file_name = os.path.join(FVCOM_DIR, 'nos.lmhofs.fields.n000.20230501.t00z.nc')\n",
    "\n",
    "# The file listing the location of open boundary nodes\n",
    "\n",
    "obc_file_name = os.path.join(MODELLING_DIR,'input', 'obc.dat')\n",
    "\n",
    "\n",
    "\n",
    "# initial position of the particles\n",
    "initial_position_file = os.path.join(FVCOM_DIR, 'input', 'initial_positions_releasezone_intersection_multigroup_2_lastrevised.dat')\n",
    "\n",
    "\n",
    "# config file\n",
    "config_file_name = os.path.join(MODELLING_DIR, 'config_files', 'Huron_Senseflux_Seasonal.cfg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf4d8b",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877dcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the output file containing the grid metrics\n",
    "# create a sub directory for the grid file\n",
    "grid_file_dir = f'{input_dir}/gridfile'\n",
    "try:\n",
    "    os.makedirs(grid_file_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "grid_metrics_file_name = f'{input_dir}/gridfile/grid_metrics_huron_senseflux_Seasonal.nc'\n",
    "\n",
    "#grid_metrics_file_name = f'{input_dir}/gridfile/grid_metrics_huron_senseflux_Seasonal_winter.nc'\n",
    "\n",
    "\n",
    "\n",
    "# Create output sub-directory\n",
    "output_dir = '{}/output'.format(MODELLING_DIR)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# Create Figure sub-directory\n",
    "fig_dir = '{}/figures'.format(MODELLING_DIR)\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "\n",
    "# output path saving the figure\n",
    "fig_path_initilapositions = os.path.join(fig_dir, 'initial_positions_LakeHuron_multigrouppoint_intersection.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864565e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Figure parameters\n",
    "# Custom colormap setup (pink and blue shades)\n",
    "pink_shades = ['#fff5f7', '#ffebf0', '#ffd6e1', '#ffbfd4', '#ff99c1', '#ff6ea9', '#ff4c92', '#ff2171', '#b50d4e']\n",
    "blue_shades = ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594']\n",
    "blue_shades_reversed = blue_shades[::-1]\n",
    "\n",
    "pink_cmap = LinearSegmentedColormap.from_list('custom_pink', pink_shades)\n",
    "blue_cmap_reversed = LinearSegmentedColormap.from_list('custom_blue', blue_shades)\n",
    "\n",
    "# Define a list of green shades for the colormap\n",
    "green_shades =  ['#e0ffe0', '#b3ffb3', '#80ff80', '#4dff4d', '#00e600', '#00cc00', '#009900', '#006600', '#003300']\n",
    "# Create a custom green colormap\n",
    "green_cmap = LinearSegmentedColormap.from_list('custom_green', green_shades)\n",
    "\n",
    "# Replace pink_cmap with viridis and plasma\n",
    "viridis_cmap = plt.colormaps['viridis']  # Updated to use new interface\n",
    "plasma_cmap = plt.colormaps['plasma']  # Updated to use new interface\n",
    "\n",
    "# Set up plotting parameters\n",
    "font_size = 15\n",
    "cmap = plt.colormaps['hsv_r']  # Fixed: using an existing colormap (hsv_r)\n",
    "\n",
    "# Extent of the plot\n",
    "extents = np.array([275, 277.69, 43, 46.3], dtype=float)\n",
    "\n",
    "# Some parameters for the Zonal Stats Fields\n",
    "# Fields to calculate / Direct delivery to Watersheds\n",
    "fieldDirectTN = 'WetLoad_TN_kgcellday'\n",
    "fieldDirectTP = 'WetLoad_TP_kgcellday'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c27ca",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d741ff",
   "metadata": {},
   "source": [
    "## Figure Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cada8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure Parameters\n",
    "# Create figure\n",
    "font_size = 15\n",
    "figsize=(26., 26.)\n",
    "cmap = colourmap('h_r')\n",
    "blue_shades = ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594']\n",
    "blue_shades_reversed = blue_shades[::-1]\n",
    "# Create a custom colormap\n",
    "blue_cmap_reversed = LinearSegmentedColormap.from_list('custom_blue_reversed', blue_shades_reversed)\n",
    "\n",
    "\n",
    "# Bathymetry \n",
    "\n",
    "# Read in the bathymetry\n",
    "ds = Dataset(grid_metrics_file_name, 'r')\n",
    "bathy = -ds.variables['h'][:]\n",
    "# make a color scale of light green to blue \n",
    "GnBu = LinearSegmentedColormap.from_list('GnBu', [(0, '#f0f9e8'), (0.5, '#bae4bc'), (1, '#7bccc4')], N=256)\n",
    "bathy_cmap = GnBu\n",
    "\n",
    "ds.close()\n",
    "del(ds)\n",
    "\n",
    "# extends \n",
    "#Lake Huron extents\n",
    "extents_LH = np.array([275, 277.69, 43, 46.3], dtype=float)\n",
    "extents_ausable = np.array([276.5, 276.8, 45, 45.5], dtype=float)\n",
    "#\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52484000",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79224b-dd44-4184-8f68-d50c2aec43cd",
   "metadata": {},
   "source": [
    "## 1-Create Grid metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbc244",
   "metadata": {},
   "source": [
    "#### this part is only need to run one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bb63de-8b8a-4c48-9acf-2317c04f73c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FVCOM grid metrics file /home/abolmaal/modelling/FVCOM/Huron/input/gridfile/grid_metrics_huron_senseflux_Seasonal.nc\n",
      "INFO - detected longitudes greater than 180.0 in variable lon. Assuming longitude limits are in the range 0 - 360. Correcting these to be in the range -180 to 180.\n",
      "INFO - detected longitudes greater than 180.0 in variable lonc. Assuming longitude limits are in the range 0 - 360. Correcting these to be in the range -180 to 180.\n",
      "\n",
      "Calculating element areas ... done\n",
      "Grid has 51110 nodes on the open boundary\n"
     ]
    }
   ],
   "source": [
    "# Generate the file\n",
    "create_fvcom_grid_metrics_file(fvcom_file_name, obc_file_name = obc_file_name,\n",
    "                               grid_metrics_file_name=grid_metrics_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940096d0",
   "metadata": {},
   "source": [
    "# 2- Config File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f9bf7",
   "metadata": {},
   "source": [
    "### Updating configure file time and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83ee0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def update_datetime_in_config(config_path, new_start, new_end):\n",
    "    # Extract year and month from start and end datetime\n",
    "    start_date = datetime.datetime.strptime(new_start, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = datetime.datetime.strptime(new_end, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    start_year = start_date.year\n",
    "    start_month = start_date.month\n",
    "    end_year = end_date.year\n",
    "    end_month = end_date.month\n",
    "    \n",
    "    # Format the output file name (e.g., FVCOM_Huron_2223_DecMar)\n",
    "    month_range = f\"{start_date.strftime('%b')}{end_date.strftime('%b')}\"  # Abbreviated months (e.g., 'DecMar')\n",
    "    output_filename = f\"FVCOM_Huron_{start_year % 100}{end_year % 100}_{month_range}\"\n",
    "\n",
    "    with open(config_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(config_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"start_datetime\"):\n",
    "                file.write(f\"start_datetime = {new_start}\\n\")\n",
    "            elif line.strip().startswith(\"end_datetime\"):\n",
    "                file.write(f\"end_datetime = {new_end}\\n\")\n",
    "            elif line.strip().startswith(\"output_file\"):\n",
    "                file.write(f\"output_file = %(out_dir)s/{output_filename}\\n\")  # Update the output_file line\n",
    "            else:\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238fb16",
   "metadata": {},
   "source": [
    "### Adjusting config file time and output name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9be3b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated start_datetime, end_datetime, and output_file in /home/abolmaal/modelling/FVCOM/Huron/config_files/Huron_Senseflux_Seasonal_test.cfg.\n"
     ]
    }
   ],
   "source": [
    "# start and end datetime\n",
    "start_datetime = '2023-01-01 00:00:00'\n",
    "end_datetime = '2023-01-31 23:59:59'\n",
    "# Update the config file with new start and end datetime\n",
    "update_datetime_in_config(config_file, start_datetime, end_datetime)\n",
    "print(f\"Updated start_datetime, end_datetime, and output_file in {config_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525c94c-71b2-496f-9c1d-1dae057450d7",
   "metadata": {},
   "source": [
    "### Creating Run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42f1597d-e88d-4f36-9825-18fe301aaf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-01-10  00:00:00\n",
      "End time: 2023-01-30  23:00:00\n",
      "Time direction: forward\n",
      "Number of particle releases: 1\n",
      "Use depth restoring: True\n",
      "Restore particles to a depth of: 0.0 m\n",
      "Model name: FVCOM\n",
      "Coordinate system: geographic\n",
      "Data directory: /mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron\n",
      "Path to grid metrics file: /home/abolmaal/modelling/FVCOM/Huron/input/gridfile/grid_metrics_huron_senseflux_Seasonal.nc\n",
      "File name stem of input files: nos.lmhofs.fields.n000.\n",
      "Numerical method: standard\n",
      "Iterative method: Adv_RK4_3D\n"
     ]
    }
   ],
   "source": [
    "cf = configparser.ConfigParser()\n",
    "cf.read(config_file_name)\n",
    "\n",
    "# Start time\n",
    "print('Start time: {}'.format(cf.get('SIMULATION', 'start_datetime')))\n",
    "\n",
    "# End time\n",
    "print('End time: {}'.format(cf.get('SIMULATION', 'end_datetime')))\n",
    "\n",
    "# Specify that this is a forward tracking experiment\n",
    "print('Time direction: {}'.format(cf.get('SIMULATION', 'time_direction')))\n",
    "\n",
    "# We will do a single run, rather than an ensemble run\n",
    "print('Number of particle releases: {}'.format(cf.get('SIMULATION', 'number_of_particle_releases')))\n",
    "\n",
    "# Use depth restoring, and restore particle depths to the ocean surface\n",
    "print('Use depth restoring: {}'.format(cf.get('SIMULATION', 'depth_restoring')))\n",
    "print('Restore particles to a depth of: {} m'.format(cf.get('SIMULATION', 'fixed_depth')))\n",
    "\n",
    "# Specify that we are working with FVCOM in cartesian coordinates0\n",
    "print('Model name: {}'.format(cf.get('OCEAN_DATA', 'name')))\n",
    "print('Coordinate system: {}'.format(cf.get('SIMULATION', 'coordinate_system')))\n",
    "\n",
    "# Set the location of the grid metrics and input files\n",
    "print('Data directory: {}'.format(cf.get('OCEAN_DATA', 'FVCOM_DIR')))\n",
    "print('Path to grid metrics file: {}'.format(cf.get('OCEAN_DATA', 'grid_metrics_file')))\n",
    "print('File name stem of input files: {}'.format(cf.get('OCEAN_DATA', 'data_file_stem')))\n",
    "      \n",
    "# Do an advection only run using a RK$ intergration scheme \n",
    "print('Numerical method: {}'.format(cf.get('NUMERICS', 'num_method')))\n",
    "print('Iterative method: {}'.format(cf.get('NUMERICS', 'iterative_method')))\n",
    "\n",
    "# print velocity calculater\n",
    "#print('Velocity calculator: {}'.format(cf.get('CONSTANT_SETTLING_VELOCITY_CALCULATOR', 'initialisation_method')))\n",
    "\n",
    "\n",
    "# print biological process you used\n",
    "#print('Biological process: {}'.format(cf.get('BIO_MODEL', 'mortality_calculator')))\n",
    "# print mortality method \n",
    "#print('Mortality method: {}'.format(cf.get('FIXED_TIME_MORALITY_CALCULATOR', 'initialisation_method')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10b808",
   "metadata": {},
   "source": [
    "# I am not using part 3-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d5bc1",
   "metadata": {},
   "source": [
    "## 3-Setting Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c1a57",
   "metadata": {},
   "source": [
    "If you use the following config file huron_senseflux_20230103_Seasonal_mortality.cfg, you don't need to run section 5. it is here for demonstration and showing how mortality works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe70479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Imports\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# from matplotlib import pyplot as plt\n",
    "# from configparser import ConfigParser\n",
    "\n",
    "# import pylag.random as random\n",
    "# from pylag.data_reader import DataReader\n",
    "# from pylag.particle_cpp_wrapper import ParticleSmartPtr\n",
    "# from pylag.mortality import get_mortality_calculator\n",
    "# from pylag.processing.plot import create_figure\n",
    "\n",
    "# # Ensure inline plotting\n",
    "# %matplotlib inline\n",
    "\n",
    "# # Parameters\n",
    "# seconds_per_day = 86400.\n",
    "\n",
    "# # Seed the random number generator\n",
    "# random.seed(10)\n",
    "\n",
    "# # Create the config\n",
    "# #cf.add_section('NUMERICS')\n",
    "# cf.add_section('BIO_MODEL')\n",
    "# cf.add_section('FIXED_TIME_MORTALITY_CALCULATOR')\n",
    "# cf.add_section('PROBABILISTIC_MORTALITY_CALCULATOR')\n",
    "# # We need a data reader to pass to the mortality calculator. It\n",
    "# # can be used to draw out environmental variables (e.g. temperature)\n",
    "# # that affect mortality. In both cases below, it isn't used, so we\n",
    "# # use the base class.\n",
    "# data_reader = DataReader()\n",
    "\n",
    "# # Set time stepping params\n",
    "# n_particles = 1000\n",
    "# simulation_duration_in_days = 30.0\n",
    "# time_step = 100\n",
    "# time_end = simulation_duration_in_days * seconds_per_day\n",
    "# times = np.arange(0.0, time_end, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #Helper function in which the model is run and mortality computed\n",
    "# def run(config, n_particles=1000):\n",
    "#     \"\"\" Run the model to compute mortality through time \"\"\"\n",
    "\n",
    "#     # Create the mortality calculator\n",
    "#     mortality_calculator = get_mortality_calculator(config)\n",
    "\n",
    "#     # Create the living particle seed\n",
    "#     particle_set = []\n",
    "#     for i in range(n_particles):\n",
    "#         # Instantiate a new particle\n",
    "#         particle = ParticleSmartPtr(age=0.0, is_alive=True)\n",
    "\n",
    "#         # Initialise particle mortality parameters\n",
    "#         mortality_calculator.set_initial_particle_properties_wrapper(particle)\n",
    "\n",
    "#         # Append it to the particle set\n",
    "#         particle_set.append(particle)\n",
    "\n",
    "#     # Store the number of living particles in a list\n",
    "#     n_alive_arr = []\n",
    "\n",
    "#     # Run the model\n",
    "#     n_alive = n_particles\n",
    "#     for t in times:\n",
    "#         n_alive_arr.append(n_alive)\n",
    "\n",
    "#         n_deaths = 0\n",
    "#         for particle in particle_set:\n",
    "#             if particle.is_alive:\n",
    "#                 mortality_calculator.apply_wrapper(data_reader, t, particle)\n",
    "#                 if particle.is_alive == False:\n",
    "#                     n_deaths += 1\n",
    "#             particle.set_age(t)\n",
    "\n",
    "#         n_alive -= n_deaths\n",
    "\n",
    "#     return n_alive_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a45586",
   "metadata": {},
   "source": [
    "## 4-FixedTimeMortalityCalculater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e25ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify a fixed time mortality calculator\n",
    "# cf.set('BIO_MODEL', 'mortality_calculator', 'fixed_time')\n",
    "\n",
    "# # 1) Fixed time scenario\n",
    "# # Sharp_2021 suggerst 10 days fpr N uptake in coastal wetlands\n",
    "# age_of_death_in_days = 10.\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'initialisation_method', 'common_value')\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'common_value', str(age_of_death_in_days))\n",
    "# n_alive_common_value = run(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2) Uniform Random \n",
    "# minimum_bound = 8.\n",
    "# maximum_bound = 12.\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'initialisation_method', 'uniform_random')\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'minimum_bound', str(minimum_bound))\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'maximum_bound', str(maximum_bound))\n",
    "# n_alive_uniform_random = run(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36099cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2) Gaussian random\n",
    "# mean = 10.\n",
    "# standard_deviation = 1.\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'initialisation_method', 'gaussian_random')\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'mean', str(mean))\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'standard_deviation', str(standard_deviation))\n",
    "# n_alive_gaussian_random = run(cf)\n",
    "# # Set the bio time step\n",
    "# cf.set('NUMERICS', 'time_step_bio', str(time_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# font_size = 10\n",
    "# fig, ax = create_figure(figure_size=(20, 20), font_size=font_size)\n",
    "# plt.plot(times/seconds_per_day, n_alive_common_value, 'b', label='common_value')\n",
    "# plt.plot(times/seconds_per_day, n_alive_uniform_random, 'r', label='uniform_random')\n",
    "# plt.plot(times/seconds_per_day, n_alive_gaussian_random, 'g', label='gaussian_random')\n",
    "# # Set the bio time step\n",
    "# plt.ylabel('Living individuals (-)', fontsize=font_size)\n",
    "# plt.xlabel('Time (d)', fontsize=font_size)\n",
    "\n",
    "# # Add legend\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe464e37",
   "metadata": {},
   "source": [
    "## 5-ProabilisticMortalityCalculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d38a60",
   "metadata": {},
   "source": [
    "The mortality calculator kills particles at a rate \n",
    ", where \n",
    " is a fixed mortality rate which is set in the run configuraiton file and \n",
    " is the model time step for biological processes. The model computes a uniform random deviate in the range (0, 1). If the number is less than the computed death rate, the particle is killed. Below, we create a population of \n",
    " individuals. We apply a death rate of \n",
    " per day and use a time step of \n",
    " seconds. The model is run forward for \n",
    " days and the number of living individuals plotted as a function of time. The result is compared with a simple analytical solution of exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67166411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Specify a probabilistic mortality calculator\n",
    "# cf.set('BIO_MODEL', 'mortality_calculator', 'probabilistic')\n",
    "\n",
    "# # Set the death rate - currently the same for all particles.\n",
    "# death_rate_per_day = 0.1\n",
    "# cf.set('PROBABILISTIC_MORTALITY_CALCULATOR', 'death_rate_per_day', str(death_rate_per_day))\n",
    "\n",
    "# # Set the bio time step\n",
    "# cf.set('NUMERICS', 'bio_time_step', str(time_step))\n",
    "\n",
    "# # Number of particles\n",
    "# n_particles = 1000\n",
    "\n",
    "# # Run the model\n",
    "# n_alive_numeric = run(cf, n_particles=n_particles)\n",
    "\n",
    "# # Compute the equivalent analytical solution\n",
    "# death_rate_per_second = death_rate_per_day / seconds_per_day\n",
    "# n_alive_analytic = n_particles * np.exp(-death_rate_per_second * times)\n",
    "\n",
    "# # Plot\n",
    "# font_size = 10\n",
    "# fig, ax = create_figure(figure_size=(20, 20), font_size=font_size)\n",
    "# plt.plot(times/seconds_per_day, n_alive_numeric, 'b', label='numeric')\n",
    "# plt.ylabel('Living individuals (-)', fontsize=font_size)\n",
    "# plt.xlabel('Time (d)', fontsize=font_size)\n",
    "\n",
    "# # Add equivalent analytical solution\n",
    "# plt.plot(times/seconds_per_day, n_alive_analytic, 'r', label='analytic')\n",
    "\n",
    "# # Add legend\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de30a0",
   "metadata": {},
   "source": [
    "# 3-Run the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df8f35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.set('OCEAN_DATA', 'data_dir', FVCOM_DIR)\n",
    "cf.set('OCEAN_DATA', 'grid_metrics_file', grid_metrics_file_name)\n",
    "# Directory where the simulation outputs will be saved\n",
    "out_dir = f\"{MODELLING_DIR}/output\"\n",
    "cf.set('GENERAL', 'out_dir', out_dir)\n",
    "\n",
    "# Save a copy in the simulation directory\n",
    "with open(f\"{MODELLING_DIR}/pylag.cfg\", 'w') as config:\n",
    "    cf.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa15ac87-835d-4b67-b93e-1880b89fe6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting ensemble member 1 ...\n",
      "Progress:\n",
      "100% |###########################################|\n"
     ]
    }
   ],
   "source": [
    "# Change to the run directory\n",
    "os.chdir(f\"{MODELLING_DIR}\")\n",
    "\n",
    "# Run the model\n",
    "!{\"python -m pylag.main -c pylag.cfg\"}\n",
    "\n",
    "# Return to the cwd\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42e3e2",
   "metadata": {},
   "source": [
    "# 4-Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924293bf",
   "metadata": {},
   "source": [
    "### Plot Initial Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the initial position file into a pandas DataFrame and skip the first line\n",
    "df = pd.read_csv(f\"{MODELLING_DIR}/input/initial_position/initial_positions_releasezone_intersection_multigroup.dat\", sep = ' ',skiprows=1)\n",
    "group_id = df.iloc[:,0]\n",
    "lons = df.iloc[:,1] \n",
    "lats= df.iloc[:,2]\n",
    "\n",
    "# Create figure\n",
    "\n",
    "fig, ax = create_figure(figure_size=figsize, projection=ccrs.PlateCarree(),\n",
    "                      font_size=font_size, bg_color='gray')\n",
    "\n",
    "# Configure plotter\n",
    "plotter = FVCOMPlotter(grid_metrics_file_name,\n",
    "                       geographic_coords=True,\n",
    "                       font_size=font_size)\n",
    "\n",
    "# Plot bathymetry\n",
    "ax, plot = plotter.plot_field(ax, bathy, extents=zoom_extents_1, add_colour_bar=True, cb_label='Depth (m)',\n",
    "                              vmin=-60., vmax=0., cmap=blue_cmap_reversed)\n",
    "\n",
    "# Overlay grid\n",
    "plotter.draw_grid(ax, linewidth=1.0)\n",
    "\n",
    "# Plot particle initial positions\n",
    "scatter = plotter.scatter(ax, lons, lats, s=35, color='fuchsia', edgecolors='black', linewidth=0.5, zorder=10)\n",
    "\n",
    "# save the initial positions figure in the figure directory\n",
    "\n",
    "plt.savefig(fig_path_initilapositions, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4710d6",
   "metadata": {},
   "source": [
    "### Plotting PyLag results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b490dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/abolmaal/modelling/FVCOM/Huron/output/mortality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_extents_1 = [276.5, 276.8, 44.8, 45.5]  # Zoom-in 1\n",
    "zoom_extents_2 = [276.5, 276, 43.58, 44]  # Zoom-in 2\n",
    "zoom_extents_3 = [277.5, 277, 43.5, 44]  # Zoom-in 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533afde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of file names\n",
    "import re\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom sorting function to extract numerical part after \"__\"\n",
    "def extract_sort_key(filename):\n",
    "    match = re.search(r'__(\\d+)\\.nc$', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Extract the numeric identifier after \"__\"\n",
    "    return float('inf')  # If no match, push the file to the end\n",
    "\n",
    "# Process files\n",
    "for file_name in sorted(filter(lambda x: x.endswith(\".nc\"), os.listdir(output_dir)), key=extract_sort_key):\n",
    "    sample_name = file_name\n",
    "    file_name = os.path.join(output_dir, file_name)\n",
    "    time_of_flight = timedelta(hours=12)\n",
    "   \n",
    "    # Set the extents\n",
    "    extents = extents_LH\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = create_figure(figure_size=figsize, projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "    \n",
    "    # Assuming grid_metrics_file_name, bathy, and cmap are defined elsewhere\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "    plotter.plot_field(ax, bathy, extents=extents_LH, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap=blue_cmap_reversed)\n",
    "    \n",
    "    viewer = Viewer(file_name, time_rounding=900)\n",
    "    date = viewer.date[0] + time_of_flight\n",
    "    if date in viewer.date.tolist():\n",
    "        time_index = viewer.date.tolist().index(date)\n",
    "    else:\n",
    "        print(f\"Date {date} not found in viewer.date\")\n",
    "        continue\n",
    "    # Convert positions into lons/lats\n",
    "    lons, lats = [viewer('longitude')[time_index, :].squeeze(), viewer('latitude')[time_index, :].squeeze()]\n",
    "    \n",
    "    # Plot particle final positions\n",
    "    ax, scatter = plotter.scatter(ax, lons, lats, s=5, color='fuchsia', edgecolors='black')\n",
    "    \n",
    "    lons_paths, lats_paths = (viewer('longitude')[:time_index + 1, :],\n",
    "                              viewer('latitude')[:time_index + 1, :])\n",
    "    \n",
    "    \n",
    "    # Convert all pathline coordinates into lons/lats\n",
    "    ax, lines = plotter.plot_lines(ax, lons_paths, lats_paths, linewidth=0.5, alpha=1, color='#0504aa')\n",
    "    \n",
    "    output_file = os.path.join(fig_dir, f\"{sample_name.split('.')[0]}.png\")\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.close(fig)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/abolmaal/modelling/FVCOM/Huron/output/Yearly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '/home/abolmaal/modelling/FVCOM/Huron/figures/Winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a34a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from pylag.processing.ncview import Viewer\n",
    "from pylag.processing.plot import create_figure, ArakawaAPlotter\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Plot options\n",
    "font_size = 10\n",
    "\n",
    "# Create figure\n",
    "fig, ax = create_figure(figure_size=(20., 20.), projection=ccrs.PlateCarree(),\n",
    "                        font_size=font_size, bg_color='white')\n",
    "\n",
    "# Configure plotter\n",
    "plotter = FVCOMPlotter(grid_metrics_file_name,\n",
    "                          font_size=font_size)\n",
    "\n",
    "extents = [274,280, 43,46.3]\n",
    "#extent=[276.5,276.8,44.8,45.5]\n",
    "#extents=[276.5, 276, 43.58, 44]\n",
    "# Add tracks from the ocean only run\n",
    "# ----------------------------------\n",
    "# PyLag file name\n",
    "file_name = f'{out_dir}/Fvcom_Huron_23_NovtoApr_1.nc'\n",
    "\n",
    "# Dataset holding particle positions\n",
    "viewer = Viewer(file_name, time_rounding=60)\n",
    "\n",
    "# Plot final positions\n",
    "plotter.scatter(ax,\n",
    "                viewer('longitude')[-1, :].squeeze(),\n",
    "                viewer('latitude')[-1, :].squeeze(),\n",
    "                s=4, color='r', edgecolors='none',\n",
    "                configure=True,\n",
    "                draw_coastlines=True,\n",
    "                tick_inc=True,\n",
    "                extents=extents,label= 'Winter(Nov-Apr)')\n",
    "\n",
    "# Add high resolution land\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
    "ax.add_feature(cfeature.COASTLINE, edgecolor='black', linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=0.5)\n",
    "ax.add_feature(cfeature.LAKES, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Plot paths\n",
    "# _ = plotter.plot_lines(ax,\n",
    "#                        viewer('longitude')[:, :].squeeze(),\n",
    "#                        viewer('latitude')[:, :].squeeze(),\n",
    "#                        linewidth=0.005, alpha=1, color='black')\n",
    "\n",
    "\n",
    "# Add tracks from the ocean + stokes drift run\n",
    "# --------------------------------------------\n",
    "# PyLag file name\n",
    "file_name = f'{out_dir}/Fvcom_Huron_23_MaytoOct_1.nc'\n",
    "\n",
    "# Dataset holding particle positions\n",
    "viewer = Viewer(file_name, time_rounding=60)\n",
    "\n",
    "# Plot final positions\n",
    "plotter.scatter(ax,\n",
    "                viewer('longitude')[-1, :].squeeze(),\n",
    "                viewer('latitude')[-1, :].squeeze(),\n",
    "                s=8, color='y', edgecolors='none', label = 'Summer(May-Oct)')\n",
    "\n",
    "# Plot paths\n",
    "# _ = plotter.plot_lines(ax,\n",
    "#                        viewer('longitude')[:, :].squeeze(),\n",
    "#                        viewer('latitude')[:, :].squeeze(),\n",
    "#                        linewidth=1., alpha=1, color='y')\n",
    "\n",
    "\n",
    "# # Add tracks from the ocean + leeway run\n",
    "# # --------------------------------------\n",
    "# # PyLag file name\n",
    "# file_name = f'{out_dir}/Fvcom_Huron_23_Oct__10.nc'\n",
    "\n",
    "# # Dataset holding particle positions\n",
    "# viewer = Viewer(file_name, time_rounding=60)\n",
    "\n",
    "# # Plot final positions\n",
    "# plotter.scatter(ax,\n",
    "#                 viewer('longitude')[-1, :].squeeze(),\n",
    "#                 viewer('latitude')[-1, :].squeeze(),\n",
    "#                 s=8, color='b', edgecolors='none', label = 'OCt')\n",
    "plt.legend()\n",
    "plt.title('particle Tracking in Lake Huron Summer and Winter', fontsize=font_size)\n",
    "\n",
    "# Save the figure\n",
    "output_file = os.path.join(fig_dir, 'tracks_LakeHuron_Summerwinter.jpeg')\n",
    "plt.savefig(output_file, dpi=300)\n",
    "\n",
    "# Plot paths\n",
    "# _ = plotter.plot_lines(ax,\n",
    "#                        viewer('longitude')[:, :].squeeze(),\n",
    "#                        viewer('latitude')[:, :].squeeze(),\n",
    "#                        linewidth=1., alpha=1, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b95534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import os\n",
    "\n",
    "from pylag.processing.ncview import Viewer\n",
    "from pylag.processing.plot import create_figure, FVCOMPlotter\n",
    "\n",
    "# ✅ Define plot options\n",
    "font_size = 10\n",
    "\n",
    "# ✅ Define main and zoomed-in extents\n",
    "main_extents = [274, 280, 43, 46.3]  # Main map extent\n",
    "zoom_extents_1 = [276.5, 276.8, 44.8, 45.5]  # Zoom-in 1\n",
    "zoom_extents_2 = [276.5, 276, 43.58, 44]  # Zoom-in 2\n",
    "zoom_extents_3 = [277.5, 277, 43.5, 44]  # Zoom-in 3\n",
    "\n",
    "# ✅ Create figure with main map\n",
    "fig = plt.figure(figsize=(26, 26))\n",
    "ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax_main.set_extent(main_extents, crs=ccrs.PlateCarree())\n",
    "\n",
    "# ✅ Configure plotter\n",
    "plotter = FVCOMPlotter(grid_metrics_file_name, font_size=font_size)\n",
    "\n",
    "# ✅ PyLag file name\n",
    "file_name = f'{out_dir}/Fvcom_Huron_23_JunJulAug_1.nc'\n",
    "\n",
    "# ✅ Dataset holding particle positions\n",
    "viewer = Viewer(file_name, time_rounding=60)\n",
    "\n",
    "# ✅ Plot final positions (red for summer)\n",
    "plotter.scatter(ax_main,\n",
    "                viewer('longitude')[-1, :].squeeze(),\n",
    "                viewer('latitude')[-1, :].squeeze(),\n",
    "                s=8, color='r', edgecolors='none',\n",
    "                configure=True,\n",
    "                draw_coastlines=True,\n",
    "                tick_inc=True,\n",
    "                extents=main_extents,\n",
    "                label='JunJulAug')\n",
    "\n",
    "# ✅ Add high-resolution land features\n",
    "ax_main.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
    "ax_main.add_feature(cfeature.COASTLINE, edgecolor='black', linewidth=0.5)\n",
    "ax_main.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=0.5)\n",
    "ax_main.add_feature(cfeature.LAKES, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# ✅ Plot paths (particle tracks)\n",
    "# _ = plotter.plot_lines(ax_main,\n",
    "#                        viewer('longitude')[:, :].squeeze(),\n",
    "#                        viewer('latitude')[:, :].squeeze(),\n",
    "#                        linewidth=0.005, alpha=1, color='black')\n",
    "\n",
    "file_name = f'{out_dir}/Fvcom_Huron_23_OctNovDec_1.nc'\n",
    "\n",
    "# Dataset holding particle positions\n",
    "viewer = Viewer(file_name, time_rounding=60)\n",
    "\n",
    "# Plot final positions\n",
    "plotter.scatter(ax,\n",
    "                viewer('longitude')[-1, :].squeeze(),\n",
    "                viewer('latitude')[-1, :].squeeze(),\n",
    "                s=8, color='y', edgecolors='none', label = 'Nov')\n",
    "\n",
    "# ✅ Define inset positions relative to the figure (x, y, width, height)\n",
    "inset_positions = [\n",
    "    [0.60, 0.50, 0.25, 0.25],  # Top right\n",
    "    [0.15, 0.40, 0.18, 0.18],  # Top left\n",
    "    [0.65, 0.25,0.18, 0.18]   # Bottom center\n",
    "]\n",
    "\n",
    "# ✅ Define zoom extents\n",
    "zoom_extents = [zoom_extents_1, zoom_extents_2, zoom_extents_3]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# ✅ Loop through the three insets\n",
    "for i, (inset_pos, zoom_extent, color) in enumerate(zip(inset_positions, zoom_extents, colors)):\n",
    "    # ✅ Create inset axes manually\n",
    "    left, bottom, width, height = inset_pos\n",
    "    ax_inset = fig.add_axes([left, bottom, width, height], projection=ccrs.PlateCarree())\n",
    "    ax_inset.set_extent(zoom_extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    # ✅ Plot zoomed-in scatter points\n",
    "    plotter.scatter(ax_inset,\n",
    "                    viewer('longitude')[-1, :].squeeze(),\n",
    "                    viewer('latitude')[-1, :].squeeze(),\n",
    "                    s=10, color=color, edgecolors='none')\n",
    "\n",
    "    # ✅ Plot paths inside zoomed-in inset\n",
    "    # _ = plotter.plot_lines(ax_inset,\n",
    "    #                        viewer('longitude')[:, :].squeeze(),\n",
    "    #                        viewer('latitude')[:, :].squeeze(),\n",
    "    #                        linewidth=0.05, alpha=1, color=color)\n",
    "\n",
    "    # ✅ Set zoomed-in title\n",
    "    ax_inset.set_title(f\"Zoom {i+1}\", fontsize=font_size - 4, color=color, fontweight='bold')\n",
    "\n",
    "    # ✅ Remove axis ticks for zoom-in maps\n",
    "    ax_inset.set_xticks([])\n",
    "    ax_inset.set_yticks([])\n",
    "\n",
    "    # ✅ Add rectangle to highlight zoomed-in region on main map\n",
    "    rect = plt.Rectangle(\n",
    "        (zoom_extent[0], zoom_extent[2]),\n",
    "        zoom_extent[1] - zoom_extent[0],\n",
    "        zoom_extent[3] - zoom_extent[2],\n",
    "        linewidth=2, edgecolor=color, facecolor='none', transform=ccrs.PlateCarree(), zorder=50\n",
    "    )\n",
    "    ax_main.add_patch(rect)  # ✅ Ensure the rectangle is added to the main map\n",
    "\n",
    "# ✅ Add legend\n",
    "plt.legend()\n",
    "plt.title('Particle tracks in Lake Huron: Three Months of Summer', fontsize=font_size)\n",
    "\n",
    "# ✅ Save the figure\n",
    "output_file = os.path.join(fig_dir, 'tracks_LakeHuron_JunJulyAug.png')\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# ✅ Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir ='/home/abolmaal/modelling/FVCOM/Huron/output/mortality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Define the function to sort the files based on the time\n",
    "def extract_sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        # Extract the number after the double underscores and before the `.nc` extension\n",
    "        number = int(filename.split('__')[1].split('.')[0])\n",
    "        return number\n",
    "    except (IndexError, ValueError):\n",
    "        # Handle filenames that do not match the pattern by returning a high number to place them last\n",
    "        return float('inf')\n",
    "\n",
    "# Specify `group_id` and `group_number` for filtering\n",
    "target_group_id = 57  # Change to your specific group_id\n",
    "target_group_number = '57040'  # Change to your specific group_number\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith(\".nc\"), os.listdir(out_dir)), key=extract_sort_key):\n",
    "    sample_name = file_name\n",
    "    file_name = os.path.join(out_dir, file_name)\n",
    "    time_of_flight = timedelta(hours=24)\n",
    "   \n",
    "    # Create figure\n",
    "    fig, ax = create_figure(figure_size=figsize, projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "    plotter.plot_field(ax, bathy, extents=extents_LH, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap=cmap)\n",
    "    \n",
    "    viewer = Viewer(file_name, time_rounding=25200)\n",
    "    date = viewer.date[0] + time_of_flight\n",
    "    if date in viewer.date.tolist():\n",
    "        time_index = viewer.date.tolist().index(date)\n",
    "    else:\n",
    "        print(f\"Date {date} not found in viewer.date\")\n",
    "        continue\n",
    "    \n",
    "    # Sanity checks for `group_id` and `group_number`\n",
    "    try:\n",
    "        group_ids = viewer('group_id')[:].squeeze()  # Assuming 'group_id' is a variable in the file\n",
    "        group_numbers = viewer('group_number')[:].squeeze()  # Assuming 'group_number' is a variable in the file\n",
    "    except KeyError as e:\n",
    "        print(f\"Variable {str(e)} not found in {file_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Filter particles by `group_id` and `group_number`\n",
    "    target_indices = (group_ids == target_group_id) & (group_numbers == target_group_number)\n",
    "    \n",
    "    if not target_indices.any():\n",
    "        print(f\"No particles found for group_id={target_group_id} and group_number={target_group_number}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract positions for the specific group_id and group_number\n",
    "    lons, lats = [viewer('longitude')[time_index, target_indices].squeeze(),\n",
    "                  viewer('latitude')[time_index, target_indices].squeeze()]\n",
    "    \n",
    "    # Plot particle final positions\n",
    "    ax, scatter = plotter.scatter(ax, lons, lats, s=200, color='#e50000', edgecolors='black')\n",
    "    \n",
    "    # Extract pathlines for the specific group_id and group_number\n",
    "    lons_paths, lats_paths = (viewer('longitude')[:time_index + 1, target_indices],\n",
    "                              viewer('latitude')[:time_index + 1, target_indices])\n",
    "    \n",
    "    # Plot the particle pathlines\n",
    "    ax, lines = plotter.plot_lines(ax, lons_paths, lats_paths, linewidth=0.5, alpha=1, color='#0504aa')\n",
    "    \n",
    "    # Save the figure\n",
    "    output_file = os.path.join(fig_dir, f\"{sample_name.split('.')[0]}_particle_{target_group_id}_{target_group_number}.png\")\n",
    "    plt.savefig(output_file, dpi=50)\n",
    "    plt.close(fig)\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to sort the files based on the time\n",
    "def extract_sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        # Extract the number after the double underscores and before the `.nc` extension\n",
    "        number = int(filename.split('__')[1].split('.')[0])\n",
    "        return number\n",
    "    except (IndexError, ValueError):\n",
    "        # Handle filenames that do not match the pattern by returning a high number to place them last\n",
    "        return float('inf')\n",
    "\n",
    "# Specify `group_id` and `group_number` for filtering\n",
    "target_group_id = 2  # Change to your specific group_id\n",
    "target_group_number = '57040'  # Change to your specific group_number\n",
    "\n",
    "for file_name in sorted(filter(lambda x: x.endswith(\".nc\"), os.listdir(out_dir)), key=extract_sort_key):\n",
    "    try:\n",
    "        sample_name = file_name\n",
    "        file_name = os.path.join(out_dir, file_name)\n",
    "        time_of_flight = timedelta(hours=24)\n",
    "\n",
    "        # Create figure\n",
    "        fig, ax = create_figure(figure_size=figsize, projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "        plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "\n",
    "        viewer = Viewer(file_name, time_rounding=25200)\n",
    "        date = viewer.date[0] + time_of_flight\n",
    "        if date in viewer.date.tolist():\n",
    "            time_index = viewer.date.tolist().index(date)\n",
    "        else:\n",
    "            print(f\"Date {date} not found in viewer.date\")\n",
    "            continue\n",
    "\n",
    "        # Sanity checks for `group_id` and `group_number`\n",
    "        try:\n",
    "            group_ids = viewer('group_id')[:].squeeze()  # Assuming 'group_id' is a variable in the file\n",
    "            group_numbers = viewer('group_number')[:].squeeze()  # Assuming 'group_number' is a variable in the file\n",
    "        except KeyError as e:\n",
    "            print(f\"Variable {str(e)} not found in {file_name}\")\n",
    "            continue\n",
    "\n",
    "        # Filter particles by `group_id` and `group_number`\n",
    "        target_indices = (group_ids == target_group_id) & (group_numbers == target_group_number)\n",
    "\n",
    "        if not target_indices.any():\n",
    "            print(f\"No particles found for group_id={target_group_id} and group_number={target_group_number}\")\n",
    "            continue\n",
    "\n",
    "        # Extract positions for the specific group_id and group_number\n",
    "        lons, lats = [viewer('longitude')[time_index, target_indices].squeeze(),\n",
    "                      viewer('latitude')[time_index, target_indices].squeeze()]\n",
    "\n",
    "        # Dynamically calculate extent based on min/max coordinates\n",
    "        extent_margin = 1  # Add a small margin to the extent\n",
    "        extent = [\n",
    "            lons.min() - extent_margin,\n",
    "            lons.max() + extent_margin,\n",
    "            lats.min() - extent_margin,\n",
    "            lats.max() + extent_margin\n",
    "        ]\n",
    "\n",
    "        # Set extent for the plot\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot particle final positions\n",
    "        ax, scatter = plotter.scatter(ax, lons, lats, s=200, color='#e50000', edgecolors='black')\n",
    "\n",
    "        # Extract pathlines for the specific group_id and group_number\n",
    "        lons_paths, lats_paths = (viewer('longitude')[:time_index + 1, target_indices],\n",
    "                                  viewer('latitude')[:time_index + 1, target_indices])\n",
    "\n",
    "        # Plot the particle pathlines\n",
    "        ax, lines = plotter.plot_lines(ax, lons_paths, lats_paths, linewidth=0.5, alpha=1, color='#0504aa')\n",
    "\n",
    "        # Save the figure\n",
    "        output_file = os.path.join(fig_dir, f\"{sample_name.split('.')[0]}_particle_{target_group_id}_{target_group_number}.png\")\n",
    "        plt.savefig(output_file, dpi=50)\n",
    "\n",
    "    finally:\n",
    "        # Clean up resources\n",
    "        plt.close(fig)\n",
    "        del viewer  # Free Viewer memory\n",
    "        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c177e8d",
   "metadata": {},
   "source": [
    "# plot the target group_id, group_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "# Define the function to sort the files based on the time\n",
    "def extract_sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        # Extract the number after the double underscores and before the .nc extension\n",
    "        number = int(filename.split('__')[1].split('.')[0])\n",
    "        return number\n",
    "    except (IndexError, ValueError):\n",
    "        # Handle filenames that do not match the pattern by returning a high number to place them last\n",
    "        return float('inf')\n",
    "\n",
    "# Specify group_id and group_number for filtering\n",
    "target_group_id = 57  # Change to your specific group_id\n",
    "target_group_number = '57040'  # Change to your specific group_number\n",
    "\n",
    "# Find the files and sort them\n",
    "files = sorted(filter(lambda x: x.endswith(\".nc\"), os.listdir(output_dir)), key=extract_sort_key)\n",
    "\n",
    "# Prepare animation elements\n",
    "fig, ax = plt.subplots(figsize=figsize, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "\n",
    "# Initialize empty elements for animation\n",
    "scatter = None\n",
    "lines = None\n",
    "time_text = ax.text(\n",
    "    0.02, 0.95, '', transform=ax.transAxes, fontsize=12, color='white', bbox=dict(facecolor='black', alpha=0.5)\n",
    ")\n",
    "\n",
    "# Function to update animation frames\n",
    "def update_frame(file_name):\n",
    "    global scatter, lines  # Use global variables to update scatter and lines\n",
    "    file_name = os.path.join(out_dir, file_name)\n",
    "\n",
    "    # Load viewer for the file\n",
    "    viewer = Viewer(file_name, time_rounding=25200)\n",
    "\n",
    "    # Extract the date and time of flight\n",
    "    date = viewer.date[0] + timedelta(hours=24)\n",
    "    time_index = viewer.date.tolist().index(date)\n",
    "\n",
    "    # Sanity checks for group_id and group_number\n",
    "    group_ids = viewer('group_id')[:].squeeze()\n",
    "    group_numbers = viewer('group_number')[:].squeeze()\n",
    "    target_indices = (group_ids == target_group_id) & (group_numbers == target_group_number)\n",
    "\n",
    "    if not target_indices.any():\n",
    "        return  # Skip if no particles are found\n",
    "\n",
    "    # Extract positions for the specific group_id and group_number\n",
    "    lons, lats = [viewer('longitude')[time_index, target_indices].squeeze(),\n",
    "                  viewer('latitude')[time_index, target_indices].squeeze()]\n",
    "\n",
    "    # Dynamically calculate extent with a margin\n",
    "    extent_margin = 0.5  # Add a larger margin to the extent\n",
    "    extent = extents_LH\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    # Add high resolution land\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor='black', linewidth=0.5, zorder = 10)\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=0.5, zorder = 10)\n",
    "    ax.add_feature(cfeature.LAKES, edgecolor='black', linewidth=0.5,zorder =10)\n",
    "\n",
    "\n",
    "    # Clear previous scatter and lines\n",
    "    if scatter:\n",
    "        scatter.remove()\n",
    "    if lines:\n",
    "        for line in lines:\n",
    "            line.remove()\n",
    "\n",
    "    # Plot particle final positions\n",
    "    scatter = ax.scatter(lons, lats, s=200, color='#e50000', edgecolors='black', transform=ccrs.PlateCarree(),zorder = 30)\n",
    "\n",
    "    # Extract pathlines\n",
    "    lons_paths, lats_paths = (viewer('longitude')[:time_index + 1, target_indices],\n",
    "                              viewer('latitude')[:time_index + 1, target_indices])\n",
    "\n",
    "    # Plot the particle pathlines\n",
    "    # lines = []\n",
    "    # for i in range(lons_paths.shape[1]):  # Iterate over particles\n",
    "    #     line, = ax.plot(lons_paths[:, i], lats_paths[:, i], linewidth=0.5, alpha=1, color='#0504aa', transform=ccrs.PlateCarree(),zorder = 20)\n",
    "    #     lines.append(line)\n",
    "\n",
    "    # Update the title\n",
    "    time_text.set_text(f\"Time: {date.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # Clean up memory\n",
    "    del viewer\n",
    "    gc.collect()\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update_frame, frames=files, interval=1000, repeat=False)\n",
    "\n",
    "# Save the animation\n",
    "output_file = os.path.join(fig_dir, f\"particle_animation_group_{target_group_id}_{target_group_number}.mp4\")\n",
    "ani.save(output_file, fps=1, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b85fd2",
   "metadata": {},
   "source": [
    "# Plot group_id with couple group_number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2be4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "# Define the function to sort the files based on time\n",
    "def extract_sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        # Extract the number after the double underscores and before the `.nc` extension\n",
    "        number = int(filename.split('__')[1].split('.')[0])\n",
    "        return number\n",
    "    except (IndexError, ValueError):\n",
    "        # Handle filenames that do not match the pattern by returning a high number to place them last\n",
    "        return float('inf')\n",
    "\n",
    "# Specify `group_id` and multiple `group_number` values for filtering\n",
    "target_group_id = 57  # Change to your specific group_id\n",
    "target_group_numbers = ['57040', '57041', '57042']  # List of group numbers\n",
    "\n",
    "# Find the files and sort them\n",
    "files = sorted(filter(lambda x: x.endswith(\".nc\"), os.listdir(output_dir)), key=extract_sort_key)\n",
    "\n",
    "# Prepare animation elements\n",
    "fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=12)\n",
    "\n",
    "# Initialize empty elements for animation\n",
    "scatter = []\n",
    "lines = []\n",
    "time_text = ax.text(\n",
    "    0.02, 0.95, '', transform=ax.transAxes, fontsize=12, color='white', bbox=dict(facecolor='black', alpha=0.5)\n",
    ")\n",
    "\n",
    "# Define colors for each group number\n",
    "colors = plt.cm.jet(np.linspace(0, 1, len(target_group_numbers)))\n",
    "\n",
    "# Function to update animation frames\n",
    "def update_frame(file_name):\n",
    "    global scatter, lines\n",
    "    file_name = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Load viewer for the file\n",
    "    viewer = Viewer(file_name, time_rounding=21600)\n",
    "\n",
    "    # Extract the date and time of flight\n",
    "    date = viewer.date[0] + timedelta(hours=12)\n",
    "    time_index = viewer.date.tolist().index(date)\n",
    "\n",
    "    # Sanity checks for `group_id` and multiple `group_number` values\n",
    "    group_ids = viewer('group_id')[:].squeeze()\n",
    "    group_numbers = viewer('group_number')[:].squeeze()\n",
    "    print(f\"Available group_ids: {np.unique(group_ids)}\")\n",
    "    print(f\"Available group_numbers: {np.unique(group_numbers)}\")\n",
    "    # Check if any group has data for this frame\n",
    "    if not any(((group_ids == target_group_id) & (group_numbers == int(group_number))).any() for group_number in target_group_numbers):\n",
    "        print(f\"No particles found for any group at {date}, skipping frame.\")\n",
    "        return\n",
    "\n",
    "    # Clear previous scatter and lines\n",
    "    for scatter_point in scatter:\n",
    "        scatter_point.remove()\n",
    "    scatter.clear()\n",
    "\n",
    "    for line in lines:\n",
    "        line.remove()\n",
    "    lines.clear()\n",
    "\n",
    "    # Set map extent and add map features\n",
    "    extent = extents_LH\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgrey', zorder=1)  # Low zorder\n",
    "    ax.add_feature(cfeature.COASTLINE, edgecolor='black', linewidth=0.5, zorder=2)  # Higher than land\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=0.5, zorder=2)\n",
    "    ax.add_feature(cfeature.LAKES, edgecolor='black', linewidth=0.5, zorder=2)\n",
    "\n",
    "    # Plot particle final positions for each group_number\n",
    "    for group_number, color in zip(target_group_numbers, colors):\n",
    "        group_idx = (group_ids == target_group_id) & (group_numbers == int(group_number))\n",
    "        if not group_idx.any():  # Skip if no particles are found for this group_number\n",
    "            print(f\"No particles found for group_number {group_number} at {date}\")\n",
    "            continue\n",
    "\n",
    "        # Extract positions for the current group_number\n",
    "        group_lons = viewer('longitude')[time_index, group_idx].squeeze()\n",
    "        group_lats = viewer('latitude')[time_index, group_idx].squeeze()\n",
    "\n",
    "        # Adjust longitude for consistency with projection\n",
    "        #group_lons = np.where(group_lons < 180, group_lons + 360, group_lons)\n",
    "\n",
    "        # Plot the scatter points\n",
    "        scatter_point = ax.scatter(\n",
    "            group_lons,\n",
    "            group_lats,\n",
    "            s=200, color=color, edgecolors='black', label=f'Group {group_number}',\n",
    "            transform=ccrs.PlateCarree(), zorder=30  # Higher zorder for points\n",
    "        )\n",
    "        scatter.append(scatter_point)\n",
    "\n",
    "    # Extract and plot pathlines for each group_number\n",
    "    lons_paths, lats_paths = (viewer('longitude')[:time_index + 1, target_indices],\n",
    "                              viewer('latitude')[:time_index + 1, target_indices])\n",
    "    for i in range(lons_paths.shape[1]):  # Iterate over particles\n",
    "        line, = ax.plot(\n",
    "            lons_paths[:, i], lats_paths[:, i], linewidth=0.5, alpha=1, color='#0504aa',\n",
    "            transform=ccrs.PlateCarree(), zorder=2.5  # Below scatter\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    # Update the title\n",
    "    time_text.set_text(f\"Time: {date.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # Clean up memory\n",
    "    del viewer\n",
    "    gc.collect()\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update_frame, frames=files, interval=1000, repeat=False)\n",
    "\n",
    "# Save the animation\n",
    "output_file = os.path.join(fig_dir, f\"particle_animation_group_{target_group_id}_multiple_groups.mp4\")\n",
    "ani.save(output_file, fps=1, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
