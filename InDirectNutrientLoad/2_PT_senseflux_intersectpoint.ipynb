{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814ab0ed",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664767c",
   "metadata": {},
   "source": [
    "Following Code Uses PyLag, offline Particle Tracking model and FVCOM outputs that are Downloaded from the following for 2023 https://noaa-nos-ofs-pds.s3.amazonaws.com/index.html#lmhofs/netcdf\n",
    "and Computes Lagrangian Particle Tracking for particles that are release at the mouth of Lake Huron's stream watersheds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d9afa",
   "metadata": {},
   "source": [
    "in the local directory they are placed here\n",
    "FVCOME files are in this location \n",
    "#S:\\Data\\External_Models\\Outputs\\GLCFS\\LakeHuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ca450-9df5-4770-92ab-1fb3397e6b87",
   "metadata": {},
   "source": [
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41dad765-f52b-43e8-a78f-0c01abd0aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File system and configuration management\n",
    "import os\n",
    "import glob\n",
    "import configparser\n",
    "import datetime\n",
    "\n",
    "# Data handling and processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# NetCDF data handling\n",
    "from netCDF4 import Dataset\n",
    "from cftime import num2pydate\n",
    "import xarray as xr\n",
    "\n",
    "# Visualization: general plotting, Cartopy, and Matplotlib utilities\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# FVCOM-specific visualization and utility tools\n",
    "from pylag.processing.plot import FVCOMPlotter, create_figure, colourmap\n",
    "from pylag.processing.utils import get_grid_bands\n",
    "from pylag.grid_metrics import create_fvcom_grid_metrics_file\n",
    "\n",
    "# Regridding, viewing, and garbage collection utilities\n",
    "from pylag.regrid import regridder\n",
    "from pylag.processing.ncview import Viewer\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bebed",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470043bd-12f8-4d0b-8659-8e68d8ac3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FVCOM_DIR='/home/abolmaal/Data/FVCOMEDATA'.format(os.environ['HOME']) \n",
    "# fvcom model directory\n",
    "FVCOM_DIR = '/mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/2023'\n",
    "\n",
    "# Create run directory\n",
    "cwd = os.getcwd()\n",
    "# Create run directory\n",
    "MODELLING_DIR = '/home/abolmaal/modelling/FVCOM/Huron'.format(cwd)\n",
    "try:\n",
    "    os.makedirs(MODELLING_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Create input sub-directory for input files\n",
    "input_dir = '{}/input'.format(MODELLING_DIR)\n",
    "try:\n",
    "    os.makedirs(input_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# input file to create grid metrics\n",
    "fvcom_file_name = os.path.join(FVCOM_DIR, 'nos.lmhofs.fields.n000.20230501.t00z.nc')\n",
    "\n",
    "# The file listing the location of open boundary nodes\n",
    "\n",
    "obc_file_name = os.path.join(MODELLING_DIR,'input', 'obc.dat')\n",
    "\n",
    "\n",
    "\n",
    "# initial position of the particles\n",
    "initial_position_file = os.path.join(MODELLING_DIR, 'input', 'initial_position', 'initial_positions_releasezone_intersection_multigroup_2_lastrevised.dat')\n",
    "\n",
    "\n",
    "# config file\n",
    "config_file_name = os.path.join(MODELLING_DIR, 'config_files', 'Huron_Senseflux_Seasonal.cfg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb1723e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: /mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/2023/nos.lmhofs.fields.n000.20230501.t00z.nc\n"
     ]
    }
   ],
   "source": [
    "print(f\"File path: {fvcom_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf4d8b",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877dcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The name of the output file containing the grid metrics\n",
    "# # create a sub directory for the grid file\n",
    "# grid_file_dir = f'{input_dir}/gridfile'\n",
    "# try:\n",
    "#     os.makedirs(grid_file_dir)\n",
    "# except FileExistsError:\n",
    "#     pass\n",
    "grid_metrics_file_name = f'{input_dir}/gridfile/grid_metrics_huron_senseflux_Seasonal.nc'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create output sub-directory\n",
    "output_dir = '{}/output'.format(MODELLING_DIR)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52484000",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79224b-dd44-4184-8f68-d50c2aec43cd",
   "metadata": {},
   "source": [
    "## 1-Create Grid metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbc244",
   "metadata": {},
   "source": [
    "#### this part is only need to run one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb63de-8b8a-4c48-9acf-2317c04f73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the file\n",
    "# create_fvcom_grid_metrics_file(fvcom_file_name, obc_file_name = obc_file_name,\n",
    "#                             grid_metrics_file_name=grid_metrics_file_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940096d0",
   "metadata": {},
   "source": [
    "# 2- Config File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f9bf7",
   "metadata": {},
   "source": [
    "### Updating configure file time and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ee0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def update_datetime_in_config(config_path, new_start, new_end):\n",
    "    # Extract year and month from start and end datetime\n",
    "    start_date = datetime.datetime.strptime(new_start, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = datetime.datetime.strptime(new_end, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    start_year = start_date.year\n",
    "    start_month = start_date.month\n",
    "    end_year = end_date.year\n",
    "    end_month = end_date.month\n",
    "    \n",
    "    # Format the output file name (e.g., FVCOM_Huron_2223_DecMar)\n",
    "    month_range = f\"{start_date.strftime('%b')}{end_date.strftime('%b')}\"  # Abbreviated months (e.g., 'DecMar')\n",
    "    output_filename = f\"FVCOM_Huron_{start_year % 100}{end_year % 100}_{month_range}\"\n",
    "\n",
    "    with open(config_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(config_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"start_datetime\"):\n",
    "                file.write(f\"start_datetime = {new_start}\\n\")\n",
    "            elif line.strip().startswith(\"end_datetime\"):\n",
    "                file.write(f\"end_datetime = {new_end}\\n\")\n",
    "            elif line.strip().startswith(\"output_file\"):\n",
    "                file.write(f\"output_file = %(out_dir)s/{output_filename}\\n\")  # Update the output_file line\n",
    "            else:\n",
    "                file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238fb16",
   "metadata": {},
   "source": [
    "### Adjusting config file time and output name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be3b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated start_datetime, end_datetime, and output_file in /home/abolmaal/modelling/FVCOM/Huron/config_files/Huron_Senseflux_Seasonal.cfg.\n"
     ]
    }
   ],
   "source": [
    "# #start and end datetime\n",
    "start_datetime = '2023-10-01 00:00:00'\n",
    "end_datetime = '2023-11-28 23:59:59'\n",
    "# Update the config file with new start and end datetime\n",
    "update_datetime_in_config(config_file_name, start_datetime, end_datetime)\n",
    "print(f\"Updated start_datetime, end_datetime, and output_file in {config_file_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525c94c-71b2-496f-9c1d-1dae057450d7",
   "metadata": {},
   "source": [
    "### Creating Run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42f1597d-e88d-4f36-9825-18fe301aaf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-10-01 00:00:00\n",
      "End time: 2023-11-28 23:59:59\n",
      "Time direction: forward\n",
      "Number of particle releases: 1\n",
      "Use depth restoring: True\n",
      "Restore particles to a depth of: 0.0 m\n",
      "Model name: FVCOM\n",
      "Coordinate system: geographic\n",
      "Data directory: /mnt/hydroglg/Data/External_Models/Outputs/GLCFS/LakeHuron/2023\n",
      "Path to grid metrics file: /home/abolmaal/modelling/FVCOM/Huron/input/gridfile/grid_metrics_huron_senseflux_Seasonal.nc\n",
      "File name stem of input files: nos.lmhofs.fields.n000.\n",
      "Numerical method: standard\n",
      "Iterative method: Adv_RK4_3D\n"
     ]
    }
   ],
   "source": [
    "cf = configparser.ConfigParser()\n",
    "cf.read(config_file_name)\n",
    "\n",
    "# Start time\n",
    "print('Start time: {}'.format(cf.get('SIMULATION', 'start_datetime')))\n",
    "\n",
    "# End time\n",
    "print('End time: {}'.format(cf.get('SIMULATION', 'end_datetime')))\n",
    "\n",
    "# Specify that this is a forward tracking experiment\n",
    "print('Time direction: {}'.format(cf.get('SIMULATION', 'time_direction')))\n",
    "\n",
    "# We will do a single run, rather than an ensemble run\n",
    "print('Number of particle releases: {}'.format(cf.get('SIMULATION', 'number_of_particle_releases')))\n",
    "\n",
    "# Use depth restoring, and restore particle depths to the ocean surface\n",
    "print('Use depth restoring: {}'.format(cf.get('SIMULATION', 'depth_restoring')))\n",
    "print('Restore particles to a depth of: {} m'.format(cf.get('SIMULATION', 'fixed_depth')))\n",
    "\n",
    "# Specify that we are working with FVCOM in cartesian coordinates0\n",
    "print('Model name: {}'.format(cf.get('OCEAN_DATA', 'name')))\n",
    "print('Coordinate system: {}'.format(cf.get('SIMULATION', 'coordinate_system')))\n",
    "\n",
    "# Set the location of the grid metrics and input files\n",
    "print('Data directory: {}'.format(cf.get('OCEAN_DATA', 'data_dir')))\n",
    "print('Path to grid metrics file: {}'.format(cf.get('OCEAN_DATA', 'grid_metrics_file')))\n",
    "print('File name stem of input files: {}'.format(cf.get('OCEAN_DATA', 'data_file_stem')))\n",
    "      \n",
    "# Do an advection only run using a RK$ intergration scheme \n",
    "print('Numerical method: {}'.format(cf.get('NUMERICS', 'num_method')))\n",
    "print('Iterative method: {}'.format(cf.get('NUMERICS', 'iterative_method')))\n",
    "\n",
    "# print velocity calculater\n",
    "#print('Velocity calculator: {}'.format(cf.get('CONSTANT_SETTLING_VELOCITY_CALCULATOR', 'initialisation_method')))\n",
    "\n",
    "\n",
    "# print biological process you used\n",
    "#print('Biological process: {}'.format(cf.get('BIO_MODEL', 'mortality_calculator')))\n",
    "# print mortality method \n",
    "#print('Mortality method: {}'.format(cf.get('FIXED_TIME_MORALITY_CALCULATOR', 'initialisation_method')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10b808",
   "metadata": {},
   "source": [
    "# I am not using part 3-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d5bc1",
   "metadata": {},
   "source": [
    "## 3-Setting Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c1a57",
   "metadata": {},
   "source": [
    "If you use the following config file huron_senseflux_20230103_Seasonal_mortality.cfg, you don't need to run section 5. it is here for demonstration and showing how mortality works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe70479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Imports\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# from matplotlib import pyplot as plt\n",
    "# from configparser import ConfigParser\n",
    "\n",
    "# import pylag.random as random\n",
    "# from pylag.data_reader import DataReader\n",
    "# from pylag.particle_cpp_wrapper import ParticleSmartPtr\n",
    "# from pylag.mortality import get_mortality_calculator\n",
    "# from pylag.processing.plot import create_figure\n",
    "\n",
    "# # Ensure inline plotting\n",
    "# %matplotlib inline\n",
    "\n",
    "# # Parameters\n",
    "# seconds_per_day = 86400.\n",
    "\n",
    "# # Seed the random number generator\n",
    "# random.seed(10)\n",
    "\n",
    "# # Create the config\n",
    "# #cf.add_section('NUMERICS')\n",
    "# cf.add_section('BIO_MODEL')\n",
    "# cf.add_section('FIXED_TIME_MORTALITY_CALCULATOR')\n",
    "# cf.add_section('PROBABILISTIC_MORTALITY_CALCULATOR')\n",
    "# # We need a data reader to pass to the mortality calculator. It\n",
    "# # can be used to draw out environmental variables (e.g. temperature)\n",
    "# # that affect mortality. In both cases below, it isn't used, so we\n",
    "# # use the base class.\n",
    "# data_reader = DataReader()\n",
    "\n",
    "# # Set time stepping params\n",
    "# n_particles = 1000\n",
    "# simulation_duration_in_days = 30.0\n",
    "# time_step = 100\n",
    "# time_end = simulation_duration_in_days * seconds_per_day\n",
    "# times = np.arange(0.0, time_end, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #Helper function in which the model is run and mortality computed\n",
    "# def run(config, n_particles=1000):\n",
    "#     \"\"\" Run the model to compute mortality through time \"\"\"\n",
    "\n",
    "#     # Create the mortality calculator\n",
    "#     mortality_calculator = get_mortality_calculator(config)\n",
    "\n",
    "#     # Create the living particle seed\n",
    "#     particle_set = []\n",
    "#     for i in range(n_particles):\n",
    "#         # Instantiate a new particle\n",
    "#         particle = ParticleSmartPtr(age=0.0, is_alive=True)\n",
    "\n",
    "#         # Initialise particle mortality parameters\n",
    "#         mortality_calculator.set_initial_particle_properties_wrapper(particle)\n",
    "\n",
    "#         # Append it to the particle set\n",
    "#         particle_set.append(particle)\n",
    "\n",
    "#     # Store the number of living particles in a list\n",
    "#     n_alive_arr = []\n",
    "\n",
    "#     # Run the model\n",
    "#     n_alive = n_particles\n",
    "#     for t in times:\n",
    "#         n_alive_arr.append(n_alive)\n",
    "\n",
    "#         n_deaths = 0\n",
    "#         for particle in particle_set:\n",
    "#             if particle.is_alive:\n",
    "#                 mortality_calculator.apply_wrapper(data_reader, t, particle)\n",
    "#                 if particle.is_alive == False:\n",
    "#                     n_deaths += 1\n",
    "#             particle.set_age(t)\n",
    "\n",
    "#         n_alive -= n_deaths\n",
    "\n",
    "#     return n_alive_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a45586",
   "metadata": {},
   "source": [
    "## 4-FixedTimeMortalityCalculater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e25ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify a fixed time mortality calculator\n",
    "# cf.set('BIO_MODEL', 'mortality_calculator', 'fixed_time')\n",
    "\n",
    "# # 1) Fixed time scenario\n",
    "# # Sharp_2021 suggerst 10 days fpr N uptake in coastal wetlands\n",
    "# age_of_death_in_days = 10.\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'initialisation_method', 'common_value')\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'common_value', str(age_of_death_in_days))\n",
    "# n_alive_common_value = run(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2) Uniform Random \n",
    "# minimum_bound = 8.\n",
    "# maximum_bound = 12.\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'initialisation_method', 'uniform_random')\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'minimum_bound', str(minimum_bound))\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'maximum_bound', str(maximum_bound))\n",
    "# n_alive_uniform_random = run(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36099cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2) Gaussian random\n",
    "# mean = 10.\n",
    "# standard_deviation = 1.\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'initialisation_method', 'gaussian_random')\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'mean', str(mean))\n",
    "# cf.set('FIXED_TIME_MORTALITY_CALCULATOR', 'standard_deviation', str(standard_deviation))\n",
    "# n_alive_gaussian_random = run(cf)\n",
    "# # Set the bio time step\n",
    "# cf.set('NUMERICS', 'time_step_bio', str(time_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# font_size = 10\n",
    "# fig, ax = create_figure(figure_size=(20, 20), font_size=font_size)\n",
    "# plt.plot(times/seconds_per_day, n_alive_common_value, 'b', label='common_value')\n",
    "# plt.plot(times/seconds_per_day, n_alive_uniform_random, 'r', label='uniform_random')\n",
    "# plt.plot(times/seconds_per_day, n_alive_gaussian_random, 'g', label='gaussian_random')\n",
    "# # Set the bio time step\n",
    "# plt.ylabel('Living individuals (-)', fontsize=font_size)\n",
    "# plt.xlabel('Time (d)', fontsize=font_size)\n",
    "\n",
    "# # Add legend\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe464e37",
   "metadata": {},
   "source": [
    "## 5-ProabilisticMortalityCalculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d38a60",
   "metadata": {},
   "source": [
    "The mortality calculator kills particles at a rate \n",
    ", where \n",
    " is a fixed mortality rate which is set in the run configuraiton file and \n",
    " is the model time step for biological processes. The model computes a uniform random deviate in the range (0, 1). If the number is less than the computed death rate, the particle is killed. Below, we create a population of \n",
    " individuals. We apply a death rate of \n",
    " per day and use a time step of \n",
    " seconds. The model is run forward for \n",
    " days and the number of living individuals plotted as a function of time. The result is compared with a simple analytical solution of exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67166411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Specify a probabilistic mortality calculator\n",
    "# cf.set('BIO_MODEL', 'mortality_calculator', 'probabilistic')\n",
    "\n",
    "# # Set the death rate - currently the same for all particles.\n",
    "# death_rate_per_day = 0.1\n",
    "# cf.set('PROBABILISTIC_MORTALITY_CALCULATOR', 'death_rate_per_day', str(death_rate_per_day))\n",
    "\n",
    "# # Set the bio time step\n",
    "# cf.set('NUMERICS', 'bio_time_step', str(time_step))\n",
    "\n",
    "# # Number of particles\n",
    "# n_particles = 1000\n",
    "\n",
    "# # Run the model\n",
    "# n_alive_numeric = run(cf, n_particles=n_particles)\n",
    "\n",
    "# # Compute the equivalent analytical solution\n",
    "# death_rate_per_second = death_rate_per_day / seconds_per_day\n",
    "# n_alive_analytic = n_particles * np.exp(-death_rate_per_second * times)\n",
    "\n",
    "# # Plot\n",
    "# font_size = 10\n",
    "# fig, ax = create_figure(figure_size=(20, 20), font_size=font_size)\n",
    "# plt.plot(times/seconds_per_day, n_alive_numeric, 'b', label='numeric')\n",
    "# plt.ylabel('Living individuals (-)', fontsize=font_size)\n",
    "# plt.xlabel('Time (d)', fontsize=font_size)\n",
    "\n",
    "# # Add equivalent analytical solution\n",
    "# plt.plot(times/seconds_per_day, n_alive_analytic, 'r', label='analytic')\n",
    "\n",
    "# # Add legend\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de30a0",
   "metadata": {},
   "source": [
    "# 3-Run the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd344ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chapck the path doesnt have a pylag.cfg file \n",
    "# Check if pylag.cfg exists in the output directory and delete it if present\n",
    "# pylag_cfg_path = os.path.join(output_dir, 'pylag.cfg')\n",
    "\n",
    "# # If the file exists, delete it\n",
    "# if os.path.exists(pylag_cfg_path):\n",
    "#     print(f\"Deleting existing pylag.cfg in {out_dir}\")\n",
    "#     os.remove(pylag_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df8f35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up configuration options\n",
    "cf.set('OCEAN_DATA', 'data_dir', FVCOM_DIR)\n",
    "cf.set('OCEAN_DATA', 'grid_metrics_file', grid_metrics_file_name)\n",
    "\n",
    "# Directory where the simulation outputs will be saved\n",
    "out_dir = f\"{MODELLING_DIR}/output\"\n",
    "cf.set('GENERAL', 'out_dir', out_dir)\n",
    "\n",
    "# Save a copy in the simulation directory\n",
    "with open(f\"{MODELLING_DIR}/pylag.cfg\", 'w') as config:\n",
    "    cf.write(config)\n",
    "    \n",
    "# Save a copy in the output directory\n",
    "#print(f\"Updated configuration and saved to {pylag_cfg_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa15ac87-835d-4b67-b93e-1880b89fe6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting ensemble member 1 ...\n",
      "Progress:\n",
      "Traceback (most recent call last):############## |\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/root/miniforge3/envs/pylag/lib/python3.11/site-packages/pylag/main.py\", line 82, in <module>\n",
      "    main()\n",
      "  File \"/root/miniforge3/envs/pylag/lib/python3.11/site-packages/pylag/main.py\", line 75, in main\n",
      "    simulator.run()\n",
      "  File \"/root/miniforge3/envs/pylag/lib/python3.11/site-packages/pylag/simulator.py\", line 183, in run\n",
      "    pbar.update(abs(self.time_manager.time))\n",
      "  File \"/root/miniforge3/envs/pylag/lib/python3.11/site-packages/progressbar/progressbar.py\", line 250, in update\n",
      "    raise ValueError('Value out of range')\n",
      "ValueError: Value out of range\n"
     ]
    }
   ],
   "source": [
    "# Change to the run directory\n",
    "os.chdir(f\"{MODELLING_DIR}\")\n",
    "\n",
    "# Run the model\n",
    "!{\"python -m pylag.main -c pylag.cfg\"}\n",
    "\n",
    "# Return to the cwd\n",
    "os.chdir(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
