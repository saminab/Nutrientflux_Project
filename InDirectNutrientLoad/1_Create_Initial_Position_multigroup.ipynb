{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Initial Particle Positions:\n",
    "\n",
    "Particles are initialized at the intersection of Lake Huron watersheds with the shoreline.\n",
    "To ensure starting points are within the lake, these intersection points are snapped 50 meters toward the lake.\n",
    "The create initial position module is used to generate multiple particles around each primary starting point for enhanced resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the initial position file using watershed pourpoints\n",
    "The following code read the pour points extracted from Arc gis from the intersection of watersheds with lake huron boundary.\n",
    " We are using PyLag Create initial position function to Create a release Zone for each of the Pour points. Before creating the initial positions, We want to add a condition to make a the relase zone that are in the boundary of Lake Huron.\n",
    " \n",
    " Then using Pylag create initial position file it will create a release zone for each pour point/groupid, in the end each group_id will contain sets of release zone \n",
    " 6/3/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1-1: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box\n",
    "import matplotlib.pyplot as plt\n",
    "from pylag.processing.coordinate import get_epsg_code, utm_from_lonlat, lonlat_from_utm\n",
    "from pylag.processing.coordinate import utm_from_lonlat, lonlat_from_utm\n",
    "from pylag.processing.release_zone import create_release_zones_along_cord\n",
    "from pylag.processing.plot import create_figure, colourmap\n",
    "from pylag.processing.plot import FVCOMPlotter\n",
    "from pylag.processing.release_zone import create_release_zone\n",
    "from pylag.processing.input import create_initial_positions_file_multi_group\n",
    "from pylag.processing.input import create_initial_positions_file_single_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input path/ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to pourpoint \n",
    "pourpoints = r\"/mnt/d/Users/abolmaal/Arcgis/NASAOceanProject/GIS_layer/pourpoints\"\n",
    "\n",
    "init_file = os.path.join(pourpoints, 'Streamwatershedpourpoints_snapped_middleplume.shp')\n",
    "\n",
    "#init_file = os.path.join(pourpoints, 'Streamwatershedpourpoints_snapped_middleplume_Saginaw.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourpoint_dat = os.path.join(pourpoints, 'Streamwatershedpourpoints_NAD1983_buffer_middleplume_morePT.dat')\n",
    "\n",
    "# path to the release zone that intersect to Lake Huron\n",
    "# path to release zone shapefile\n",
    "release_zone_path = r\"/mnt/d/Users/abolmaal/Arcgis/NASAOceanProject/GIS_layer/particle_tracking_output\"\n",
    "intersection = \"initial_positions_releasezone_intersection_middleplume_morePT.shp\"\n",
    "release_zone_intersect = os.path.join(release_zone_path, 'initial_positions_releasezone_intersection_middleplume_morePT.shp')\n",
    "\n",
    "# temporary file to store the release zone\n",
    "\n",
    "temp_out_name = os.path.join(release_zone_path, 'initial_positions_releasezone_middleplume_morePT.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to final output file\n",
    "out_path = '/home/abolmaal/modelling/FVCOM/Huron/input/initial_position'\n",
    "\n",
    "# name of the output file that is multigrouped and ready to be used in FVCOM\n",
    "output_file_initial_releasezone_multigroup = os.path.join(out_path, 'initial_positions_releasezone_intersection_multigroup_middleplume.dat')\n",
    "\n",
    "output_file_initial_releasezone_multigroup_lastrevised= os.path.join(out_path, 'initial_positions_releasezone_intersection_multigroup_middleplume_lastrevised.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evironments\n",
    "create directory/Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part1-2: Read the initial position file(from watreshed and lake intersections) and rename the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters/ temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters to Create release zone\n",
    "# Release zone  \n",
    "radius = 0.006\n",
    "# target number of particles\n",
    "n_particles_target = 100\n",
    "\n",
    "# Release depths\n",
    "depth_below_surface = 0.0\n",
    "\n",
    "# define the watershed number\n",
    "watershed_num = \"group_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the shapefile to a dat file and keeping the required columns\n",
    "# this is the output from arcgis and in this code we are preparing the output to be used for particle tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group_id         lon        lat  depth\n",
      "0         0  275.336267  45.747577      0\n",
      "1         3  275.882160  45.535793      0\n",
      "2         4  276.076128  45.494006      0\n",
      "3         9  276.176836  45.432871      0\n",
      "4        10  276.285434  45.418564      0\n"
     ]
    }
   ],
   "source": [
    "# read the pourpoint shapefile\n",
    "df_pourpoint = gpd.read_file(init_file)\n",
    "# print the first 5 rows\n",
    "# rename the columns POINT_X and POINT_Y to lat and lon\n",
    "df_pourpoint_copy = df_pourpoint.rename(columns={'POINT_X': 'lon', 'POINT_Y': 'lat'})\n",
    "# add a new column called deoth and set it to 0\n",
    "df_pourpoint_copy['depth'] = 0\n",
    "\n",
    "# conver the crs to lonlat\n",
    "df_pourpoint_copy = df_pourpoint_copy.to_crs(epsg=4326)\n",
    "\n",
    "# conver columns lon and lat to epsg 4326\n",
    "df_pourpoint_copy['lon'] = df_pourpoint_copy['geometry'].x\n",
    "df_pourpoint_copy['lat'] = df_pourpoint_copy['geometry'].y\n",
    "\n",
    "# if column lon is not in the range of -180 to 0, then convert it to the range of 0 to 360\n",
    "df_pourpoint_copy.loc[df_pourpoint_copy['lon'] < 0, 'lon'] = df_pourpoint_copy.loc[df_pourpoint_copy['lon'] < 0, 'lon'] + 360\n",
    "df_pourpoint_copy = df_pourpoint_copy[['Group_id', 'lon', 'lat', 'depth']]\n",
    "\n",
    "\n",
    "print(df_pourpoint_copy.head())\n",
    "\n",
    "# save the lon and lat with only four decimal points\n",
    "df_pourpoint_copy['lon'] = df_pourpoint_copy['lon'].round(4)\n",
    "df_pourpoint_copy['lat'] = df_pourpoint_copy['lat'].round(4)\n",
    "\n",
    "# save the pourpoint file to a dat file with one space as a separator\n",
    "df_pourpoint_copy.to_csv(pourpoint_dat, sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>275.3363</td>\n",
       "      <td>45.7476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>275.8822</td>\n",
       "      <td>45.5358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>276.0761</td>\n",
       "      <td>45.4940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>276.1768</td>\n",
       "      <td>45.4329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>276.2854</td>\n",
       "      <td>45.4186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>144</td>\n",
       "      <td>277.5285</td>\n",
       "      <td>43.1226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>145</td>\n",
       "      <td>277.5489</td>\n",
       "      <td>43.0819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>146</td>\n",
       "      <td>277.5618</td>\n",
       "      <td>43.0711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>147</td>\n",
       "      <td>277.5855</td>\n",
       "      <td>43.0251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>162</td>\n",
       "      <td>276.1489</td>\n",
       "      <td>43.6543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group_id       lon      lat  depth\n",
       "0           0  275.3363  45.7476      0\n",
       "1           3  275.8822  45.5358      0\n",
       "2           4  276.0761  45.4940      0\n",
       "3           9  276.1768  45.4329      0\n",
       "4          10  276.2854  45.4186      0\n",
       "..        ...       ...      ...    ...\n",
       "109       144  277.5285  43.1226      0\n",
       "110       145  277.5489  43.0819      0\n",
       "111       146  277.5618  43.0711      0\n",
       "112       147  277.5855  43.0251      0\n",
       "113       162  276.1489  43.6543      0\n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the pouropoints file\n",
    "\n",
    "df_pourpoint = pd.read_csv(pourpoint_dat, skiprows=0,sep=' ',header=None)\n",
    "# rename the columns\n",
    "df_pourpoint.rename(columns={0: \"Group_id\", 1:\"lon\",2:\"lat\",3:\"depth\"}, inplace=True)\n",
    "df_pourpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a release zone and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to accumulate release zones\n",
    "release_zones = []\n",
    "\n",
    "# Loop through the rows of the DataFrame\n",
    "for index, row in df_pourpoint.iterrows():\n",
    "    group_id = row['Group_id']\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    \n",
    "    # Create the release zone\n",
    "    surface_release_zone = create_release_zone(group_id = group_id,\n",
    "                                           radius = radius,\n",
    "                                           centre = [lon, lat],\n",
    "                                           n_particles = n_particles_target,\n",
    "                                           depth = depth_below_surface,\n",
    "                                           random = False)\n",
    "    \n",
    "    # accumulate the release zones\n",
    "    release_zones.append(surface_release_zone)\n",
    "    \n",
    "\n",
    "# Write data to file\n",
    "create_initial_positions_file_multi_group(output_file_initial_releasezone_multigroup, release_zones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/abolmaal/modelling/FVCOM/Huron/input/initial_position/initial_positions_releasezone_intersection_multigroup_middleplume.dat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_initial_releasezone_multigroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I save the initial position file as shape file and I used arcpy to remove the points that are not inside Lake Huron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output_file_initial_releasezone_multigroup as shapefile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for removing the points is in InDirectNutrientLoad_Arcpy directory and it's called Initial_position_removeoutsidelakepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_positions = output_file_initial_releasezone_multigroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the output file\n",
    "df_initial_positions = pd.read_csv(initial_positions, sep=' ', header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total particles: 8550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>275.3339</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>275.3351</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>275.3363</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>275.3375</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>275.3387</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group_id       lon      lat  depth\n",
       "0         0  275.3339  45.7428      0\n",
       "1         0  275.3351  45.7428      0\n",
       "2         0  275.3363  45.7428      0\n",
       "3         0  275.3375  45.7428      0\n",
       "4         0  275.3387  45.7428      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "df_initial_positions.rename(columns={0: \"Group_id\", 1:\"lon\",2:\"lat\",3:\"depth\"}, inplace=True)\n",
    "\n",
    "# round the lon and lat to 4 decimal points\n",
    "df_initial_positions['lon'] = df_initial_positions['lon'].round(4)\n",
    "df_initial_positions['lat'] = df_initial_positions['lat'].round(4)\n",
    "\n",
    "# group_id to integer\n",
    "df_initial_positions['Group_id'] = df_initial_positions['Group_id'].astype(int)\n",
    "# depth integer\n",
    "df_initial_positions['depth'] = df_initial_positions['depth'].astype(int)\n",
    "# Calculate the total number of particles\n",
    "n_particles_target = df_initial_positions['Group_id'].count()\n",
    "\n",
    "# Display `n_particles_target` as part of the header information\n",
    "print(f\"# Total particles: {n_particles_target}\")\n",
    "df_initial_positions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of particles\n",
    "n_particles_target = len(df_initial_positions)\n",
    "\n",
    "# Save: first row = total count, then data rows with no header/index\n",
    "out_name = os.path.join(out_path, 'initial_positions_releasezone_intersection_multigroup_middleplume_final.dat')\n",
    "\n",
    "with open(out_name, \"w\") as f:\n",
    "    f.write(f\"{n_particles_target}\\n\")\n",
    "df_initial_positions.to_csv(\n",
    "    out_name,\n",
    "    mode=\"a\",\n",
    "    sep=\" \",          # use \",\" for CSV if you want\n",
    "    header=False,\n",
    "    index=False,\n",
    "    float_format=\"%.4f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the out_file_initial_releasezone_multigroup_lastrevised to a shapefile\n",
    "# read the output file\n",
    "df_initial_positions = pd.read_csv(output_file_initial_releasezone_multigroup, sep=' ', header=None, skiprows=1)\n",
    "# Rename the columns\n",
    "df_initial_positions.rename(columns={0: \"Group_id\", 1:\"lon\",2:\"lat\",3:\"depth\"}, inplace=True)\n",
    "# round the lon and lat to 4 decimal points\n",
    "df_initial_positions['lon'] = df_initial_positions['lon'].round(4)\n",
    "df_initial_positions['lat'] = df_initial_positions['lat'].round(4)\n",
    "# group_id to integer\n",
    "df_initial_positions['Group_id'] = df_initial_positions['Group_id'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_initial_positions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['lon'] = df_temp['lon'] -360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-84.6661</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-84.6649</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-84.6637</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-84.6625</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-84.6613</td>\n",
       "      <td>45.7428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8545</th>\n",
       "      <td>162</td>\n",
       "      <td>-83.8535</td>\n",
       "      <td>43.6591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8546</th>\n",
       "      <td>162</td>\n",
       "      <td>-83.8523</td>\n",
       "      <td>43.6591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8547</th>\n",
       "      <td>162</td>\n",
       "      <td>-83.8511</td>\n",
       "      <td>43.6591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8548</th>\n",
       "      <td>162</td>\n",
       "      <td>-83.8499</td>\n",
       "      <td>43.6591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>162</td>\n",
       "      <td>-83.8487</td>\n",
       "      <td>43.6591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group_id      lon      lat  depth\n",
       "0            0 -84.6661  45.7428    0.0\n",
       "1            0 -84.6649  45.7428    0.0\n",
       "2            0 -84.6637  45.7428    0.0\n",
       "3            0 -84.6625  45.7428    0.0\n",
       "4            0 -84.6613  45.7428    0.0\n",
       "...        ...      ...      ...    ...\n",
       "8545       162 -83.8535  43.6591    0.0\n",
       "8546       162 -83.8523  43.6591    0.0\n",
       "8547       162 -83.8511  43.6591    0.0\n",
       "8548       162 -83.8499  43.6591    0.0\n",
       "8549       162 -83.8487  43.6591    0.0\n",
       "\n",
       "[8550 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note define this top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a shapefile in temp_out directory with temp_out_name\n",
    "gdf = gpd.GeoDataFrame(df_temp, geometry=gpd.points_from_xy(df_temp.lon, df_temp.lat))\n",
    "# this is written as WGS84\n",
    "gdf.crs = 'EPSG:4326'\n",
    "gdf.to_file(temp_out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/Users/abolmaal/Arcgis/NASAOceanProject/GIS_layer/particle_tracking_output/initial_positions_releasezone_middleplume_morePT.shp'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_out_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Solve an error related to PyLag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Lat and lon number has more than 10 digits and when I run it through Pylag it gives me this error:ValueError: invalid literal for int() with base 10: '0.0' so to avoid this I want to read Lat and Lon and round them by 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I removed the points outside Lake Boundary I read the cleaned point here again \n",
    "- make sure Longitudes are in 360 degree \n",
    "- Lat and Lon are rounded to 10 \n",
    "- Save the file as dat file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the release zone shapefile that intersect with Lake Huron\n",
    "release_zone_intersect = gpd.read_file(release_zone_intersect)\n",
    "release_zone_intersect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the group_id, lon, lat, and depth columns\n",
    "release_zone_intersect = release_zone_intersect[['group_id', 'lon', 'lat', 'depth']]\n",
    "# sort the data from group_id\n",
    "release_zone_intersect = release_zone_intersect.sort_values(by=[watershed_num])\n",
    "# if df[lon] and df[lat] are greater than 10 digits round them to 10 digits\n",
    "release_zone_intersect['lon'] = release_zone_intersect['lon'].round(10)\n",
    "release_zone_intersect['lat'] = release_zone_intersect['lat'].round(10)\n",
    "# group_id to integer\n",
    "release_zone_intersect['group_id'] = release_zone_intersect['group_id'].astype(int)\n",
    "# depth integer\n",
    "release_zone_intersect['depth'] = release_zone_intersect['depth'].astype(int)\n",
    "# Calculate the total number of particles\n",
    "n_particles_target = release_zone_intersect['group_id'].count()\n",
    "\n",
    "# Display `n_particles_target` as part of the header information\n",
    "print(f\"# Total particles: {n_particles_target}\")\n",
    "release_zone_intersect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write only the total number of particles as the header and data without column names\n",
    "with open(output_file_initial_releasezone_multigroup, 'w') as file:\n",
    "    # Write the total number of particles as the header\n",
    "    file.write(f\"{n_particles_target}\\n\")\n",
    "    # Write the data without headers\n",
    "    release_zone_intersect.to_csv(file,sep=' ' ,index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylag_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
