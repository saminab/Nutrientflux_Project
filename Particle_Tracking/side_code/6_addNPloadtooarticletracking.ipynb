{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have this netcdf files one the variable this file has is group_id, and I have a csv that also has group_id coulmn and another coulmn called WetLoad_TN_kg2 and WetLoad_TP_kg2 how I can add the values of WetLoad to nercdf file with the corresponding group_id in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign the values of WetLoad_TN_kg2 and WetLoad_TP_kg2 from your CSV to the NetCDF files, while distributing them equally across the occurrences of each group_id, you can do the following:\n",
    "\n",
    "For each group_id, count how many times it appears in the NetCDF dataset.\n",
    "Divide the corresponding WetLoad_TN_kg2 and WetLoad_TP_kg2 values from the CSV by the number of occurrences of that group_id.\n",
    "Assign the divided values back to the NetCDF file for each occurrence of the group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm\n",
    "import re \n",
    "import pylag\n",
    "from shapely.geometry import Point\n",
    "import contextily as ctx\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the data directory\n",
    "data_dir = '/home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output'\n",
    "# Define the sort_key function to sort files by number in the filename\n",
    "def sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "    number = int(filename.split('__')[1].split('.')[0])\n",
    "    return number\n",
    "\n",
    "csv_file_path  = '/mnt/d/Users/abolmaal/Arcgis/NASAOceanProject/ZonalStats/StreamWatresheds_total_N_P.csv'\n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "# Ensure the CSV contains the necessary columns\n",
    "if 'Group_id' not in csv_data.columns or 'WetLoad_TN_kg2' not in csv_data.columns or 'WetLoad_TP_kg2' not in csv_data.columns:\n",
    "    raise ValueError(\"CSV file is missing required columns: 'Group_id', 'WetLoad_TN_kg2', 'WetLoad_TP_kg2'\")\n",
    "\n",
    "# Rename 'Group_id' to 'group_id' in the CSV to match the NetCDF data\n",
    "csv_data.rename(columns={'Group_id': 'group_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Jan__1.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Feb__2.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Mar__3.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Apr__4.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_May__5.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Jun__6.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_July__7.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Aug__8.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Sep__9.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Oct__10.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Nov__11.nc\n",
      "Updated NetCDF file saved: /home/abolmaal/data/FVCOME_OUTPUT/Simulations/Huron/output/updated_Fvcome_huron_estuary_2023_Winter_Dec__12.nc\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(os.path.join(data_dir, 'Fvcome_huron_estuary_2023_Winter_*.nc'))\n",
    "files.sort(key=sort_key)\n",
    "\n",
    "# Loop through each file, load it, merge the WetLoad data, and save the updated NetCDF file\n",
    "for file in files:\n",
    "    # Read the NetCDF file\n",
    "    ds = xr.open_dataset(file)\n",
    "\n",
    "    # Convert the NetCDF 'group_id' variable to a DataFrame for processing\n",
    "    netcdf_df = ds['group_id'].to_dataframe().reset_index()\n",
    "\n",
    "    # Step 1: Count occurrences of each group_id in the NetCDF file\n",
    "    group_counts = netcdf_df['group_id'].value_counts().to_dict()\n",
    "\n",
    "    # Step 2: Merge the CSV data with the NetCDF data on 'group_id'\n",
    "    merged_df = pd.merge(netcdf_df, csv_data, on='group_id', how='left')\n",
    "\n",
    "    # Step 3: For each group_id, divide the WetLoad_TN_kg2 and WetLoad_TP_kg2 values by the count of that group_id\n",
    "    merged_df['WetLoad_TN_kg2'] = merged_df.apply(\n",
    "        lambda row: row['WetLoad_TN_kg2'] / group_counts[row['group_id']] if pd.notnull(row['WetLoad_TN_kg2']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    merged_df['WetLoad_TP_kg2'] = merged_df.apply(\n",
    "        lambda row: row['WetLoad_TP_kg2'] / group_counts[row['group_id']] if pd.notnull(row['WetLoad_TP_kg2']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Step 4: Add the updated WetLoad_TN_kg2 and WetLoad_TP_kg2 columns back into the NetCDF dataset\n",
    "    ds['WetLoad_TN_kg2'] = (('dim_0'), merged_df['WetLoad_TN_kg2'].values)  # Replace 'dim_0' with the correct dimension\n",
    "    ds['WetLoad_TP_kg2'] = (('dim_0'), merged_df['WetLoad_TP_kg2'].values)\n",
    "\n",
    "    # Step 5: Save the updated NetCDF file\n",
    "    output_file_path = os.path.join(data_dir, f\"updated_{os.path.basename(file)}\")\n",
    "    ds.to_netcdf(output_file_path)\n",
    "\n",
    "    print(f\"Updated NetCDF file saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<xarray.Dataset>\n",
      "Dimensions:                   (time: 121, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-01-01 ... 2023-01-31\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 105, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-02-01 ... 2023-02-27\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 121, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-03-01 ... 2023-03-31\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 117, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-04-01 ... 2023-04-30\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 121, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-05-01 ... 2023-05-31\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 117, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-06-01 ... 2023-06-30\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 121, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-07-01 ... 2023-07-31\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 111, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-08-02T18:00:00 ... 2...\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 117, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-09-01 ... 2023-09-30\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 121, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-10-01 ... 2023-10-31\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 42, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-11-19T18:00:00 ... 2...\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory, <xarray.Dataset>\n",
      "Dimensions:                   (time: 121, particles: 4950, dim_0: 4950)\n",
      "Coordinates:\n",
      "  * time                      (time) datetime64[ns] 2023-12-01 ... 2023-12-31\n",
      "Dimensions without coordinates: particles, dim_0\n",
      "Data variables: (12/13)\n",
      "    group_id                  (particles) int32 ...\n",
      "    longitude                 (time, particles) float32 ...\n",
      "    latitude                  (time, particles) float32 ...\n",
      "    depth                     (time, particles) float32 ...\n",
      "    host_fvcom                (time, particles) int32 ...\n",
      "    error_status              (time, particles) int32 ...\n",
      "    ...                        ...\n",
      "    is_beached                (time, particles) int32 ...\n",
      "    land_boundary_encounters  (time, particles) int32 ...\n",
      "    thetao                    (time, particles) float32 ...\n",
      "    so                        (time, particles) float32 ...\n",
      "    WetLoad_TN_kg2            (dim_0) float64 ...\n",
      "    WetLoad_TP_kg2            (dim_0) float64 ...\n",
      "Attributes:\n",
      "    title:    PyLag -- Plymouth Marine Laboratory]\n"
     ]
    }
   ],
   "source": [
    "# Load the updated NetCDF files\n",
    "updated_files = glob.glob(os.path.join(data_dir, 'updated_Fvcome_huron_estuary_2023_Winter_*.nc'))\n",
    "updated_files.sort(key=sort_key)\n",
    "\n",
    "# read all the files and concatenate them into a single xarray datase\n",
    "updated_ds = [xr.open_dataset(file) for file in updated_files]\n",
    "print(updated_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'updated_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mupdated_ds\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Check if group_id exists\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_id\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ds:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Step 1: Filter the dataset for group_id == 1 before converting to a DataFrame\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'updated_ds' is not defined"
     ]
    }
   ],
   "source": [
    "ds = updated_ds[0]\n",
    "# Check if group_id exists\n",
    "if 'group_id' in ds:\n",
    "    # Step 1: Filter the dataset for group_id == 1 before converting to a DataFrame\n",
    "    ds_group_1 = ds.where(ds['group_id'] == 0, drop=True)\n",
    "\n",
    "    # Step 2: Convert filtered data to DataFrame\n",
    "    netcdf_df = ds_group_1.to_dataframe().reset_index()\n",
    "\n",
    "    # Step 3: Extract the WetLoad_TN_kg2 and WetLoad_TP_kg2 values for group_id == 1\n",
    "    wetload_tn = netcdf_df['WetLoad_TN_kg2'].values\n",
    "    wetload_tp = netcdf_df['WetLoad_TP_kg2'].values\n",
    "\n",
    "    # Step 4: Create the plot for WetLoad_TN_kg2 and WetLoad_TP_kg2\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot WetLoad_TN_kg2\n",
    "    plt.plot(wetload_tn, label='WetLoad_TN_kg2')\n",
    "\n",
    "    # Plot WetLoad_TP_kg2\n",
    "    plt.plot(wetload_tp, label='WetLoad_TP_kg2')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('WetLoad TN and TP for group_id = 1')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('WetLoad (kg2)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "     print(\"group_id not found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of group_id == 1: <xarray.DataArray 'group_id' ()>\n",
      "array(42)\n"
     ]
    }
   ],
   "source": [
    "# count the number of group_id that is equal to 1\n",
    "group_count = ds['group_id'].where(ds['group_id'] == 0).count()\n",
    "print(f\"Number of group_id == 1: {group_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2390048929415335e-08\n"
     ]
    }
   ],
   "source": [
    "a= 5.20382055035444E-07/42\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we want to only keep the values that return to Coastal wetlands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
