{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1- Realease the particles (2_PT_seseflux)\n",
    "\n",
    "2- Read the particles for each month \n",
    "\n",
    "3- Reduce to first particles intersection to coastline, delete the ones that does not interact with coastline \n",
    "\n",
    "4- Make a dataframe that only include the particles first intersect with the shoreline for each month \n",
    "\n",
    "-(another thing we need to add is to add a group_number to the particles in addition that group_id like 11, 12, 13, code 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "# Data manipulation and analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from netCDF4 import Dataset\n",
    "# geopandas \n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "# Dask diagnostics and progress bar\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm\n",
    "import cartopy.crs as ccrs\n",
    "from pylag.processing.plot import FVCOMPlotter, create_figure, colourmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to sort the files based on the time\n",
    "def sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        # Extract the number after the double underscores and before the `.nc` extension\n",
    "        number = int(filename.split('_')[-1].split('.')[0])\n",
    "        return number\n",
    "    except (IndexError, ValueError):\n",
    "        # Handle filenames that do not match the pattern by returning a high number to place them last\n",
    "        return float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(file):\n",
    "    filename = os.path.basename(file)\n",
    "\n",
    "    # ‚úÖ Debugging: Print filename to check if it's correct\n",
    "    print(f\"üîç Sorting file: {filename}\")\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ Extract the numeric part after the last underscore `_`\n",
    "        parts = filename.split(\"_\")\n",
    "        number_part = parts[-1].split('.')[0]  # Get the last part before .nc\n",
    "\n",
    "        number = int(number_part)  # Convert to integer\n",
    "        print(f\"‚úÖ Extracted number: {number} from {filename}\")\n",
    "        return number\n",
    "\n",
    "    except (IndexError, ValueError) as e:\n",
    "        print(f\"‚ùå ERROR processing filename '{filename}': {e}\")\n",
    "        return float('inf')  # Move problematic files to the end of sorting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for coastal wetland shapefiles\n",
    "GIS_LAYERS = '/home/abolmaal/Data/GIS_layer'  # Add leading slash to make it an absolute path\n",
    "CW_path = os.path.join(GIS_LAYERS, 'Coastalwetland/hitshoreline')\n",
    "\n",
    "#CW_path = '/mnt/d/Users/abolmaal/Arcgis/NASAOceanProject/GIS_layer/Coastalwetland/hitshoreline/'\n",
    "\n",
    "# Paths to specific coastal wetland shapefiles with different inundation levels that have 50 meter buffer from the shoreline\n",
    "CW_avg_path = os.path.join(CW_path, 'Wetland_connected_avg_inundation_NAD1983_shorelineinteraction_50m_ExportFeatures.shp')\n",
    "CW_low_path = os.path.join(CW_path, 'wetlands_connected_low_inundation_NAD1983_shorelineinteraction_50m_ExportFeatures.shp')\n",
    "CW_high_path = os.path.join(CW_path, 'wetlands_connected_high_inundation_NAD1983_shorelineinteraction_50m_ExportFeatures.shp')\n",
    "CW_surge_path = os.path.join(CW_path, 'wetlands_connected_surge_inundation_NAD1983_shorelineinteraction_50m_ExportFeatures.shp')\n",
    "\n",
    "# Load coastal wetland shapefiles as GeoDataFrames\n",
    "CW_avg = gpd.read_file(CW_avg_path)\n",
    "CW_low = gpd.read_file(CW_low_path)\n",
    "CW_high = gpd.read_file(CW_high_path)\n",
    "CW_surge = gpd.read_file(CW_surge_path)\n",
    "\n",
    "# Define the path to FVCOM model output files\n",
    "data_dir = '/home/abolmaal/modelling/FVCOM/Huron/output'\n",
    "files = glob.glob(os.path.join(data_dir, \"updated_FVCOM_Huron_*.nc\"))\n",
    "files.sort(key=sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If time range in the FVCOM outputs overlap we need to remove the times overlap/if not we will use this methid for reading datasets = xr.open_mfdataset(files, combine='by_coords', parallel=True)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the files list is sorted before iterating\n",
    "files.sort(key=sort_key)\n",
    "\n",
    "for file in files:\n",
    "    with xr.open_dataset(file) as ds:\n",
    "        if 'time' in ds.variables:\n",
    "            print(f\"File: {file} - Time range: {ds['time'].values[0]} to {ds['time'].values[-1]}\")\n",
    "        else:\n",
    "            print(f\"File: {file} - No 'time' variable found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overlap(datasets):\n",
    "    # Remove the first time step of each dataset except for the first one\n",
    "    datasets[1:] = [ds.sel(time=slice(ds['time'][1], None)) for ds in datasets[1:]]\n",
    "    return datasets\n",
    "\n",
    "# Apply to datasets\n",
    "datasets = [xr.open_dataset(file) for file in files]\n",
    "datasets = remove_overlap(datasets)\n",
    "\n",
    "# Now you can combine them\n",
    "datasets = xr.concat(datasets, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the FVCOM output files\n",
    "# Open multiple NetCDF datasets with xarray, using chunks and parallel processing\n",
    "#datasets = xr.open_mfdataset(files, combine='by_coords', parallel=True)\n",
    "\n",
    "# Define the path to the FVCOM grid metrics file\n",
    "grid_metrics_file_name = '/home/abolmaal/modelling/FVCOM/Huron/input/gridfile/grid_metrics_huron_senseflux_Seasonal.nc'\n",
    "\n",
    "\n",
    "# Path to nutrient load data CSV and load the CSV\n",
    "Direct_Nutrient_load = '/mnt/d/Users/abolmaal/Arcgis/NASAOceanProject/ZonalStats/StreamWatresheds_total_N_P.csv'\n",
    "Direct_Nutrient = pd.read_csv(Direct_Nutrient_load)\n",
    "\n",
    "# Check and rename columns in the CSV file to match NetCDF data requirements\n",
    "required_columns = {'Group_id': 'group_id', 'WetLoad_TN_kgcellday': 'WetLoad_TN_kgcellday', 'WetLoad_TP_kgcellday': 'WetLoad_TP_kgcellday'}\n",
    "\n",
    "# for col, new_col in required_columns.items():\n",
    "# if col not in Direct_Nutrient.columns:\n",
    "#         raise ValueError(f\"CSV file is missing required column: '{col}'\")\n",
    "# Direct_Nutrient.rename(columns={'Group_id': 'group_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/home/abolmaal/modelling/FVCOM/Huron/results'\n",
    "output_figures = '/home/abolmaal/modelling/FVCOM/Huron/figures'\n",
    "\n",
    "# Define the file names to the FVCOM model output\n",
    "originalFVCOM = 'LakeHuronparticletracking_2023_original.shp'\n",
    "\n",
    "\n",
    "# file name for Intersected FVCOM model output with coastal wetlands\n",
    "\n",
    "Intersection_PTCW_Avg = 'Intersections_Avg_PTCW.csv'\n",
    "Intersection_PTCW_high = 'Intersections_high_PTCW.csv'\n",
    "Intersection_PTCW_low = 'Intersections_low_PTCW.csv'\n",
    "Intersection_PTCW_surge = 'Intersections_surge_PTCW.csv'\n",
    "###################################################################\n",
    "GroupIdcount = 'group_id_counts.csv'\n",
    "Non_Intersection_avg = 'Non_Intersection_avg.csv'\n",
    "Non_Intersection_high = 'Non_Intersection_high.csv'\n",
    "Non_Intersection_low = 'Non_Intersection_low.csv'\n",
    "Non_Intersection_surge = 'Non_Intersection_surge.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure parameters\n",
    "# Custom colormap setup (pink and blue shades)\n",
    "pink_shades = ['#fff5f7', '#ffebf0', '#ffd6e1', '#ffbfd4', '#ff99c1', '#ff6ea9', '#ff4c92', '#ff2171', '#b50d4e']\n",
    "blue_shades = ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594']\n",
    "blue_shades_reversed = blue_shades[::-1]\n",
    "\n",
    "pink_cmap = LinearSegmentedColormap.from_list('custom_pink', pink_shades)\n",
    "blue_cmap_reversed = LinearSegmentedColormap.from_list('custom_blue', blue_shades)\n",
    "\n",
    "# Define a list of green shades for the colormap\n",
    "green_shades =  ['#e0ffe0', '#b3ffb3', '#80ff80', '#4dff4d', '#00e600', '#00cc00', '#009900', '#006600', '#003300']\n",
    "# Create a custom green colormap\n",
    "green_cmap = LinearSegmentedColormap.from_list('custom_green', green_shades)\n",
    "\n",
    "# Replace pink_cmap with viridis and plasma\n",
    "viridis_cmap = plt.colormaps['viridis']  # Updated to use new interface\n",
    "plasma_cmap = plt.colormaps['plasma']  # Updated to use new interface\n",
    "\n",
    "# Set up plotting parameters\n",
    "font_size = 15\n",
    "cmap = plt.colormaps['hsv_r']  # Fixed: using an existing colormap (hsv_r)\n",
    "\n",
    "# Extent of the plot\n",
    "extents = np.array([275, 277.69, 43, 46.3], dtype=float)\n",
    "\n",
    "extents_ausable = np.array([276.5, 276.8, 45, 45.5], dtype=float)\n",
    "\n",
    "# Some parameters for the Zonal Stats Fields\n",
    "# Fields to calculate / Direct delivery to Watersheds\n",
    "fieldDirectTN = 'WetLoad_TN_kgcellday'\n",
    "fieldDirectTP = 'WetLoad_TP_kgcellday'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Make a geodataframe for particle tracking output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.delayed import delayed\n",
    "import xarray as xr\n",
    "from shapely.geometry import Point\n",
    "import dask  # Import Dask to access dask.compute\n",
    "from dask import compute  # Import the specific compute function\n",
    "import gc  # To manually collect garbage and free up memory\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "# Limit the number of workers and threads\n",
    "client = Client(n_workers=2, threads_per_worker=2)  # Adjust as needed\n",
    "\n",
    "print(client)\n",
    "# Function to remove overlap in time\n",
    "def remove_overlap(datasets):\n",
    "    # Remove the first time step of each dataset except for the first one\n",
    "    datasets[1:] = [ds.sel(time=slice(ds['time'][1], None)) for ds in datasets[1:]]\n",
    "    return datasets\n",
    "\n",
    "# Function to process a single file and convert to GeoDataFrame\n",
    "@delayed\n",
    "def process_file(file):\n",
    "    # Open the dataset lazily with xarray (no data loaded yet)\n",
    "    with xr.open_dataset(file) as ds:\n",
    "        selected_vars = ds[['time', 'group_id', 'group_number', 'longitude', 'latitude']]\n",
    "\n",
    "        # Perform operations like longitude correction\n",
    "        selected_vars['longitude'].values = np.where(selected_vars['longitude'].values > 180, \n",
    "                                                     selected_vars['longitude'].values - 360, \n",
    "                                                     selected_vars['longitude'].values)\n",
    "\n",
    "        # Convert xarray to pandas dataframe\n",
    "        PT_df = selected_vars.to_dataframe().reset_index()\n",
    "\n",
    "        # Create GeoDataFrame from the DataFrame\n",
    "        PT_gdf = gpd.GeoDataFrame(PT_df, geometry=gpd.GeoSeries.from_xy(PT_df['longitude'], PT_df['latitude']))\n",
    "\n",
    "        # Set the CRS and reproject if necessary\n",
    "        PT_gdf.set_crs('EPSG:4326', inplace=True, allow_override=True)\n",
    "        PT_gdf = PT_gdf.to_crs('EPSG:3174')\n",
    "\n",
    "        # Release memory after processing the dataset\n",
    "        del ds, selected_vars, PT_df  # Delete variables no longer needed\n",
    "        gc.collect()  # Force garbage collection to release memory\n",
    "\n",
    "        return PT_gdf\n",
    "\n",
    "# Use dask.delayed to process each file (process files in smaller batches to avoid memory overload)\n",
    "batch_size = 2  # Process in smaller batches of 2 files at a time\n",
    "batches = [files[i:i + batch_size] for i in range(0, len(files), batch_size)]\n",
    "\n",
    "all_gdfs = []\n",
    "\n",
    "# Process each batch separately\n",
    "for batch in batches:\n",
    "    all_delayed = [process_file(file) for file in batch]\n",
    "    batch_gdfs = compute(*all_delayed)  # Use dask.compute here\n",
    "    all_gdfs.extend(batch_gdfs)  # Append the GeoDataFrames from this batch\n",
    "\n",
    "    # Manually trigger garbage collection after each batch to release memory\n",
    "    gc.collect()\n",
    "\n",
    "# Now combine the GeoDataFrames from all batches into one\n",
    "final_gdf = pd.concat(all_gdfs, ignore_index=True)\n",
    "\n",
    "# Set final CRS if necessary\n",
    "#final_gdf.set_crs('EPSG:4326', inplace=True, allow_override=True)\n",
    "#final_gdf = final_gdf.to_crs('EPSG:3174')\n",
    "\n",
    "# Final GeoDataFrame with all datasets\n",
    "print(final_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the crs of the final_gdf\n",
    "print(\"Final GeoDataFrame CRS:\", final_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress FutureWarnings related to pandas unique\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xarray\")\n",
    "\n",
    "# Select relevant variables: time, group_id, group_number, longitude, latitude\n",
    "selected_vars = datasets[['time', 'group_id', 'group_number','longitude', 'latitude']]\n",
    "\n",
    "# Stack across 'time' and 'particles', dropping unwanted dimensions\n",
    "#stacked_data = selected_vars.stack(particle_time=('time', 'particles')).drop_dims('dim_0', errors='ignore')\n",
    "\n",
    "# Stack across 'time' and 'particles', dropping unwanted dimensions\n",
    "stacked_vars = selected_vars.stack(particle_time=('time', 'particles'))\n",
    "# Convert longitudes greater than 180 to the range -180 to 180\n",
    "\n",
    "# If longitude values are greater than 180, subtract 360 to convert them to the range -180 to 180\n",
    "selected_vars['longitude'].values = np.where(selected_vars['longitude'].values > 180, \n",
    "                                             selected_vars['longitude'].values - 360, \n",
    "                                             selected_vars['longitude'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert selected variable to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataframe to geodataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your Pandas DataFrame to a Dask DataFrame\n",
    "PT_ddf = dd.from_pandas(PT_df, npartitions=2)  # Partition based on the number of cores\n",
    "\n",
    "# Function to create geometry using GeoSeries.from_xy (efficient and vectorized)\n",
    "def create_geometry(df):\n",
    "    return gpd.GeoSeries.from_xy(df['longitude'], df['latitude'])\n",
    "\n",
    "# Apply the function to create the geometry in each partition\n",
    "PT_ddf['geometry'] = PT_ddf.map_partitions(create_geometry)\n",
    "\n",
    "# Convert Dask DataFrame to GeoDataFrame (compute the result)\n",
    "PT_gdf = gpd.GeoDataFrame(PT_ddf.compute(), geometry='geometry')\n",
    "\n",
    "# Set CRS to EPSG:4326\n",
    "PT_gdf.set_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "# Convert CRS to EPSG:3174 for Great Lakes Albers\n",
    "PT_gdf = PT_gdf.to_crs('EPSG:3174')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that longitude and latitude are valid\n",
    "PT_df = PT_df.dropna(subset=['longitude', 'latitude'])\n",
    "\n",
    "# Create geometry from valid points\n",
    "geometry = [Point(xy) for xy in zip(PT_df['longitude'], PT_df['latitude'])]\n",
    "\n",
    "# Create GeoDataFrame\n",
    "PT_gdf = gpd.GeoDataFrame(PT_df, geometry=geometry)\n",
    "\n",
    "# Set CRS to EPSG:4326\n",
    "PT_gdf.set_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "# Convert CRS to EPSG:3174 for Great Lakes Albers\n",
    "PT_gdf.to_crs('EPSG:3174', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_gdf = final_gdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'time' column is in datetime format\n",
    "PT_df['time'] = pd.to_datetime(PT_df['time'], errors='coerce')\n",
    "\n",
    "# Extract the month from the 'time' column\n",
    "PT_df['month'] = PT_df['time'].dt.month\n",
    "\n",
    "# Convert 'group_id' to integer (ensure the 'group_id' column exists and is valid)\n",
    "PT_df['group_id'] = PT_df['group_id'].astype(int)\n",
    "\n",
    "# Count the unique 'group_id' in each month\n",
    "group_id_counts = PT_df.groupby('month')['group_id'].nunique().reset_index(name='unique_group_count')\n",
    "\n",
    "# Create a DataFrame with all months (1 through 12)\n",
    "all_months = pd.DataFrame({'month': range(1, 13)})\n",
    "\n",
    "# Merge the result with all months to ensure all months are shown\n",
    "group_id_counts_full = pd.merge(all_months, group_id_counts, on='month', how='left').fillna({'unique_group_count': 0})\n",
    "\n",
    "# Print the result\n",
    "print(group_id_counts_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of particles in each month\n",
    "PT_df['time'] = PT_df.index.get_level_values('time')\n",
    "PT_df['time'] = PT_df['time'].dt.month\n",
    "PT_df['time'].value_counts()\n",
    "print(PT_df['time'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the crs of cw_avg to 3174\n",
    "CW_avg.to_crs('EPSG:3174', inplace=True)\n",
    "CW_low.to_crs('EPSG:3174', inplace=True)\n",
    "CW_high.to_crs('EPSG:3174', inplace=True)\n",
    "CW_surge.to_crs('EPSG:3174', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CW_avg.crs)\n",
    "print(CW_low.crs)\n",
    "print(CW_high.crs)\n",
    "print(CW_surge.crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find intersection of particle tracking with coastal wetlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_first_intersections(gdf, CW_avg):\n",
    "    \"\"\"\n",
    "    Calculate the first intersections of particles with the CW_avg for each month,\n",
    "    and compute the percentage of particles intersecting for the first time.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame containing particle data with 'time', 'group_id', and 'group_number' columns.\n",
    "    - CW_avg: GeoDataFrame representing the coastal wetlands with average lake level to find intersections with.\n",
    "\n",
    "    Returns:\n",
    "    - first_intersections: DataFrame with the first intersections for each particle group.\n",
    "    - percentage_intersecting: float representing the percentage of particles intersecting for the first time.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Ensure 'time' and 'particles' are not both an index and a column\n",
    "    if 'time' in gdf.index.names:\n",
    "        gdf = gdf.reset_index(drop=False)\n",
    "\n",
    "    # Step 2: Sort the GeoDataFrame by 'group_id' and 'group_number'\n",
    "    gdf = gdf.sort_values(by=['group_id', 'group_number'])\n",
    "\n",
    "    # Initialize a DataFrame to store the first intersections for each particle\n",
    "    first_intersections = pd.DataFrame()\n",
    "\n",
    "    # Initialize variables to store the count of total particles and intersecting particles\n",
    "    total_particles_tracked = 0\n",
    "    total_particles_intersecting = 0\n",
    "\n",
    "    # Step 3: Loop through each month to find the first intersection with CW_avg\n",
    "    unique_times = gdf['time'].dt.to_period('M').unique()\n",
    "\n",
    "    for month in unique_times:\n",
    "        # Filter the data for the current month\n",
    "        monthly_gdf = gdf[gdf['time'].dt.to_period('M') == month]\n",
    "        \n",
    "        # Count total particles tracked in this month\n",
    "        total_particles_tracked += monthly_gdf['group_id'].nunique()\n",
    "        \n",
    "        # Perform the spatial join to find intersections with CW_avg\n",
    "        monthly_intersections = gpd.sjoin(monthly_gdf, CW_avg, how='inner', predicate='intersects')\n",
    "\n",
    "        # Sort by 'group_id' and 'group_number' to ensure we find the first intersection\n",
    "        monthly_intersections = monthly_intersections.sort_values(by=['group_id', 'group_number'])\n",
    "\n",
    "        # Group by 'group_id' to find the first intersection for each particle group\n",
    "        first_month_intersections = monthly_intersections.groupby('group_id').first().reset_index()\n",
    "\n",
    "        # Append the first intersections for this month to the overall DataFrame\n",
    "        first_intersections = pd.concat([first_intersections, first_month_intersections], ignore_index=True)\n",
    "\n",
    "        # Step 4: Filter out particles that do not intersect at all\n",
    "        particles_with_intersection = first_month_intersections[['group_id', 'group_number']]\n",
    "        \n",
    "        # Count how many particles intersect for the first time\n",
    "        total_particles_intersecting += particles_with_intersection['group_id'].nunique()\n",
    "        \n",
    "        # Remove the particles from the original GeoDataFrame that don't intersect for this month\n",
    "        gdf = gdf[~gdf.set_index(['group_id', 'group_number']).index.isin(\n",
    "            particles_with_intersection.set_index(['group_id', 'group_number']).index)]\n",
    "\n",
    "    # Step 5: Count the number of occurrences of each unique 'group_id'\n",
    "    group_id_counts = first_intersections.groupby('group_id').size().reset_index(name='count')\n",
    "\n",
    "    # Step 6: Calculate the percentage of particles that intersect for the first time\n",
    "    if total_particles_tracked > 0:\n",
    "        percentage_intersecting = (total_particles_intersecting / total_particles_tracked) * 100\n",
    "        print(f\"Percentage of particles intersecting for the first time: {percentage_intersecting:.2f}%\")\n",
    "    else:\n",
    "        percentage_intersecting = 0.0\n",
    "\n",
    "    return first_intersections, percentage_intersecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Monthly Intersections Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def calculate_monthly_first_intersections(gdf, CW_avg, output_csv=\"monthly_first_intersections.csv\"):\n",
    "    \"\"\"\n",
    "    Loop through each month in the dataset, find only the first intersection per particle, \n",
    "    and save the results to a single CSV file. Also calculates the percentage of \n",
    "    intersecting particles per month.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame with 'time', 'group_id', 'group_number', 'geometry'\n",
    "    - CW_avg: GeoDataFrame representing the wetland shapefile\n",
    "    - output_csv: Optional output CSV filename\n",
    "\n",
    "    Returns:\n",
    "    - monthly_first_intersections_df: DataFrame of first-time intersections\n",
    "    - summary_stats_df: DataFrame of intersection percentages per month\n",
    "    \"\"\"\n",
    "\n",
    "    # ‚úÖ Step 1: Reset index if needed\n",
    "    if 'time' in gdf.index.names:\n",
    "        print(\"üîÑ Resetting 'time' from index to column...\")\n",
    "        gdf = gdf.reset_index()\n",
    "\n",
    "    if 'time' not in gdf.columns:\n",
    "        print(\"‚ùå ERROR: 'time' column is missing!\")\n",
    "        return None, None\n",
    "\n",
    "    gdf['time'] = pd.to_datetime(gdf['time'], errors='coerce')\n",
    "\n",
    "    # ‚úÖ Ensure CRS matches\n",
    "    if gdf.crs != CW_avg.crs:\n",
    "        print(\"üîÑ Reprojecting gdf to match CW_avg CRS...\")\n",
    "        gdf = gdf.to_crs(CW_avg.crs)\n",
    "\n",
    "    # ‚úÖ Extract month\n",
    "    gdf['month'] = gdf['time'].dt.to_period(\"M\")\n",
    "\n",
    "    # ‚úÖ Precompute wetland union geometry\n",
    "    wetland_union = CW_avg.geometry.union_all()\n",
    "\n",
    "    # ‚úÖ Initialize storage\n",
    "    monthly_results = []\n",
    "    summary_stats = []\n",
    "\n",
    "    # ‚úÖ Loop over each unique month\n",
    "    unique_months = sorted(gdf['month'].unique())\n",
    "    for month in unique_months:\n",
    "        print(f\"üìÖ Processing {month}...\")\n",
    "\n",
    "        monthly_gdf = gdf[gdf['month'] == month]\n",
    "        total_particles = monthly_gdf[['group_id', 'group_number']].drop_duplicates().shape[0]\n",
    "\n",
    "        intersecting_particles = monthly_gdf[monthly_gdf['geometry'].intersects(wetland_union)]\n",
    "\n",
    "        if not intersecting_particles.empty:\n",
    "            first_intersections = (\n",
    "                intersecting_particles\n",
    "                .sort_values(by=['group_id', 'group_number', 'time'])\n",
    "                .groupby(['group_id', 'group_number'])\n",
    "                .first()\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            total_first = first_intersections.shape[0]\n",
    "            percentage = (total_first / total_particles) * 100 if total_particles > 0 else 0\n",
    "\n",
    "            print(f\"‚úÖ {month}: {total_first} particles first-time intersected ({percentage:.2f}%)\")\n",
    "\n",
    "            first_intersections['month'] = str(month)\n",
    "            monthly_results.append(first_intersections)\n",
    "            summary_stats.append({'month': str(month), 'percentage': percentage})\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {month}: No intersections found.\")\n",
    "\n",
    "    # ‚úÖ Combine all results\n",
    "    if monthly_results:\n",
    "        monthly_first_intersections_df = pd.concat(monthly_results, ignore_index=True)\n",
    "    else:\n",
    "        monthly_first_intersections_df = pd.DataFrame()\n",
    "\n",
    "    # ‚úÖ Convert summary list to DataFrame\n",
    "    summary_stats_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "    # ‚úÖ Save to CSV\n",
    "    monthly_first_intersections_df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Monthly first-time intersections saved to {output_csv}\")\n",
    "\n",
    "    # ‚úÖ Return both\n",
    "    return monthly_first_intersections_df, summary_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_df, monthly_percentages_df = calculate_monthly_first_intersections(PT_gdf, CW_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_monthly_intersection_barchart(summary_df, title=\"Monthly % of First-Time Intersections\"):\n",
    "    \"\"\"\n",
    "    Creates a bar chart showing the percentage of particles that intersected \n",
    "    the coastal wetland for the first time each month.\n",
    "\n",
    "    Parameters:\n",
    "    - summary_df: DataFrame with 'month' and 'percentage' columns\n",
    "    - title: Title for the plot\n",
    "\n",
    "    Returns:\n",
    "    - None (displays the plot)\n",
    "    \"\"\"\n",
    "    # Ensure the data is sorted by month\n",
    "    summary_df = summary_df.sort_values(by=\"month\")\n",
    "\n",
    "    # Plot setup\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(summary_df[\"month\"], summary_df[\"percentage\"], color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Annotate each bar with the percentage\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, f\"{height:.1f}%\", \n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Intersection Percentage (%) \", fontsize=12)\n",
    "    plt.xlabel(\"Month\", fontsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_figures + '/Monthly_First_Time_Intersections_maytoOct_2.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly_intersection_barchart(monthly_percentages_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Inundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_intersections_avgInun, percentage_intersecting = calculate_first_intersections(PT_gdf, CW_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_first_intersections_avg = calculate_monthly_first_intersections(PT_gdf, CW_avg, \"monthly_first_intersections.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_gdf['time'] = PT_gdf.index.get_level_values('time')\n",
    "PT_gdf['time'] = PT_gdf['time'].dt.month\n",
    "PT_gdf['time'].value_counts()\n",
    "print(PT_gdf['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hight Inundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_intersections_HighInun, percentage_intersecting = calculate_first_intersections(PT_gdf, CW_high)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Inundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_intersections_LowInun, percentage_intersecting = calculate_first_intersections(PT_gdf, CW_low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surge Inundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_intersections_SurgeInun, percentage_intersecting = calculate_first_intersections(PT_gdf, CW_surge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save the first_intersections and group_id counts to CSV files\n",
    "first_intersections_avgInun.to_csv(os.path.join(output_path, Intersection_PTCW_Avg), index=False)\n",
    "\n",
    "first_intersections_HighInun.to_csv(os.path.join(output_path, Intersection_PTCW_high), index=False)\n",
    "\n",
    "first_intersections_LowInun.to_csv(os.path.join(output_path, Intersection_PTCW_low), index=False)\n",
    "\n",
    "first_intersections_SurgeInun.to_csv(os.path.join(output_path, Intersection_PTCW_surge), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_first_intersections_avg.to_csv(os.path.join(output_path,'monthly_first_intersections_avg.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv files from output path\n",
    "first_intersections_avgInun = pd.read_csv(os.path.join(output_path, Intersection_PTCW_Avg))\n",
    "first_intersections_highInun = pd.read_csv(os.path.join(output_path, Intersection_PTCW_high))\n",
    "first_intersections_lowInun = pd.read_csv(os.path.join(output_path, Intersection_PTCW_low))\n",
    "first_intersections_surgeInun = pd.read_csv(os.path.join(output_path, Intersection_PTCW_surge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_id_counts.to_csv(os.path.join(output_path, GroupIdcount), index=False)\n",
    "\n",
    "# # Optional: Save the filtered GeoDataFrame (after removing non-intersecting particles)\n",
    "# gdf.to_csv(os.path.join(output_path, Non_Intersection), index=False)\n",
    "\n",
    "# print(\"First intersections, group_id counts, filtered particles, and percentage calculation saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Add NP load to the particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can look at DirectNutrientload Directory, ZonalStats code to see how we obtain Zonal Stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge Intersection with NP Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_ZonalStats(first_intersections_avgInun, Direct_Nutrient):\n",
    "    \"\"\"\n",
    "    Merges particle tracking data with nutrient load data and adjusts nutrient loads\n",
    "    based on occurrences of each group_id.\n",
    "\n",
    "    Parameters:\n",
    "    - first_intersections_avgInun: DataFrame containing particle tracking data with a 'group_id' column.\n",
    "    - Direct_Nutrient: DataFrame containing nutrient load data with 'group_id', 'WetLoad_TN_kg2', and 'WetLoad_TP_kg2' columns.\n",
    "\n",
    "    Returns:\n",
    "    - merged_data: DataFrame with merged data and adjusted 'WetLoad_TN_kg2' and 'WetLoad_TP_kg2' values.\n",
    "    - returns the wetload values divided by the group_id counts the get the values for each group_id count\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Count occurrences of each group_id in the NetCDF file and store as a dictionary\n",
    "    group_id_counts = first_intersections_avgInun['group_id'].value_counts().to_dict()\n",
    "    \n",
    "    # Step 2: Merge particle data with nutrient load data\n",
    "    merged_data = pd.merge(first_intersections_avgInun, Direct_Nutrient, on='group_id', how='left')\n",
    "    \n",
    "    # Step 3: Adjust WetLoad_TN_kg2 and WetLoad_TP_kg2 values by dividing by group_id count\n",
    "    merged_data[fieldDirectTN] = merged_data.apply(\n",
    "        lambda row: row[fieldDirectTN] / group_id_counts[row['group_id']] if pd.notnull(row[fieldDirectTN]) else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    merged_data[fieldDirectTN] = merged_data.apply(\n",
    "        lambda row: row[fieldDirectTN] / group_id_counts[row['group_id']] if pd.notnull(row[fieldDirectTN]) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    merged_data[fieldDirectTP] = merged_data.apply(\n",
    "        lambda row: row[fieldDirectTP] / group_id_counts[row['group_id']] if pd.notnull(row[fieldDirectTP]) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    # drop unnecessary columns\n",
    "    #merged_data.drop(columns=['index_right','ID','GRIDCODE','start_lat','start_lon'], inplace=True)\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging the Intersections for different lake levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge particle tracking data_average inundation with nutrient load data and adjust nutrient loads\n",
    "merged_data_avg = merged_ZonalStats(first_intersections_avgInun, Direct_Nutrient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge particle tracking data_high inundation with nutrient load data and adjust nutrient loads\n",
    "merged_data_high = merged_ZonalStats(first_intersections_highInun, Direct_Nutrient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge particle tracking data_low inundation with nutrient load data and adjust nutrient loads\n",
    "merged_data_low = merged_ZonalStats(first_intersections_lowInun, Direct_Nutrient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge particle tracking data_surge inundation with nutrient load data and adjust nutrient loads\n",
    "merged_data_surge = merged_ZonalStats(first_intersections_surgeInun, Direct_Nutrient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot particles return to Coastal Wetlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_wetload_distribution(\n",
    "    merged_data, \n",
    "    grid_metrics_file_name, \n",
    "    extents, \n",
    "    cmap_tn, \n",
    "    cmap_tp, \n",
    "    font_size=15, \n",
    "    title=\"Combined Wetload Distribution\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a combined hexbin plot showing WetLoad_TN_kg2 and WetLoad_TP_kg2 concentrations \n",
    "    in coastal wetlands with bathymetry background.\n",
    "\n",
    "    Parameters:\n",
    "    - merged_data: DataFrame containing 'longitude', 'latitude', 'WetLoad_TN_kg2', and 'WetLoad_TP_kg2' columns.\n",
    "    - grid_metrics_file_name: Path to the NetCDF file containing bathymetry data.\n",
    "    - extents: List defining the geographic extents for plotting [xmin, xmax, ymin, ymax].\n",
    "    - cmap_tn: Colormap for WetLoad_TN_kg2.\n",
    "    - cmap_tp: Colormap for WetLoad_TP_kg2.\n",
    "    - font_size: Integer representing the font size in the plot.\n",
    "    - title: Optional string to set a custom plot title.\n",
    "\n",
    "    Returns:\n",
    "    - None; displays a combined plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect coordinates and wetload data for plotting\n",
    "    all_coords = np.array(list(zip(merged_data['longitude'], merged_data['latitude'])))\n",
    "    wetload_tn = merged_data[fieldDirectTN].values\n",
    "    wetload_tp = merged_data[fieldDirectTP].values\n",
    "\n",
    "    # Create the figure and axis using the FVCOM plotter\n",
    "    fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure plotter and plot bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "    ax, plot = plotter.plot_field(ax, bathy, extents=extents, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap='Blues', zorder=0)\n",
    "    plotter.draw_grid(ax, linewidth=1.0)\n",
    "\n",
    "    # Create hexbin plot for WetLoad_TN_kg2\n",
    "    hb_tn = ax.hexbin(\n",
    "        all_coords[:, 0], \n",
    "        all_coords[:, 1], \n",
    "        C=wetload_tn, \n",
    "        gridsize=800, \n",
    "        # use viridis colormap for TN\n",
    "        cmap = 'viridis',\n",
    "        #cmap=cmap_tn, \n",
    "        norm=LogNorm(), \n",
    "        reduce_C_function=np.sum, \n",
    "        zorder=40, \n",
    "        alpha=0.6, \n",
    "        label=\"WetLoad_TN\",\n",
    "        color = 'green'\n",
    "    )\n",
    "\n",
    "    # Create hexbin plot for WetLoad_TP_kg2\n",
    "    hb_tp = ax.hexbin(\n",
    "        all_coords[:, 0], \n",
    "        all_coords[:, 1], \n",
    "        C=wetload_tp, \n",
    "        gridsize=80, \n",
    "        cmap=cmap_tp, \n",
    "        norm=LogNorm(), \n",
    "        reduce_C_function=np.sum, \n",
    "        zorder=40, \n",
    "        alpha=0.6, \n",
    "        label=\"WetLoad_TP\",\n",
    "        color = 'pink'\n",
    "    )\n",
    "\n",
    "    # Add color bars for both loads\n",
    "    cbar_tn = fig.colorbar(hb_tn, ax=ax, pad=0.05, fraction=0.05)\n",
    "    #cbar_tn.set_label('WetLoad_TN', fontsize=font_size)\n",
    "\n",
    "    cbar_tp = fig.colorbar(hb_tp, ax=ax, pad=0.14, fraction=0.05)\n",
    "    #cbar_tp.set_label('WetLoad_TP', fontsize=font_size)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(title, fontsize=font_size)\n",
    "\n",
    "    # Show legend\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wetload_distribution_TN_with_three_insets(\n",
    "    merged_data, \n",
    "    grid_metrics_file_name, \n",
    "    main_extents, \n",
    "    zoom_extents_1, \n",
    "    zoom_extents_2, \n",
    "    zoom_extents_3, \n",
    "    color_map, \n",
    "    font_size=15, \n",
    "    title=None,\n",
    "    inset_position_1=[0.6, 0.6, 0.25, 0.25],  \n",
    "    inset_position_2=[0.2, 0.6, 0.25, 0.25],  \n",
    "    inset_position_3=[0.4, 0.2, 0.25, 0.25],  \n",
    "    colorbar_outside=True  \n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a hexbin plot showing the WetLoad_TN_kg2 concentration in coastal wetlands with bathymetry background,\n",
    "    with three zoomed-in maps inside or near the main map.\n",
    "\n",
    "    Fixes:\n",
    "    ‚úÖ Each zoom-in map title matches the color of its highlight rectangle.\n",
    "    ‚úÖ Axis ticks & labels removed for zoom-in maps.\n",
    "    ‚úÖ Smaller font sizes for zoom-in maps.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect coordinates and WetLoad_TN_kg2 data for plotting\n",
    "    all_coords = np.array(list(zip(merged_data['longitude'], merged_data['latitude'])))\n",
    "    wetload_tn = merged_data['WetLoad_TN_kgcellday'].values\n",
    "\n",
    "    # Create the figure and main axis\n",
    "    fig, ax_main = plt.subplots(figsize=(26., 26.), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig.suptitle(title if title else 'Indirect Annual Nitrogen Load to Coastal Wetlands', fontsize=font_size + 5)\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure plotter for bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "\n",
    "    # Plot the main extent\n",
    "    ax_main, plot_main = plotter.plot_field(\n",
    "        ax_main, bathy, extents=main_extents, add_colour_bar=True, cb_label='Depth(m)', vmin=-60., vmax=0., cmap='Blues', zorder=0\n",
    "    )\n",
    "    plotter.draw_grid(ax_main, linewidth=0.5)\n",
    "    hb_main = ax_main.hexbin(\n",
    "        all_coords[:, 0], \n",
    "        all_coords[:, 1], \n",
    "        C=wetload_tn, \n",
    "        gridsize=50, \n",
    "        cmap=color_map, \n",
    "        norm=LogNorm(), \n",
    "        reduce_C_function=np.sum, \n",
    "        zorder=40\n",
    "    )\n",
    "\n",
    "    # Add color bar for main extent\n",
    "    if colorbar_outside:\n",
    "        cbar_main = fig.colorbar(hb_main, ax=ax_main, pad=0.1)\n",
    "    else:\n",
    "        cbar_main = fig.colorbar(hb_main, ax=ax_main, shrink=0.8, location=\"right\", pad=0.02)\n",
    "    cbar_main.set_label('Nitrogen Load (kg/cell/day)', fontsize=font_size)\n",
    "    #ax_main.set_title( fontsize=font_size)\n",
    "    ax_main.set_xlabel('Longitude', fontsize=font_size)\n",
    "    ax_main.set_ylabel('Latitude', fontsize=font_size)\n",
    "\n",
    "    # Define inset positions, extents, and titles\n",
    "    inset_positions = [inset_position_1, inset_position_2, inset_position_3]\n",
    "    zoom_extents = [zoom_extents_1, zoom_extents_2, zoom_extents_3]\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    # Iterate over three insets\n",
    "    for i, (inset_pos, zoom_extent, color) in enumerate(zip(inset_positions, zoom_extents, colors)):\n",
    "        # Create inset axis\n",
    "        ax_inset = plt.axes(inset_pos, projection=ccrs.PlateCarree())\n",
    "        ax_inset.set_extent(zoom_extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Plot inset bathymetry\n",
    "        ax_inset, plot_zoom = plotter.plot_field(\n",
    "            ax_inset, bathy, extents=zoom_extent, add_colour_bar=False, cb_label=None, vmin=-60., vmax=0., cmap='Blues', zorder=0\n",
    "        )\n",
    "        plotter.draw_grid(ax_inset, linewidth=0.5)\n",
    "\n",
    "        # Add hexbin plot\n",
    "        hb_zoom = ax_inset.hexbin(\n",
    "            all_coords[:, 0], \n",
    "            all_coords[:, 1], \n",
    "            C=wetload_tn, \n",
    "            gridsize=50, \n",
    "            cmap=color_map, \n",
    "            norm=LogNorm(), \n",
    "            reduce_C_function=np.sum, \n",
    "            zorder=40\n",
    "        )\n",
    "\n",
    "        # Add color bar inside the inset with smaller font\n",
    "        #cbar_zoom = fig.colorbar(hb_zoom, ax=ax_inset, shrink=0.6, pad=0.02)\n",
    "        #cbar_zoom.set_label('N Load', fontsize=font_size - 6)  \n",
    "\n",
    "        # Set inset title with matching color\n",
    "        ax_inset.set_title(f\"Enlarge view {i+1}\", fontsize=font_size - 4, color=color, fontweight='bold')\n",
    "\n",
    "        # Remove axis ticks & labels\n",
    "        #ax_inset.set_xticks([])\n",
    "        #ax_inset.set_yticks([])\n",
    "        #ax_inset.set_xlabel('')\n",
    "        #ax_inset.set_ylabel('')\n",
    "\n",
    "        # Add rectangle to highlight the zoomed-in region with matching color\n",
    "        rect = plt.Rectangle(\n",
    "            (zoom_extent[0], zoom_extent[2]), \n",
    "            zoom_extent[1] - zoom_extent[0], \n",
    "            zoom_extent[3] - zoom_extent[2],\n",
    "            linewidth=2, edgecolor=color, facecolor='none', transform=ccrs.PlateCarree(), zorder=50\n",
    "        )\n",
    "        ax_main.add_patch(rect)\n",
    "        \n",
    "    #ax.set_title(title if title else 'Indirect Annual Nitrogen Load to Coastal Wetlands with lowe Inundation (kg^2/area)', fontsize=font_size)\n",
    "    plt.savefig(output_figures + '/WetLoadDistribution_AvgInun_Nitrogen_Zoombox.png', dpi=300, bbox_inches='tight')\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wetload_distribution_TN_with_three_insets(\n",
    "    merged_data, \n",
    "    grid_metrics_file_name, \n",
    "    main_extents, \n",
    "    zoom_extents_1, \n",
    "    zoom_extents_2, \n",
    "    zoom_extents_3, \n",
    "    color_map, \n",
    "    font_size=15, \n",
    "    title=None,\n",
    "    inset_position_1=[0.30, 0.50, 0.25, 0.25],  # [left, bottom, width, height]\n",
    "    inset_position_2= [0.1, 0.40, 0.18, 0.18],  # [left, bottom, width, height]\n",
    "    inset_position_3=[0.50, 0.25,0.18, 0.18],  # [left, bottom, width, height] \n",
    "    colorbar_outside=True  \n",
    "    #save_fig=True\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a hexbin plot showing the WetLoad_TN_kg2 concentration in coastal wetlands with bathymetry background,\n",
    "    with three zoomed-in maps inside or near the main map. \n",
    "    Each zoom-in region is enclosed with a colored box that matches the zoomed-in map's title color.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect coordinates and WetLoad_TN_kg2 data for plotting\n",
    "    all_coords = np.array(list(zip(merged_data['longitude'], merged_data['latitude'])))\n",
    "    wetload_tn = merged_data['WetLoad_TN_kgcellday'].values\n",
    "\n",
    "    # Create the figure and main axis\n",
    "    fig, ax_main = plt.subplots(figsize=(26., 26.), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig.suptitle(title if title else 'Indirect Annual Nitrogen Load to Coastal Wetlands', fontsize=font_size + 5)\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure plotter for bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "\n",
    "    # Plot the main extent\n",
    "    ax_main, plot_main = plotter.plot_field(\n",
    "        ax_main, bathy, extents=main_extents, add_colour_bar=True, cb_label='Depth(m)', vmin=-60., vmax=0., cmap='Blues', zorder=0\n",
    "    )\n",
    "    plotter.draw_grid(ax_main, linewidth=0.5)\n",
    "    hb_main = ax_main.hexbin(\n",
    "        all_coords[:, 0], \n",
    "        all_coords[:, 1], \n",
    "        C=wetload_tn, \n",
    "        gridsize=50, \n",
    "        cmap=color_map, \n",
    "        norm=LogNorm(), \n",
    "        reduce_C_function=np.sum, \n",
    "        zorder=40\n",
    "    )\n",
    "\n",
    "    # Add color bar for main extent with increased font size\n",
    "    if colorbar_outside:\n",
    "        cbar_main = fig.colorbar(hb_main, ax=ax_main, pad=0.1)\n",
    "    else:\n",
    "        cbar_main = fig.colorbar(hb_main, ax=ax_main, shrink=0.8, location=\"right\", pad=0.15)\n",
    "    cbar_main.set_label('Nitrogen Load (kg/cell/day)', fontsize=font_size + 5)  # Increased font size for label\n",
    "    cbar_main.ax.tick_params(labelsize=font_size + 2)  # Increase font size for tick labels\n",
    "\n",
    "    ax_main.set_xlabel('Longitude', fontsize=font_size)\n",
    "    ax_main.set_ylabel('Latitude', fontsize=font_size)\n",
    "\n",
    "    # Define inset positions, extents, and titles\n",
    "    inset_positions = [inset_position_1, inset_position_2, inset_position_3]\n",
    "    zoom_extents = [zoom_extents_1, zoom_extents_2, zoom_extents_3]\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    # Iterate over three insets\n",
    "    for i, (inset_pos, zoom_extent, color) in enumerate(zip(inset_positions, zoom_extents, colors)):\n",
    "        # Create inset axis\n",
    "        ax_inset = plt.axes(inset_pos, projection=ccrs.PlateCarree())\n",
    "        ax_inset.set_extent(zoom_extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Plot inset bathymetry\n",
    "        ax_inset, plot_zoom = plotter.plot_field(\n",
    "            ax_inset, bathy, extents=zoom_extent, add_colour_bar=False, cb_label=None, vmin=-60., vmax=0., cmap='Blues', zorder=0\n",
    "        )\n",
    "        plotter.draw_grid(ax_inset, linewidth=0.5)\n",
    "\n",
    "        # Add hexbin plot for the inset zoom area\n",
    "        hb_zoom = ax_inset.hexbin(\n",
    "            all_coords[:, 0], \n",
    "            all_coords[:, 1], \n",
    "            C=wetload_tn, \n",
    "            gridsize=50, \n",
    "            cmap=color_map, \n",
    "            norm=LogNorm(), \n",
    "            reduce_C_function=np.sum, \n",
    "            zorder=40\n",
    "        )\n",
    "\n",
    "        # Set inset title with matching color\n",
    "        ax_inset.set_title(f\"Enlarge view {i+1}\", fontsize=font_size - 4, color=color, fontweight='bold')\n",
    "\n",
    "        # Add rectangle to highlight the zoomed-in region with matching color\n",
    "        rect = plt.Rectangle(\n",
    "            (zoom_extent[0], zoom_extent[2]), \n",
    "            zoom_extent[1] - zoom_extent[0], \n",
    "            zoom_extent[3] - zoom_extent[2],\n",
    "            linewidth=2, edgecolor=color, facecolor='none', transform=ccrs.PlateCarree(), zorder=50\n",
    "        )\n",
    "        ax_main.add_patch(rect)\n",
    "\n",
    "        # **NEW CODE**: Draw a colored border around each zoom-in box\n",
    "        inset_box = plt.Rectangle(\n",
    "            (inset_pos[0], inset_pos[1]),  # Position of the inset box on the figure\n",
    "            inset_pos[2],                  # Width of the inset box\n",
    "            inset_pos[3],                  # Height of the inset box\n",
    "            linewidth=3, edgecolor=color, facecolor='none', linestyle='-', zorder=60\n",
    "        )\n",
    "        ax_main.add_patch(inset_box)\n",
    "        \n",
    "    # Save the plot\n",
    "    plt.savefig (output_figures + '/WetLoadDistribution_AvgInun_Nitrogen_Zoombox.png',dpi=300, bbox_inches='tight')\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Annual Nitorgen load with enlarge maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN_with_three_insets(\n",
    "    merged_data=merged_data_avg,\n",
    "    grid_metrics_file_name=grid_metrics_file_name,\n",
    "    main_extents=[275,279,43,46.3],  # Main extent\n",
    "    zoom_extents_1=[276.5,276.8,44.8,45.5],#zoomed-in extent\n",
    "    zoom_extents_2=[276.5, 276, 43.58, 44],   # Zoomed-in extent\n",
    "    zoom_extents_3=[277.5, 277, 43.5, 44],   # Zoomed-in extent\n",
    "    color_map=plasma_cmap,  # Colormap for nitrogen\n",
    "    font_size=24,\n",
    "    inset_position_1=[0.30, 0.50, 0.25, 0.25],  # [left, bottom, width, height]\n",
    "    inset_position_2= [0.1, 0.40, 0.18, 0.18],  # [left, bottom, width, height]\n",
    "    inset_position_3=[0.50, 0.25,0.18, 0.18],  # [left, bottom, width, height]\n",
    "    colorbar_outside=True,\n",
    "    title=\"Indirect Nitrogen Load to Coastal Wetlands with Average Inundation(kg/cell/day)\"\n",
    "\n",
    ")\n",
    "#lt.savefig(output_figures + '/WetLoadDistribution_AvgInun_Nitrogen_Nov-Apr.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN_with_three_insets(\n",
    "    merged_data=merged_data_high,\n",
    "    grid_metrics_file_name=grid_metrics_file_name,\n",
    "    main_extents=[275,279,43,46.3],  # Main extent\n",
    "    zoom_extents_1=[276.5,276.8,44.8,45.5],#zoomed-in extent\n",
    "    zoom_extents_2=[276.5, 276, 43.58, 44],   # Zoomed-in extent\n",
    "    zoom_extents_3=[277.5, 277, 43.5, 44],   # Zoomed-in extent\n",
    "    color_map=plasma_cmap,  # Colormap for nitrogen\n",
    "    font_size=24,\n",
    "    inset_position_1=[0.30, 0.50, 0.25, 0.25],  # [left, bottom, width, height]\n",
    "    inset_position_2= [0.1, 0.40, 0.18, 0.18],  # [left, bottom, width, height]\n",
    "    inset_position_3=[0.50, 0.25,0.18, 0.18],  # [left, bottom, width, height]\n",
    "    colorbar_outside=True,\n",
    "    title=\"Indirect Annual Nitrogen Load to Coastal Wetlands with High Inundation( kg/cell/day)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN_with_three_insets(\n",
    "    merged_data=merged_data_low,\n",
    "    grid_metrics_file_name=grid_metrics_file_name,\n",
    "    main_extents=[275,279,43,46.3],  # Main extent\n",
    "    zoom_extents_1=[276.5,276.8,44.8,45.5],#zoomed-in extent\n",
    "    zoom_extents_2=[276.5, 276, 43.58, 44],   # Zoomed-in extent\n",
    "    zoom_extents_3=[277.5, 277, 43.5, 44],   # Zoomed-in extent\n",
    "    color_map=plasma_cmap,  # Colormap for nitrogen\n",
    "    font_size=24,\n",
    "    inset_position_1=[0.30, 0.50, 0.25, 0.25],  # [left, bottom, width, height]\n",
    "    inset_position_2= [0.1, 0.40, 0.18, 0.18],  # [left, bottom, width, height]\n",
    "    inset_position_3=[0.50, 0.25,0.18, 0.18],  # [left, bottom, width, height]\n",
    "    colorbar_outside=True,\n",
    "    title=\"Indirect Annual Nitrogen Load to Coastal Wetlands with Low Inundation( kg/cell/day)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot P load with enlarge map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wetload_distribution_TP_with_three_insets(\n",
    "    merged_data, \n",
    "    grid_metrics_file_name, \n",
    "    main_extents, \n",
    "    zoom_extents_1, \n",
    "    zoom_extents_2, \n",
    "    zoom_extents_3, \n",
    "    color_map, \n",
    "    font_size=15, \n",
    "    title=None,\n",
    "    inset_position_1=[0.6, 0.6, 0.25, 0.25],  \n",
    "    inset_position_2=[0.2, 0.6, 0.25, 0.25],  \n",
    "    inset_position_3=[0.4, 0.2, 0.25, 0.25],  \n",
    "    colorbar_outside=True  \n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a hexbin plot showing the WetLoad_TP_kg2 concentration in coastal wetlands with bathymetry background,\n",
    "    with three zoomed-in maps inside or near the main map.\n",
    "\n",
    "    Fixes:\n",
    "    ‚úÖ Each zoom-in map title matches the color of its highlight rectangle.\n",
    "    ‚úÖ Axis ticks & labels removed for zoom-in maps.\n",
    "    ‚úÖ Smaller font sizes for zoom-in maps.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect coordinates and WetLoad_TP_kg2 data for plotting\n",
    "    all_coords = np.array(list(zip(merged_data['longitude'], merged_data['latitude'])))\n",
    "    wetload_tp = merged_data['WetLoad_TP_kgcellday'].values  # Change from TN to TP\n",
    "\n",
    "    # Create the figure and main axis\n",
    "    fig, ax_main = plt.subplots(figsize=(26., 26.), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig.suptitle(title if title else 'Indirect Annual Phosphorus Load to Coastal Wetlands', fontsize=font_size + 5)\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure plotter for bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "\n",
    "    # Plot the main extent\n",
    "    ax_main, plot_main = plotter.plot_field(\n",
    "        ax_main, bathy, extents=main_extents, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap='Blues', zorder=0\n",
    "    )\n",
    "    plotter.draw_grid(ax_main, linewidth=0.5)\n",
    "    hb_main = ax_main.hexbin(\n",
    "        all_coords[:, 0], \n",
    "        all_coords[:, 1], \n",
    "        C=wetload_tp,  # Change from TN to TP\n",
    "        gridsize=50, \n",
    "        cmap=color_map, \n",
    "        norm=LogNorm(), \n",
    "        reduce_C_function=np.sum, \n",
    "        zorder=40\n",
    "    )\n",
    "\n",
    "    # Add color bar for main extent with increased font size\n",
    "    if colorbar_outside:\n",
    "        cbar_main = fig.colorbar(hb_main, ax=ax_main, pad=0.1)\n",
    "    else:\n",
    "        cbar_main = fig.colorbar(hb_main, ax=ax_main, shrink=0.8, location=\"right\", pad=0.02)\n",
    "    cbar_main.set_label('Phosphorus Load (kg/cell/day)', fontsize=font_size + 5)  # Increased font size for label\n",
    "    cbar_main.ax.tick_params(labelsize=font_size + 2)  # Increase font size for tick labels\n",
    "\n",
    "    ax_main.set_xlabel('Longitude', fontsize=font_size)\n",
    "    ax_main.set_ylabel('Latitude', fontsize=font_size)\n",
    "\n",
    "    # Define inset positions, extents, and titles\n",
    "    inset_positions = [inset_position_1, inset_position_2, inset_position_3]\n",
    "    zoom_extents = [zoom_extents_1, zoom_extents_2, zoom_extents_3]\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    # Iterate over three insets\n",
    "    for i, (inset_pos, zoom_extent, color) in enumerate(zip(inset_positions, zoom_extents, colors)):\n",
    "        # Create inset axis\n",
    "        ax_inset = plt.axes(inset_pos, projection=ccrs.PlateCarree())\n",
    "        ax_inset.set_extent(zoom_extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Plot inset bathymetry\n",
    "        ax_inset, plot_zoom = plotter.plot_field(\n",
    "            ax_inset, bathy, extents=zoom_extent, add_colour_bar=False, cb_label=None, vmin=-60., vmax=0., cmap='Blues', zorder=0\n",
    "        )\n",
    "        plotter.draw_grid(ax_inset, linewidth=0.5)\n",
    "\n",
    "        # Add hexbin plot\n",
    "        hb_zoom = ax_inset.hexbin(\n",
    "            all_coords[:, 0], \n",
    "            all_coords[:, 1], \n",
    "            C=wetload_tp,  # Change from TN to TP\n",
    "            gridsize=50, \n",
    "            cmap=color_map, \n",
    "            norm=LogNorm(), \n",
    "            reduce_C_function=np.sum, \n",
    "            zorder=40\n",
    "        )\n",
    "\n",
    "        # Set inset title with matching color\n",
    "        ax_inset.set_title(f\"Enlarged View {i+1}\", fontsize=font_size - 4, color=color, fontweight='bold')\n",
    "\n",
    "        # Remove axis ticks & labels\n",
    "        ax_inset.set_xticks([])\n",
    "        ax_inset.set_yticks([])\n",
    "        ax_inset.set_xlabel('')\n",
    "        ax_inset.set_ylabel('')\n",
    "\n",
    "        # Add rectangle to highlight the zoomed-in region with matching color\n",
    "        rect = plt.Rectangle(\n",
    "            (zoom_extent[0], zoom_extent[2]), \n",
    "            zoom_extent[1] - zoom_extent[0], \n",
    "            zoom_extent[3] - zoom_extent[2],\n",
    "            linewidth=2, edgecolor=color, facecolor='none', transform=ccrs.PlateCarree(), zorder=50\n",
    "        )\n",
    "        ax_main.add_patch(rect)\n",
    "        \n",
    "    # Save the plot\n",
    "    plt.savefig(output_figures + '/WetLoadDistribution_AvgInun_Phosphorus_Zoombox.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TP_with_three_insets(\n",
    "    merged_data=merged_data_avg,\n",
    "    grid_metrics_file_name=grid_metrics_file_name,\n",
    "    main_extents=[275,279,43,46.3],  # Main extent\n",
    "    zoom_extents_1=[276.5,276.8,44.8,45.5],#zoomed-in extent\n",
    "    zoom_extents_2=[276.5, 276, 43.58, 44],   # Zoomed-in extent\n",
    "    zoom_extents_3=[277.5, 277, 43.5, 44],   # Zoomed-in extent\n",
    "    color_map=plasma_cmap,  # Colormap for nitrogen\n",
    "    font_size=24,\n",
    "    inset_position_1=[0.30, 0.50, 0.25, 0.25],  # [left, bottom, width, height]\n",
    "    inset_position_2= [0.1, 0.40, 0.18, 0.18],  # [left, bottom, width, height]\n",
    "    inset_position_3=[0.50, 0.25,0.18, 0.18],  # [left, bottom, width, height]\n",
    "    colorbar_outside=True,\n",
    "    title=\"Indirect Annual Phosphorus Load to Coastal Wetlands with Average Inundation (kg^2/area)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Nitrogen return to Coastal Wetlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wetload_distribution_TN(merged_data, grid_metrics_file_name, extents, color_map, font_size=15, title=None):\n",
    "    \"\"\"\n",
    "    Creates a hexbin plot showing the WetLoad_TN_kg2 concentration in coastal wetlands with bathymetry background.\n",
    "\n",
    "    Parameters:\n",
    "    - merged_data: DataFrame containing 'longitude', 'latitude', and 'WetLoad_TN_kg2' columns.\n",
    "    - grid_metrics_file_name: Path to the NetCDF file containing bathymetry data.\n",
    "    - extents: List defining the geographic extents for plotting [xmin, xmax, ymin, ymax].\n",
    "    - color_map: Colormap for hexbin particle data.\n",
    "    - font_size: Integer representing the font size in the plot.\n",
    "    - title: Optional string to set a custom plot title.\n",
    "\n",
    "    Returns:\n",
    "    - None; displays a plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect coordinates and WetLoad_TN_kg2 data for plotting\n",
    "    all_coords = np.array(list(zip(merged_data['longitude'], merged_data['latitude'])))\n",
    "    wetload_tn = merged_data[fieldDirectTN].values\n",
    "\n",
    "    # Create the figure and axis using the FVCOM plotter\n",
    "    fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure plotter and plot bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "    ax, plot = plotter.plot_field(ax, bathy, extents=extents, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap='Blues', zorder=0)\n",
    "    plotter.draw_grid(ax, linewidth=1.0)\n",
    "\n",
    "    # Create a hexbin plot where bins reflect WetLoad_TN_kg2 concentration\n",
    "    hb = ax.hexbin(all_coords[:, 0], all_coords[:, 1], C=wetload_tn, gridsize=50, cmap=color_map, norm=LogNorm(), reduce_C_function=np.sum, zorder=40)\n",
    "\n",
    "    # Add color bar for WetLoad_TN_kg2 concentration\n",
    "    cbar = fig.colorbar(hb, ax=ax, pad=0.1)\n",
    "    cbar.set_label('Annual Indirect Nitrogen Load (kg/cell/day)', fontsize=font_size)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(title if title else 'Indirect Annual Nitrogen Load to Coastal Wetlands with lowe Inundation (kg^2/area)', fontsize=font_size)\n",
    "    plt.savefig(output_figures + '/WetLoadDistribution_SurgeInun_Nitrogen.png', dpi=300, bbox_inches='tight')\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN(\n",
    "    merged_data=merged_data_avg,\n",
    "    grid_metrics_file_name= grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    color_map=plasma_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Nitrogen Load to Coastal Wetlands with Average Inundation in 2023 (kg¬≤/area)'\n",
    ")\n",
    "\n",
    "#plt.savefig(output_path + '/WetLoadDistribution_AvgInun.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN(\n",
    "    merged_data=merged_data_high,\n",
    "    grid_metrics_file_name= grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    color_map=plasma_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Nitrogen Load to Coastal Wetlands with High Inundation in 2023 (kg¬≤/area)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN(merged_data=merged_data_low,\n",
    "    grid_metrics_file_name= grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    color_map=plasma_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Nitrogen Load to Coastal Wetlands with Low Inundation in 2023 (kg¬≤/area)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TN(merged_data=merged_data_surge, \n",
    "    grid_metrics_file_name= grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    color_map=plasma_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Nitrogen Load to Coastal Wetlands with Surge Inundation in 2023 (kg¬≤/area)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Phosphorus return to coastal Wetlands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wetload_distribution_TP(merged_data, grid_metrics_file_name, extents, colourmap, font_size=15, title=None):\n",
    "    \"\"\"\n",
    "    Creates a hexbin plot showing the WetLoad_TP_kg2 concentration in coastal wetlands with bathymetry background.\n",
    "\n",
    "    Parameters:\n",
    "    - merged_data: DataFrame containing 'longitude', 'latitude', and 'WetLoad_TP_kg2' columns.\n",
    "    - grid_metrics_file_name: Path to the NetCDF file containing bathymetry data.\n",
    "    - extents: List defining the geographic extents for plotting [xmin, xmax, ymin, ymax].\n",
    "    - green_cmap: Colormap for hexbin phosphorus load data.\n",
    "    - font_size: Integer representing the font size in the plot.\n",
    "    - title: Optional string to set a custom plot title.\n",
    "\n",
    "    Returns:\n",
    "    - None; displays a plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect coordinates and WetLoad_TP_kg2 data for plotting\n",
    "    all_coords = np.array(list(zip(merged_data['longitude'], merged_data['latitude'])))\n",
    "    wetload_tp = merged_data[fieldDirectTP].values\n",
    "\n",
    "    # Create the figure and axis using the FVCOM plotter\n",
    "    fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure plotter and plot bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "    ax, plot = plotter.plot_field(ax, bathy, extents=extents, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap='Blues', zorder=0)\n",
    "    plotter.draw_grid(ax, linewidth=1.0)\n",
    "\n",
    "    # Create a hexbin plot where bins reflect WetLoad_TP_kg2 concentration\n",
    "    hb = ax.hexbin(all_coords[:, 0], all_coords[:, 1], C=wetload_tp, gridsize=50, cmap=viridis_cmap, norm=LogNorm(), reduce_C_function=np.sum, zorder=40)\n",
    "\n",
    "    # Add color bar for WetLoad_TP_kg2 concentration\n",
    "    cbar = fig.colorbar(hb, ax=ax, pad=0.1)\n",
    "    cbar.set_label('Annual Indirect Phosphorus Load (kg/cell/day)', fontsize=font_size)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(title if title else 'Annual Indirect Phosphorus Load to Coastal Wetlands with Average Inundation in 2023 (kg¬≤/area)', fontsize=font_size, pad=20)\n",
    "    plt.savefig(output_figures + '/WetLoadDistribution_LowInun_PH.png', dpi=300, bbox_inches='tight')\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TP(\n",
    "    merged_data=merged_data_avg,\n",
    "    grid_metrics_file_name = grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    colourmap=viridis_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Phosphorus Load to CW with Average Inundation in 2023(kg¬≤/area)'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TP(\n",
    "    merged_data=merged_data_high,\n",
    "    grid_metrics_file_name = grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    colourmap=viridis_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Phosphorus Load to CW with High Inundation in 2023(kg¬≤/area)'\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TP(\n",
    "    merged_data=merged_data_low,\n",
    "    grid_metrics_file_name = grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    colourmap=viridis_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Phosphorus Load to CW with Low Inundation in 2023(kg¬≤/area)'\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wetload_distribution_TP(\n",
    "    merged_data=merged_data_surge,\n",
    "    grid_metrics_file_name = grid_metrics_file_name,\n",
    "    extents=extents,\n",
    "    colourmap=viridis_cmap,\n",
    "    font_size=12,\n",
    "    title='Annual Indirect Phosphorus Load to CW with Surge Inundation in 2023(kg¬≤/area)'\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CW_avg_with_bathy(CW_avg, grid_metrics_file_name, extents, font_size=15, title=None):\n",
    "    \"\"\"\n",
    "    Plots the Coastal Wetlands (CW_avg) using the start_lat and start_lon coordinates over a bathymetry background.\n",
    "\n",
    "    Parameters:\n",
    "    - CW_avg: GeoDataFrame containing the 'start_lat' and 'start_lon' coordinates of the coastal wetlands.\n",
    "    - grid_metrics_file_name: Path to the NetCDF file containing bathymetry data.\n",
    "    - extents: List defining the geographic extents for plotting [xmin, xmax, ymin, ymax].\n",
    "    - font_size: Integer representing the font size in the plot.\n",
    "    - title: Optional string to set a custom plot title.\n",
    "\n",
    "    Returns:\n",
    "    - None; displays a plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract coordinates for plotting\n",
    "    coords = np.array(list(zip(CW_avg['start_lon'], CW_avg['start_lat'])))\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='white')\n",
    "\n",
    "    # Load bathymetry data from NetCDF\n",
    "    with Dataset(grid_metrics_file_name, 'r') as ds:\n",
    "        bathy = -ds.variables['h'][:]\n",
    "\n",
    "    # Configure the plot for bathymetry\n",
    "    plotter = FVCOMPlotter(grid_metrics_file_name, geographic_coords=True, font_size=font_size)\n",
    "    ax, plot = plotter.plot_field(ax, bathy, extents=extents, add_colour_bar=True, cb_label='Depth (m)', vmin=-60., vmax=0., cmap='Blues', zorder=0)\n",
    "\n",
    "    # Scatter plot of CW_avg points\n",
    "    ax.scatter(coords[:, 0], coords[:, 1], c='green', marker='o', s=10, label='Average Lake Level Extent of Coastal Wetlands', zorder=5)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(title if title else 'Coastal Wetlands (CW_avg) with Bathymetry', fontsize=font_size, pad=20)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend(fontsize=font_size)\n",
    "    plt.savefig(output_figures + '/CW_avg_with_bathy.png', dpi=300, bbox_inches='tight')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CW_avg_with_bathy(\n",
    "    CW_avg=CW_avg,\n",
    "    grid_metrics_file_name=grid_metrics_file_name,\n",
    "    extents=[275, 277.69, 43, 46.3],\n",
    "    font_size=15,\n",
    "    title='Coastal Wetlands extent with average lake levels'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
